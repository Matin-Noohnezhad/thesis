{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "#Transfering data to GPU memory will take time and we only do it, if we really need to use GPU\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],-1) #reshape 2D image into a 1D vector\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) #reshape 2D image into a 1D vector\n",
    "##\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the input vectors\n",
    "x_train /= 255 \n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the output to one-hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train, no_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, no_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(shape_of_input, no_classes, no_hidden_layers=0, no_units_per_layer=50):\n",
    "    model = Sequential()\n",
    "    if (no_hidden_layers == 0):\n",
    "        model.add(Dense(no_classes, input_shape = shape_of_input, name='output_layer', activation='softmax'))\n",
    "        return model\n",
    "    model.add(Dense(no_units_per_layer, input_shape = shape_of_input,  activation='relu'))\n",
    "    for i in range(no_hidden_layers-1):\n",
    "        model.add(Dense(no_units_per_layer, activation='relu'))\n",
    "    model.add(Dense(no_classes, name='output_layer', activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                30730     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 31,280\n",
      "Trainable params: 31,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 2.1585 - accuracy: 0.1653 - val_loss: 2.0928 - val_accuracy: 0.2125\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.9791 - accuracy: 0.2428 - val_loss: 1.9486 - val_accuracy: 0.2609\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.9244 - accuracy: 0.2604 - val_loss: 1.8954 - val_accuracy: 0.2731\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8936 - accuracy: 0.2752 - val_loss: 1.8877 - val_accuracy: 0.2774\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8798 - accuracy: 0.2801 - val_loss: 1.8818 - val_accuracy: 0.2826\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8650 - accuracy: 0.2903 - val_loss: 1.8667 - val_accuracy: 0.2995\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8631 - accuracy: 0.2954 - val_loss: 1.8718 - val_accuracy: 0.2921\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8517 - accuracy: 0.3045 - val_loss: 1.8709 - val_accuracy: 0.3022\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8449 - accuracy: 0.3087 - val_loss: 1.8561 - val_accuracy: 0.3079\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8422 - accuracy: 0.3115 - val_loss: 1.8579 - val_accuracy: 0.3079\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8371 - accuracy: 0.3153 - val_loss: 1.8488 - val_accuracy: 0.3130\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8290 - accuracy: 0.3204 - val_loss: 1.8357 - val_accuracy: 0.3174\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8237 - accuracy: 0.3226 - val_loss: 1.8590 - val_accuracy: 0.3107\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8178 - accuracy: 0.3254 - val_loss: 1.8398 - val_accuracy: 0.3164\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8100 - accuracy: 0.3296 - val_loss: 1.8281 - val_accuracy: 0.3222\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8029 - accuracy: 0.3308 - val_loss: 1.8214 - val_accuracy: 0.3227\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7989 - accuracy: 0.3339 - val_loss: 1.8051 - val_accuracy: 0.3303\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7905 - accuracy: 0.3394 - val_loss: 1.8038 - val_accuracy: 0.3381\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7851 - accuracy: 0.3425 - val_loss: 1.8060 - val_accuracy: 0.3360\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7786 - accuracy: 0.3446 - val_loss: 1.7859 - val_accuracy: 0.3419\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7756 - accuracy: 0.3470 - val_loss: 1.7973 - val_accuracy: 0.3355\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7671 - accuracy: 0.3519 - val_loss: 1.7720 - val_accuracy: 0.3465\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7665 - accuracy: 0.3506 - val_loss: 1.7817 - val_accuracy: 0.3420\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7617 - accuracy: 0.3542 - val_loss: 1.7805 - val_accuracy: 0.3465\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7629 - accuracy: 0.3523 - val_loss: 1.7683 - val_accuracy: 0.3497\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7537 - accuracy: 0.3570 - val_loss: 1.7701 - val_accuracy: 0.3474\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7541 - accuracy: 0.3573 - val_loss: 1.7786 - val_accuracy: 0.3477\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7512 - accuracy: 0.3578 - val_loss: 1.7727 - val_accuracy: 0.3520\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7506 - accuracy: 0.3580 - val_loss: 1.7670 - val_accuracy: 0.3522\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7484 - accuracy: 0.3602 - val_loss: 1.7725 - val_accuracy: 0.3470\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7458 - accuracy: 0.3604 - val_loss: 1.7694 - val_accuracy: 0.3466\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.7419 - accuracy: 0.3629 - val_loss: 1.8020 - val_accuracy: 0.3278\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7387 - accuracy: 0.3629 - val_loss: 1.7589 - val_accuracy: 0.3546\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7378 - accuracy: 0.3647 - val_loss: 1.7650 - val_accuracy: 0.3484\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7373 - accuracy: 0.3636 - val_loss: 1.7633 - val_accuracy: 0.3487\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7337 - accuracy: 0.3651 - val_loss: 1.7623 - val_accuracy: 0.3547\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7354 - accuracy: 0.3640 - val_loss: 1.7761 - val_accuracy: 0.3449\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7300 - accuracy: 0.3652 - val_loss: 1.7651 - val_accuracy: 0.3467\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7330 - accuracy: 0.3652 - val_loss: 1.7541 - val_accuracy: 0.3555\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7301 - accuracy: 0.3670 - val_loss: 1.7532 - val_accuracy: 0.3514\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7311 - accuracy: 0.3657 - val_loss: 1.7524 - val_accuracy: 0.3555\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7277 - accuracy: 0.3666 - val_loss: 1.7660 - val_accuracy: 0.3514\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.7268 - accuracy: 0.3682 - val_loss: 1.7496 - val_accuracy: 0.3567\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7245 - accuracy: 0.3687 - val_loss: 1.7667 - val_accuracy: 0.3503\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7229 - accuracy: 0.3678 - val_loss: 1.7585 - val_accuracy: 0.3528\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7233 - accuracy: 0.3693 - val_loss: 1.7585 - val_accuracy: 0.3507\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7231 - accuracy: 0.3686 - val_loss: 1.7580 - val_accuracy: 0.3550\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7205 - accuracy: 0.3691 - val_loss: 1.7675 - val_accuracy: 0.3515\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7196 - accuracy: 0.3700 - val_loss: 1.7576 - val_accuracy: 0.3580\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7208 - accuracy: 0.3708 - val_loss: 1.7527 - val_accuracy: 0.3565\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.7095 - accuracy: 0.3733\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 1.7527 - accuracy: 0.3565\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 20)                61460     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 63,350\n",
      "Trainable params: 63,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "20 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 2.1127 - accuracy: 0.1725 - val_loss: 2.0497 - val_accuracy: 0.1913\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 2.0444 - accuracy: 0.1962 - val_loss: 2.0461 - val_accuracy: 0.1927\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 2.0347 - accuracy: 0.2016 - val_loss: 2.0256 - val_accuracy: 0.1992\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 2.0318 - accuracy: 0.2034 - val_loss: 2.0301 - val_accuracy: 0.1981\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 2.0267 - accuracy: 0.2040 - val_loss: 2.0175 - val_accuracy: 0.2087\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 2.0267 - accuracy: 0.2070 - val_loss: 1.9857 - val_accuracy: 0.2288\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.9493 - accuracy: 0.2573 - val_loss: 1.9166 - val_accuracy: 0.2632\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.9185 - accuracy: 0.2670 - val_loss: 1.9077 - val_accuracy: 0.2741\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.9088 - accuracy: 0.2721 - val_loss: 1.8894 - val_accuracy: 0.2762\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.9041 - accuracy: 0.2745 - val_loss: 1.9039 - val_accuracy: 0.2746\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.9022 - accuracy: 0.2755 - val_loss: 1.8959 - val_accuracy: 0.2735\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8970 - accuracy: 0.2781 - val_loss: 1.8889 - val_accuracy: 0.2815\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8967 - accuracy: 0.2772 - val_loss: 1.8809 - val_accuracy: 0.2805\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8945 - accuracy: 0.2776 - val_loss: 1.8803 - val_accuracy: 0.2844\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8914 - accuracy: 0.2810 - val_loss: 1.8849 - val_accuracy: 0.2821\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8931 - accuracy: 0.2811 - val_loss: 1.8829 - val_accuracy: 0.2807\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8895 - accuracy: 0.2831 - val_loss: 1.8821 - val_accuracy: 0.2838\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8888 - accuracy: 0.2846 - val_loss: 1.8930 - val_accuracy: 0.2814\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8879 - accuracy: 0.2850 - val_loss: 1.8763 - val_accuracy: 0.2837\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8817 - accuracy: 0.2885 - val_loss: 1.9006 - val_accuracy: 0.2793\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8844 - accuracy: 0.2855 - val_loss: 1.8772 - val_accuracy: 0.2841\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8837 - accuracy: 0.2873 - val_loss: 1.8899 - val_accuracy: 0.2757\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8842 - accuracy: 0.2884 - val_loss: 1.8783 - val_accuracy: 0.2868\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8829 - accuracy: 0.2880 - val_loss: 1.8746 - val_accuracy: 0.2859\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8830 - accuracy: 0.2868 - val_loss: 1.9024 - val_accuracy: 0.2831\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8845 - accuracy: 0.2891 - val_loss: 1.8738 - val_accuracy: 0.2844\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8794 - accuracy: 0.2924 - val_loss: 1.8800 - val_accuracy: 0.2881\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8797 - accuracy: 0.2915 - val_loss: 1.8825 - val_accuracy: 0.2828\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8788 - accuracy: 0.2924 - val_loss: 1.9192 - val_accuracy: 0.2711\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8777 - accuracy: 0.2930 - val_loss: 1.8733 - val_accuracy: 0.2904\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8762 - accuracy: 0.2933 - val_loss: 1.8763 - val_accuracy: 0.2905\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8760 - accuracy: 0.2917 - val_loss: 1.8768 - val_accuracy: 0.2902\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8799 - accuracy: 0.2918 - val_loss: 1.8735 - val_accuracy: 0.2894\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8753 - accuracy: 0.2946 - val_loss: 1.8858 - val_accuracy: 0.2863\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8779 - accuracy: 0.2940 - val_loss: 1.9071 - val_accuracy: 0.2834\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8750 - accuracy: 0.2929 - val_loss: 1.8745 - val_accuracy: 0.2947\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8746 - accuracy: 0.2969 - val_loss: 1.8816 - val_accuracy: 0.2919\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8778 - accuracy: 0.2965 - val_loss: 1.8836 - val_accuracy: 0.2870\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8746 - accuracy: 0.2949 - val_loss: 1.8873 - val_accuracy: 0.2836\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8721 - accuracy: 0.2953 - val_loss: 1.8805 - val_accuracy: 0.2876\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8739 - accuracy: 0.2969 - val_loss: 1.8727 - val_accuracy: 0.2896\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8742 - accuracy: 0.2958 - val_loss: 1.8785 - val_accuracy: 0.2892\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8720 - accuracy: 0.2986 - val_loss: 1.8761 - val_accuracy: 0.2937\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8736 - accuracy: 0.2971 - val_loss: 1.8708 - val_accuracy: 0.2912\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8714 - accuracy: 0.2973 - val_loss: 1.8799 - val_accuracy: 0.2933\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8729 - accuracy: 0.2980 - val_loss: 1.8816 - val_accuracy: 0.2914\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8707 - accuracy: 0.2976 - val_loss: 1.8742 - val_accuracy: 0.2888\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8709 - accuracy: 0.2985 - val_loss: 1.8814 - val_accuracy: 0.2870\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8692 - accuracy: 0.3001 - val_loss: 1.8787 - val_accuracy: 0.2890\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8696 - accuracy: 0.2988 - val_loss: 1.8860 - val_accuracy: 0.2902\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.8741 - accuracy: 0.2989\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 1.8860 - accuracy: 0.2902\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 30)                92190     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 96,220\n",
      "Trainable params: 96,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 2.0456 - accuracy: 0.2338 - val_loss: 1.9016 - val_accuracy: 0.2969\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8450 - accuracy: 0.3291 - val_loss: 1.8124 - val_accuracy: 0.3314\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7720 - accuracy: 0.3608 - val_loss: 1.7319 - val_accuracy: 0.3769\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7386 - accuracy: 0.3719 - val_loss: 1.7280 - val_accuracy: 0.3748\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7177 - accuracy: 0.3785 - val_loss: 1.6997 - val_accuracy: 0.3839\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7042 - accuracy: 0.3862 - val_loss: 1.6797 - val_accuracy: 0.3912\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6917 - accuracy: 0.3922 - val_loss: 1.6782 - val_accuracy: 0.3848\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6808 - accuracy: 0.3929 - val_loss: 1.6695 - val_accuracy: 0.3919\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6723 - accuracy: 0.3955 - val_loss: 1.6636 - val_accuracy: 0.3945\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.6609 - accuracy: 0.4004 - val_loss: 1.6535 - val_accuracy: 0.3986\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6599 - accuracy: 0.4020 - val_loss: 1.6803 - val_accuracy: 0.3905\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6580 - accuracy: 0.4013 - val_loss: 1.6517 - val_accuracy: 0.4017\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6548 - accuracy: 0.4012 - val_loss: 1.6664 - val_accuracy: 0.3920\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6427 - accuracy: 0.4041 - val_loss: 1.6640 - val_accuracy: 0.3983\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6434 - accuracy: 0.4044 - val_loss: 1.6421 - val_accuracy: 0.4118\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6382 - accuracy: 0.4055 - val_loss: 1.6592 - val_accuracy: 0.3982\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6345 - accuracy: 0.4093 - val_loss: 1.6583 - val_accuracy: 0.4011\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6297 - accuracy: 0.4085 - val_loss: 1.6732 - val_accuracy: 0.3951\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6338 - accuracy: 0.4082 - val_loss: 1.6951 - val_accuracy: 0.3857\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6300 - accuracy: 0.4093 - val_loss: 1.6356 - val_accuracy: 0.4083\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6243 - accuracy: 0.4121 - val_loss: 1.6624 - val_accuracy: 0.4003\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6190 - accuracy: 0.4135 - val_loss: 1.6805 - val_accuracy: 0.3938\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6198 - accuracy: 0.4143 - val_loss: 1.6312 - val_accuracy: 0.4136\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6173 - accuracy: 0.4142 - val_loss: 1.6350 - val_accuracy: 0.4115\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6150 - accuracy: 0.4161 - val_loss: 1.6536 - val_accuracy: 0.4071\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6108 - accuracy: 0.4166 - val_loss: 1.6492 - val_accuracy: 0.4027\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6094 - accuracy: 0.4166 - val_loss: 1.6597 - val_accuracy: 0.3964\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6110 - accuracy: 0.4161 - val_loss: 1.6520 - val_accuracy: 0.4021\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6072 - accuracy: 0.4171 - val_loss: 1.6559 - val_accuracy: 0.4043\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6071 - accuracy: 0.4179 - val_loss: 1.6523 - val_accuracy: 0.4020\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5989 - accuracy: 0.4203 - val_loss: 1.6316 - val_accuracy: 0.4136\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6021 - accuracy: 0.4184 - val_loss: 1.6572 - val_accuracy: 0.4021\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5968 - accuracy: 0.4197 - val_loss: 1.6452 - val_accuracy: 0.4090\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5968 - accuracy: 0.4209 - val_loss: 1.6418 - val_accuracy: 0.4103\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5983 - accuracy: 0.4187 - val_loss: 1.6349 - val_accuracy: 0.4100\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5936 - accuracy: 0.4225 - val_loss: 1.6920 - val_accuracy: 0.3857\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5903 - accuracy: 0.4225 - val_loss: 1.6533 - val_accuracy: 0.4064\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5916 - accuracy: 0.4234 - val_loss: 1.6330 - val_accuracy: 0.4112\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5928 - accuracy: 0.4226 - val_loss: 1.6330 - val_accuracy: 0.4140\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5926 - accuracy: 0.4219 - val_loss: 1.6278 - val_accuracy: 0.4144\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5884 - accuracy: 0.4198 - val_loss: 1.6620 - val_accuracy: 0.3987\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5857 - accuracy: 0.4208 - val_loss: 1.6474 - val_accuracy: 0.4041\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5830 - accuracy: 0.4268 - val_loss: 1.6492 - val_accuracy: 0.4038\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5860 - accuracy: 0.4240 - val_loss: 1.6459 - val_accuracy: 0.4120\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5877 - accuracy: 0.4265 - val_loss: 1.6372 - val_accuracy: 0.4093\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5783 - accuracy: 0.4270 - val_loss: 1.6402 - val_accuracy: 0.4103\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5816 - accuracy: 0.4242 - val_loss: 1.6326 - val_accuracy: 0.4154\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5823 - accuracy: 0.4243 - val_loss: 1.6501 - val_accuracy: 0.4046\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5760 - accuracy: 0.4282 - val_loss: 1.6385 - val_accuracy: 0.4119\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5803 - accuracy: 0.4270 - val_loss: 1.6368 - val_accuracy: 0.4093\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.5646 - accuracy: 0.4320\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6368 - accuracy: 0.4093\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 40)                122920    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                410       \n",
      "=================================================================\n",
      "Total params: 129,890\n",
      "Trainable params: 129,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "40 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.9241 - accuracy: 0.2915 - val_loss: 1.7700 - val_accuracy: 0.3605\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.7494 - accuracy: 0.3658 - val_loss: 1.6665 - val_accuracy: 0.3983\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6782 - accuracy: 0.3937 - val_loss: 1.6516 - val_accuracy: 0.4115\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6335 - accuracy: 0.4152 - val_loss: 1.5975 - val_accuracy: 0.4321\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5972 - accuracy: 0.4274 - val_loss: 1.5855 - val_accuracy: 0.4303\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5729 - accuracy: 0.4358 - val_loss: 1.5858 - val_accuracy: 0.4284\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5463 - accuracy: 0.4456 - val_loss: 1.5975 - val_accuracy: 0.4332\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5261 - accuracy: 0.4510 - val_loss: 1.5222 - val_accuracy: 0.4560\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5098 - accuracy: 0.4549 - val_loss: 1.5289 - val_accuracy: 0.4529\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5020 - accuracy: 0.4603 - val_loss: 1.4939 - val_accuracy: 0.4648\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4765 - accuracy: 0.4711 - val_loss: 1.5081 - val_accuracy: 0.4611\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4659 - accuracy: 0.4728 - val_loss: 1.5090 - val_accuracy: 0.4595\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4589 - accuracy: 0.4770 - val_loss: 1.4766 - val_accuracy: 0.4739\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4457 - accuracy: 0.4814 - val_loss: 1.4643 - val_accuracy: 0.4784\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4394 - accuracy: 0.4832 - val_loss: 1.4748 - val_accuracy: 0.4748\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4269 - accuracy: 0.4897 - val_loss: 1.4895 - val_accuracy: 0.4614\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4290 - accuracy: 0.4889 - val_loss: 1.4902 - val_accuracy: 0.4699\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4160 - accuracy: 0.4939 - val_loss: 1.4675 - val_accuracy: 0.4759\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4100 - accuracy: 0.4962 - val_loss: 1.4747 - val_accuracy: 0.4729\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3976 - accuracy: 0.5013 - val_loss: 1.4793 - val_accuracy: 0.4759\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3954 - accuracy: 0.5004 - val_loss: 1.4653 - val_accuracy: 0.4789\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3920 - accuracy: 0.5015 - val_loss: 1.4964 - val_accuracy: 0.4615\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3833 - accuracy: 0.5064 - val_loss: 1.4923 - val_accuracy: 0.4693\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3727 - accuracy: 0.5075 - val_loss: 1.4956 - val_accuracy: 0.4689\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3748 - accuracy: 0.5088 - val_loss: 1.4570 - val_accuracy: 0.4795\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3641 - accuracy: 0.5126 - val_loss: 1.4602 - val_accuracy: 0.4813\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3639 - accuracy: 0.5104 - val_loss: 1.4561 - val_accuracy: 0.4872\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3547 - accuracy: 0.5154 - val_loss: 1.4749 - val_accuracy: 0.4765\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3491 - accuracy: 0.5172 - val_loss: 1.4617 - val_accuracy: 0.4848\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3451 - accuracy: 0.5210 - val_loss: 1.4378 - val_accuracy: 0.4870\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3414 - accuracy: 0.5197 - val_loss: 1.4450 - val_accuracy: 0.4841\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3383 - accuracy: 0.5194 - val_loss: 1.4590 - val_accuracy: 0.4812\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3369 - accuracy: 0.5200 - val_loss: 1.4531 - val_accuracy: 0.4851\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3331 - accuracy: 0.5234 - val_loss: 1.4484 - val_accuracy: 0.4856\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3315 - accuracy: 0.5230 - val_loss: 1.4727 - val_accuracy: 0.4784\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3257 - accuracy: 0.5272 - val_loss: 1.4656 - val_accuracy: 0.4771\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3222 - accuracy: 0.5278 - val_loss: 1.4578 - val_accuracy: 0.4898\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3146 - accuracy: 0.5302 - val_loss: 1.4669 - val_accuracy: 0.4851\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3118 - accuracy: 0.5294 - val_loss: 1.4512 - val_accuracy: 0.4848\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3086 - accuracy: 0.5315 - val_loss: 1.4593 - val_accuracy: 0.4843\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3036 - accuracy: 0.5340 - val_loss: 1.4764 - val_accuracy: 0.4793\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3058 - accuracy: 0.5321 - val_loss: 1.4519 - val_accuracy: 0.4922\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2944 - accuracy: 0.5371 - val_loss: 1.4660 - val_accuracy: 0.4814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2929 - accuracy: 0.5372 - val_loss: 1.4677 - val_accuracy: 0.4767\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2942 - accuracy: 0.5369 - val_loss: 1.4480 - val_accuracy: 0.4923\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2938 - accuracy: 0.5358 - val_loss: 1.5000 - val_accuracy: 0.4728\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2864 - accuracy: 0.5392 - val_loss: 1.4539 - val_accuracy: 0.4878\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2880 - accuracy: 0.5402 - val_loss: 1.4390 - val_accuracy: 0.4964\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2770 - accuracy: 0.5413 - val_loss: 1.4476 - val_accuracy: 0.4912\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2765 - accuracy: 0.5428 - val_loss: 1.4861 - val_accuracy: 0.4821\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 1.2846 - accuracy: 0.5417\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 1.4861 - accuracy: 0.4821\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 50)                153650    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 164,360\n",
      "Trainable params: 164,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "50 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.9409 - accuracy: 0.2894 - val_loss: 1.7779 - val_accuracy: 0.3560\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7499 - accuracy: 0.3666 - val_loss: 1.6992 - val_accuracy: 0.3876\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6925 - accuracy: 0.3903 - val_loss: 1.6502 - val_accuracy: 0.3990\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6487 - accuracy: 0.4059 - val_loss: 1.6198 - val_accuracy: 0.4206\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6125 - accuracy: 0.4183 - val_loss: 1.6355 - val_accuracy: 0.4172\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5795 - accuracy: 0.4328 - val_loss: 1.5772 - val_accuracy: 0.4301\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5514 - accuracy: 0.4407 - val_loss: 1.5724 - val_accuracy: 0.4270\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5319 - accuracy: 0.4458 - val_loss: 1.5354 - val_accuracy: 0.4494\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5189 - accuracy: 0.4548 - val_loss: 1.5347 - val_accuracy: 0.4508\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5005 - accuracy: 0.4598 - val_loss: 1.5400 - val_accuracy: 0.4483\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4895 - accuracy: 0.4656 - val_loss: 1.5382 - val_accuracy: 0.4462\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4717 - accuracy: 0.4727 - val_loss: 1.5932 - val_accuracy: 0.4456\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4667 - accuracy: 0.4740 - val_loss: 1.5019 - val_accuracy: 0.4587\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4566 - accuracy: 0.4767 - val_loss: 1.5123 - val_accuracy: 0.4595\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4499 - accuracy: 0.4774 - val_loss: 1.5209 - val_accuracy: 0.4525\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4350 - accuracy: 0.4834 - val_loss: 1.5387 - val_accuracy: 0.4490\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4248 - accuracy: 0.4871 - val_loss: 1.5182 - val_accuracy: 0.4597\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4201 - accuracy: 0.4870 - val_loss: 1.4839 - val_accuracy: 0.4678\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4053 - accuracy: 0.4961 - val_loss: 1.5025 - val_accuracy: 0.4715\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4017 - accuracy: 0.4959 - val_loss: 1.4686 - val_accuracy: 0.4733\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3967 - accuracy: 0.4991 - val_loss: 1.4576 - val_accuracy: 0.4784\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3840 - accuracy: 0.5042 - val_loss: 1.5086 - val_accuracy: 0.4612\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3798 - accuracy: 0.5037 - val_loss: 1.4890 - val_accuracy: 0.4690\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3685 - accuracy: 0.5075 - val_loss: 1.4701 - val_accuracy: 0.4771\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3666 - accuracy: 0.5077 - val_loss: 1.4688 - val_accuracy: 0.4814\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3584 - accuracy: 0.5127 - val_loss: 1.4739 - val_accuracy: 0.4812\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3509 - accuracy: 0.5159 - val_loss: 1.4620 - val_accuracy: 0.4802\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3530 - accuracy: 0.5154 - val_loss: 1.4445 - val_accuracy: 0.4841\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3391 - accuracy: 0.5187 - val_loss: 1.4731 - val_accuracy: 0.4751\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3421 - accuracy: 0.5194 - val_loss: 1.4568 - val_accuracy: 0.4817\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3413 - accuracy: 0.5159 - val_loss: 1.4785 - val_accuracy: 0.4766\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3266 - accuracy: 0.5227 - val_loss: 1.4583 - val_accuracy: 0.4851\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3262 - accuracy: 0.5237 - val_loss: 1.4622 - val_accuracy: 0.4857\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3243 - accuracy: 0.5245 - val_loss: 1.4711 - val_accuracy: 0.4829\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3164 - accuracy: 0.5266 - val_loss: 1.4489 - val_accuracy: 0.4876\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3143 - accuracy: 0.5287 - val_loss: 1.4922 - val_accuracy: 0.4708\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3071 - accuracy: 0.5308 - val_loss: 1.4774 - val_accuracy: 0.4745\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3117 - accuracy: 0.5288 - val_loss: 1.4451 - val_accuracy: 0.4898\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3005 - accuracy: 0.5330 - val_loss: 1.4726 - val_accuracy: 0.4767\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2904 - accuracy: 0.5356 - val_loss: 1.4515 - val_accuracy: 0.4871\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2923 - accuracy: 0.5353 - val_loss: 1.4669 - val_accuracy: 0.4841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2915 - accuracy: 0.5375 - val_loss: 1.4710 - val_accuracy: 0.4813\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2897 - accuracy: 0.5350 - val_loss: 1.4455 - val_accuracy: 0.4858\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2831 - accuracy: 0.5379 - val_loss: 1.4687 - val_accuracy: 0.4808\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2806 - accuracy: 0.5412 - val_loss: 1.4822 - val_accuracy: 0.4812\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2735 - accuracy: 0.5424 - val_loss: 1.4762 - val_accuracy: 0.4848\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2746 - accuracy: 0.5441 - val_loss: 1.4898 - val_accuracy: 0.4729\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2690 - accuracy: 0.5416 - val_loss: 1.4686 - val_accuracy: 0.4872\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2646 - accuracy: 0.5450 - val_loss: 1.4728 - val_accuracy: 0.4883\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2591 - accuracy: 0.5485 - val_loss: 1.4830 - val_accuracy: 0.4784\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 1.2658 - accuracy: 0.5433\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 1.4830 - accuracy: 0.4784\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 60)                184380    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 199,630\n",
      "Trainable params: 199,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "60 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.9308 - accuracy: 0.2887 - val_loss: 1.7896 - val_accuracy: 0.3560\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7375 - accuracy: 0.3710 - val_loss: 1.7187 - val_accuracy: 0.3842\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6518 - accuracy: 0.4030 - val_loss: 1.6514 - val_accuracy: 0.4065\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6065 - accuracy: 0.4214 - val_loss: 1.6163 - val_accuracy: 0.4236\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5694 - accuracy: 0.4381 - val_loss: 1.5701 - val_accuracy: 0.4295\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5405 - accuracy: 0.4493 - val_loss: 1.5226 - val_accuracy: 0.4572\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5240 - accuracy: 0.4522 - val_loss: 1.5283 - val_accuracy: 0.4607\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5001 - accuracy: 0.4611 - val_loss: 1.5550 - val_accuracy: 0.4442\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4804 - accuracy: 0.4707 - val_loss: 1.4842 - val_accuracy: 0.4759\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4691 - accuracy: 0.4719 - val_loss: 1.5212 - val_accuracy: 0.4562\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4566 - accuracy: 0.4791 - val_loss: 1.5250 - val_accuracy: 0.4555\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4467 - accuracy: 0.4825 - val_loss: 1.4751 - val_accuracy: 0.4802\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4311 - accuracy: 0.4874 - val_loss: 1.4838 - val_accuracy: 0.4764\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4180 - accuracy: 0.4892 - val_loss: 1.4684 - val_accuracy: 0.4762\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4073 - accuracy: 0.4965 - val_loss: 1.4641 - val_accuracy: 0.4778\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4035 - accuracy: 0.4958 - val_loss: 1.4807 - val_accuracy: 0.4695\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3901 - accuracy: 0.5029 - val_loss: 1.4816 - val_accuracy: 0.4784\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3823 - accuracy: 0.5040 - val_loss: 1.4645 - val_accuracy: 0.4798\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3812 - accuracy: 0.5021 - val_loss: 1.4755 - val_accuracy: 0.4699\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3670 - accuracy: 0.5084 - val_loss: 1.4520 - val_accuracy: 0.4842\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3617 - accuracy: 0.5099 - val_loss: 1.4821 - val_accuracy: 0.4729\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3516 - accuracy: 0.5139 - val_loss: 1.4679 - val_accuracy: 0.4769\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3430 - accuracy: 0.5187 - val_loss: 1.4688 - val_accuracy: 0.4850\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3349 - accuracy: 0.5183 - val_loss: 1.4674 - val_accuracy: 0.4819\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3309 - accuracy: 0.5198 - val_loss: 1.4343 - val_accuracy: 0.4931\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3250 - accuracy: 0.5235 - val_loss: 1.4566 - val_accuracy: 0.4870\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3167 - accuracy: 0.5264 - val_loss: 1.4582 - val_accuracy: 0.4844\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3120 - accuracy: 0.5256 - val_loss: 1.4768 - val_accuracy: 0.4767\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3049 - accuracy: 0.5294 - val_loss: 1.4809 - val_accuracy: 0.4824\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3030 - accuracy: 0.5313 - val_loss: 1.4547 - val_accuracy: 0.4862\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2955 - accuracy: 0.5344 - val_loss: 1.4872 - val_accuracy: 0.4799\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2935 - accuracy: 0.5346 - val_loss: 1.4470 - val_accuracy: 0.4925\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2854 - accuracy: 0.5376 - val_loss: 1.4828 - val_accuracy: 0.4738\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2795 - accuracy: 0.5404 - val_loss: 1.4650 - val_accuracy: 0.4826\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2786 - accuracy: 0.5403 - val_loss: 1.4914 - val_accuracy: 0.4748\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2750 - accuracy: 0.5403 - val_loss: 1.4717 - val_accuracy: 0.4874\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2657 - accuracy: 0.5448 - val_loss: 1.4681 - val_accuracy: 0.4829\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2650 - accuracy: 0.5463 - val_loss: 1.4566 - val_accuracy: 0.4920\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2559 - accuracy: 0.5458 - val_loss: 1.5281 - val_accuracy: 0.4694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2535 - accuracy: 0.5510 - val_loss: 1.4808 - val_accuracy: 0.4796\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2450 - accuracy: 0.5520 - val_loss: 1.4473 - val_accuracy: 0.4912\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2528 - accuracy: 0.5469 - val_loss: 1.4761 - val_accuracy: 0.4794\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2446 - accuracy: 0.5538 - val_loss: 1.4695 - val_accuracy: 0.4866\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2430 - accuracy: 0.5548 - val_loss: 1.4906 - val_accuracy: 0.4822\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2390 - accuracy: 0.5543 - val_loss: 1.4830 - val_accuracy: 0.4825\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2294 - accuracy: 0.5579 - val_loss: 1.4718 - val_accuracy: 0.4838\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2273 - accuracy: 0.5585 - val_loss: 1.4543 - val_accuracy: 0.4943\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2226 - accuracy: 0.5611 - val_loss: 1.5084 - val_accuracy: 0.4776\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2225 - accuracy: 0.5591 - val_loss: 1.4701 - val_accuracy: 0.4881\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2239 - accuracy: 0.5610 - val_loss: 1.4630 - val_accuracy: 0.4920\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 1.1786 - accuracy: 0.5780\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 1.4630 - accuracy: 0.4920\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 70)                215110    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                710       \n",
      "=================================================================\n",
      "Total params: 235,700\n",
      "Trainable params: 235,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "70 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.9017 - accuracy: 0.3060 - val_loss: 1.7293 - val_accuracy: 0.3801\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7218 - accuracy: 0.3807 - val_loss: 1.6723 - val_accuracy: 0.3945\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6519 - accuracy: 0.4030 - val_loss: 1.5923 - val_accuracy: 0.4231\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5969 - accuracy: 0.4254 - val_loss: 1.5611 - val_accuracy: 0.4391\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.5548 - accuracy: 0.4413 - val_loss: 1.5949 - val_accuracy: 0.4197\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5308 - accuracy: 0.4490 - val_loss: 1.5881 - val_accuracy: 0.4332\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5016 - accuracy: 0.4589 - val_loss: 1.5126 - val_accuracy: 0.4563\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4852 - accuracy: 0.4670 - val_loss: 1.5117 - val_accuracy: 0.4609\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4615 - accuracy: 0.4743 - val_loss: 1.5038 - val_accuracy: 0.4616\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4443 - accuracy: 0.4840 - val_loss: 1.4803 - val_accuracy: 0.4678\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4286 - accuracy: 0.4862 - val_loss: 1.4733 - val_accuracy: 0.4737\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4080 - accuracy: 0.4952 - val_loss: 1.4779 - val_accuracy: 0.4757\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3875 - accuracy: 0.5007 - val_loss: 1.4830 - val_accuracy: 0.4713\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3782 - accuracy: 0.5036 - val_loss: 1.5168 - val_accuracy: 0.4568\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3716 - accuracy: 0.5062 - val_loss: 1.4568 - val_accuracy: 0.4782\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3546 - accuracy: 0.5127 - val_loss: 1.4385 - val_accuracy: 0.4910\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3497 - accuracy: 0.5146 - val_loss: 1.4557 - val_accuracy: 0.4827\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3386 - accuracy: 0.5175 - val_loss: 1.4259 - val_accuracy: 0.4987\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3245 - accuracy: 0.5244 - val_loss: 1.4184 - val_accuracy: 0.5020\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3208 - accuracy: 0.5253 - val_loss: 1.4246 - val_accuracy: 0.4968\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3049 - accuracy: 0.5314 - val_loss: 1.4255 - val_accuracy: 0.4941\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2928 - accuracy: 0.5377 - val_loss: 1.4452 - val_accuracy: 0.4886\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2918 - accuracy: 0.5344 - val_loss: 1.4523 - val_accuracy: 0.4829\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2837 - accuracy: 0.5389 - val_loss: 1.4392 - val_accuracy: 0.4907\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2688 - accuracy: 0.5427 - val_loss: 1.4381 - val_accuracy: 0.4908\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2686 - accuracy: 0.5449 - val_loss: 1.4566 - val_accuracy: 0.4869\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2593 - accuracy: 0.5465 - val_loss: 1.4232 - val_accuracy: 0.4994\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2530 - accuracy: 0.5480 - val_loss: 1.4360 - val_accuracy: 0.4968\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2460 - accuracy: 0.5531 - val_loss: 1.4501 - val_accuracy: 0.4907\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2405 - accuracy: 0.5535 - val_loss: 1.4476 - val_accuracy: 0.4916\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2322 - accuracy: 0.5552 - val_loss: 1.4230 - val_accuracy: 0.5004\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2250 - accuracy: 0.5599 - val_loss: 1.4389 - val_accuracy: 0.4951\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2265 - accuracy: 0.5587 - val_loss: 1.4606 - val_accuracy: 0.4914\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2131 - accuracy: 0.5644 - val_loss: 1.4341 - val_accuracy: 0.5014\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2100 - accuracy: 0.5655 - val_loss: 1.4375 - val_accuracy: 0.4894\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2044 - accuracy: 0.5655 - val_loss: 1.4403 - val_accuracy: 0.4932\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1935 - accuracy: 0.5691 - val_loss: 1.4285 - val_accuracy: 0.5012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1931 - accuracy: 0.5707 - val_loss: 1.4460 - val_accuracy: 0.5015\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1801 - accuracy: 0.5723 - val_loss: 1.4566 - val_accuracy: 0.4938\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1875 - accuracy: 0.5690 - val_loss: 1.4278 - val_accuracy: 0.5014\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1742 - accuracy: 0.5760 - val_loss: 1.4479 - val_accuracy: 0.4953\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1681 - accuracy: 0.5804 - val_loss: 1.4604 - val_accuracy: 0.4923\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1685 - accuracy: 0.5801 - val_loss: 1.4431 - val_accuracy: 0.5040\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1534 - accuracy: 0.5856 - val_loss: 1.4519 - val_accuracy: 0.4966\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1566 - accuracy: 0.5834 - val_loss: 1.4833 - val_accuracy: 0.4929\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1458 - accuracy: 0.5870 - val_loss: 1.4589 - val_accuracy: 0.4959\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1462 - accuracy: 0.5870 - val_loss: 1.4596 - val_accuracy: 0.5035\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1414 - accuracy: 0.5885 - val_loss: 1.4789 - val_accuracy: 0.5012\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1390 - accuracy: 0.5903 - val_loss: 1.4750 - val_accuracy: 0.4944\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1327 - accuracy: 0.5932 - val_loss: 1.5171 - val_accuracy: 0.4857\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 1.1404 - accuracy: 0.5874\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 1.5171 - accuracy: 0.4857\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 80)                245840    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 272,570\n",
      "Trainable params: 272,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.9041 - accuracy: 0.3029 - val_loss: 1.7573 - val_accuracy: 0.3678\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7163 - accuracy: 0.3792 - val_loss: 1.6627 - val_accuracy: 0.3994\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6475 - accuracy: 0.4094 - val_loss: 1.6388 - val_accuracy: 0.4106\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5841 - accuracy: 0.4321 - val_loss: 1.5615 - val_accuracy: 0.4403\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5416 - accuracy: 0.4464 - val_loss: 1.5219 - val_accuracy: 0.4535\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5171 - accuracy: 0.4556 - val_loss: 1.5196 - val_accuracy: 0.4561\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4810 - accuracy: 0.4692 - val_loss: 1.4848 - val_accuracy: 0.4675\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4589 - accuracy: 0.4762 - val_loss: 1.4983 - val_accuracy: 0.4655\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4325 - accuracy: 0.4852 - val_loss: 1.4545 - val_accuracy: 0.4846\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4218 - accuracy: 0.4899 - val_loss: 1.4706 - val_accuracy: 0.4738\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4015 - accuracy: 0.4977 - val_loss: 1.4401 - val_accuracy: 0.4845\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3822 - accuracy: 0.5060 - val_loss: 1.4607 - val_accuracy: 0.4762\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3659 - accuracy: 0.5103 - val_loss: 1.4607 - val_accuracy: 0.4860\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3581 - accuracy: 0.5146 - val_loss: 1.4483 - val_accuracy: 0.4862\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3333 - accuracy: 0.5218 - val_loss: 1.4139 - val_accuracy: 0.5007\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3189 - accuracy: 0.5296 - val_loss: 1.4120 - val_accuracy: 0.5016\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3133 - accuracy: 0.5311 - val_loss: 1.4358 - val_accuracy: 0.4888\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2943 - accuracy: 0.5374 - val_loss: 1.4432 - val_accuracy: 0.4960\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2894 - accuracy: 0.5379 - val_loss: 1.4433 - val_accuracy: 0.4958\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2748 - accuracy: 0.5440 - val_loss: 1.4492 - val_accuracy: 0.4875\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2725 - accuracy: 0.5434 - val_loss: 1.4176 - val_accuracy: 0.4988\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2494 - accuracy: 0.5513 - val_loss: 1.4542 - val_accuracy: 0.4892\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2443 - accuracy: 0.5562 - val_loss: 1.4246 - val_accuracy: 0.5004\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2361 - accuracy: 0.5557 - val_loss: 1.4034 - val_accuracy: 0.5065\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2211 - accuracy: 0.5632 - val_loss: 1.4371 - val_accuracy: 0.4947\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2170 - accuracy: 0.5628 - val_loss: 1.4103 - val_accuracy: 0.5081\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2066 - accuracy: 0.5685 - val_loss: 1.4415 - val_accuracy: 0.4958\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2003 - accuracy: 0.5700 - val_loss: 1.4632 - val_accuracy: 0.4975\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1932 - accuracy: 0.5739 - val_loss: 1.4234 - val_accuracy: 0.5093\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1783 - accuracy: 0.5748 - val_loss: 1.4470 - val_accuracy: 0.5010\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1743 - accuracy: 0.5783 - val_loss: 1.4129 - val_accuracy: 0.5142\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1713 - accuracy: 0.5788 - val_loss: 1.4649 - val_accuracy: 0.4901\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1549 - accuracy: 0.5839 - val_loss: 1.4505 - val_accuracy: 0.4967\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1526 - accuracy: 0.5853 - val_loss: 1.4608 - val_accuracy: 0.5012\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1411 - accuracy: 0.5895 - val_loss: 1.4603 - val_accuracy: 0.4979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1342 - accuracy: 0.5937 - val_loss: 1.4317 - val_accuracy: 0.5042\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1382 - accuracy: 0.5913 - val_loss: 1.4419 - val_accuracy: 0.5011\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1154 - accuracy: 0.5970 - val_loss: 1.4881 - val_accuracy: 0.4909\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1147 - accuracy: 0.5974 - val_loss: 1.4797 - val_accuracy: 0.4995\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1162 - accuracy: 0.5944 - val_loss: 1.4616 - val_accuracy: 0.4964\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1048 - accuracy: 0.6028 - val_loss: 1.4791 - val_accuracy: 0.5016\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0961 - accuracy: 0.6043 - val_loss: 1.4813 - val_accuracy: 0.4926\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0849 - accuracy: 0.6100 - val_loss: 1.4882 - val_accuracy: 0.4980\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0835 - accuracy: 0.6092 - val_loss: 1.4871 - val_accuracy: 0.5055\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0773 - accuracy: 0.6093 - val_loss: 1.5038 - val_accuracy: 0.4900\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0659 - accuracy: 0.6163 - val_loss: 1.5165 - val_accuracy: 0.4905\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0737 - accuracy: 0.6142 - val_loss: 1.5147 - val_accuracy: 0.4912\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0633 - accuracy: 0.6156 - val_loss: 1.5127 - val_accuracy: 0.4905\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0646 - accuracy: 0.6130 - val_loss: 1.5116 - val_accuracy: 0.4954\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0600 - accuracy: 0.6177 - val_loss: 1.4993 - val_accuracy: 0.4978\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.9807 - accuracy: 0.6491\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 1.4993 - accuracy: 0.4978\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 90)                276570    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 90)                8190      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 90)                8190      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 90)                8190      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 90)                8190      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                910       \n",
      "=================================================================\n",
      "Total params: 310,240\n",
      "Trainable params: 310,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "90 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.9071 - accuracy: 0.3035 - val_loss: 1.7418 - val_accuracy: 0.3690\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7130 - accuracy: 0.3807 - val_loss: 1.6500 - val_accuracy: 0.4023\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.6245 - accuracy: 0.4150 - val_loss: 1.6000 - val_accuracy: 0.4267\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5657 - accuracy: 0.4377 - val_loss: 1.5568 - val_accuracy: 0.4400\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.5280 - accuracy: 0.4533 - val_loss: 1.5552 - val_accuracy: 0.4429\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4932 - accuracy: 0.4652 - val_loss: 1.5226 - val_accuracy: 0.4561\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4701 - accuracy: 0.4727 - val_loss: 1.4998 - val_accuracy: 0.4580\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4426 - accuracy: 0.4814 - val_loss: 1.4685 - val_accuracy: 0.4850\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4287 - accuracy: 0.4881 - val_loss: 1.4651 - val_accuracy: 0.4818\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3981 - accuracy: 0.4982 - val_loss: 1.4709 - val_accuracy: 0.4763\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3774 - accuracy: 0.5062 - val_loss: 1.4684 - val_accuracy: 0.4781\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3697 - accuracy: 0.5066 - val_loss: 1.4396 - val_accuracy: 0.4891\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3510 - accuracy: 0.5148 - val_loss: 1.4283 - val_accuracy: 0.4870\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3357 - accuracy: 0.5215 - val_loss: 1.4611 - val_accuracy: 0.4798\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3259 - accuracy: 0.5247 - val_loss: 1.4093 - val_accuracy: 0.4970\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3067 - accuracy: 0.5306 - val_loss: 1.4799 - val_accuracy: 0.4735\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2967 - accuracy: 0.5322 - val_loss: 1.4397 - val_accuracy: 0.4897\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2828 - accuracy: 0.5386 - val_loss: 1.4284 - val_accuracy: 0.4949\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2721 - accuracy: 0.5444 - val_loss: 1.4133 - val_accuracy: 0.5029\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2563 - accuracy: 0.5474 - val_loss: 1.4130 - val_accuracy: 0.5024\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2516 - accuracy: 0.5499 - val_loss: 1.4328 - val_accuracy: 0.4924\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2312 - accuracy: 0.5564 - val_loss: 1.4445 - val_accuracy: 0.4885\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2211 - accuracy: 0.5597 - val_loss: 1.4145 - val_accuracy: 0.5064\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2080 - accuracy: 0.5652 - val_loss: 1.4125 - val_accuracy: 0.5069\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1957 - accuracy: 0.5692 - val_loss: 1.4302 - val_accuracy: 0.5024\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1981 - accuracy: 0.5685 - val_loss: 1.4264 - val_accuracy: 0.5036\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1812 - accuracy: 0.5736 - val_loss: 1.4438 - val_accuracy: 0.4950\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1672 - accuracy: 0.5781 - val_loss: 1.4352 - val_accuracy: 0.5031\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1576 - accuracy: 0.5838 - val_loss: 1.4510 - val_accuracy: 0.5032\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1496 - accuracy: 0.5855 - val_loss: 1.4443 - val_accuracy: 0.5043\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1419 - accuracy: 0.5868 - val_loss: 1.4335 - val_accuracy: 0.5057\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1339 - accuracy: 0.5916 - val_loss: 1.4539 - val_accuracy: 0.5034\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1195 - accuracy: 0.5984 - val_loss: 1.4857 - val_accuracy: 0.4914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1147 - accuracy: 0.5992 - val_loss: 1.4914 - val_accuracy: 0.4987\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1157 - accuracy: 0.5964 - val_loss: 1.4891 - val_accuracy: 0.4950\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0965 - accuracy: 0.6038 - val_loss: 1.4462 - val_accuracy: 0.5064\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0918 - accuracy: 0.6056 - val_loss: 1.4826 - val_accuracy: 0.4980\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0817 - accuracy: 0.6093 - val_loss: 1.4821 - val_accuracy: 0.5028\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0830 - accuracy: 0.6088 - val_loss: 1.4816 - val_accuracy: 0.4996\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0691 - accuracy: 0.6136 - val_loss: 1.5056 - val_accuracy: 0.4927\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0643 - accuracy: 0.6144 - val_loss: 1.5078 - val_accuracy: 0.4972\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0411 - accuracy: 0.6206 - val_loss: 1.5252 - val_accuracy: 0.4947\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0505 - accuracy: 0.6196 - val_loss: 1.5084 - val_accuracy: 0.4954\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0354 - accuracy: 0.6263 - val_loss: 1.5068 - val_accuracy: 0.4991\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0295 - accuracy: 0.6264 - val_loss: 1.5056 - val_accuracy: 0.5032\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0273 - accuracy: 0.6313 - val_loss: 1.5293 - val_accuracy: 0.5007\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0172 - accuracy: 0.6312 - val_loss: 1.5361 - val_accuracy: 0.5047\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0103 - accuracy: 0.6359 - val_loss: 1.5327 - val_accuracy: 0.4979\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0039 - accuracy: 0.6368 - val_loss: 1.5273 - val_accuracy: 0.5005\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9936 - accuracy: 0.6418 - val_loss: 1.5327 - val_accuracy: 0.5052\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.9337 - accuracy: 0.6629\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5327 - accuracy: 0.5052\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 348,710\n",
      "Trainable params: 348,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.9121 - accuracy: 0.2977 - val_loss: 1.7491 - val_accuracy: 0.3670\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.7080 - accuracy: 0.3843 - val_loss: 1.6264 - val_accuracy: 0.4111\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.6376 - accuracy: 0.4113 - val_loss: 1.5949 - val_accuracy: 0.4311\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.5739 - accuracy: 0.4328 - val_loss: 1.5561 - val_accuracy: 0.4391\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.5413 - accuracy: 0.4463 - val_loss: 1.5523 - val_accuracy: 0.4456\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.5002 - accuracy: 0.4621 - val_loss: 1.5144 - val_accuracy: 0.4613\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4742 - accuracy: 0.4721 - val_loss: 1.4821 - val_accuracy: 0.4684\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4527 - accuracy: 0.4771 - val_loss: 1.5558 - val_accuracy: 0.4445\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4350 - accuracy: 0.4844 - val_loss: 1.4862 - val_accuracy: 0.4677\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4178 - accuracy: 0.4901 - val_loss: 1.4674 - val_accuracy: 0.4738\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3935 - accuracy: 0.5014 - val_loss: 1.4663 - val_accuracy: 0.4734\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3894 - accuracy: 0.5021 - val_loss: 1.4638 - val_accuracy: 0.4775\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3665 - accuracy: 0.5100 - val_loss: 1.4386 - val_accuracy: 0.4856\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3474 - accuracy: 0.5182 - val_loss: 1.4436 - val_accuracy: 0.4833\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3285 - accuracy: 0.5236 - val_loss: 1.4531 - val_accuracy: 0.4843\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3181 - accuracy: 0.5267 - val_loss: 1.4489 - val_accuracy: 0.4872\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3100 - accuracy: 0.5301 - val_loss: 1.4424 - val_accuracy: 0.4865\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2831 - accuracy: 0.5400 - val_loss: 1.4261 - val_accuracy: 0.4998\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2745 - accuracy: 0.5442 - val_loss: 1.4472 - val_accuracy: 0.4903\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2638 - accuracy: 0.5473 - val_loss: 1.4377 - val_accuracy: 0.4888\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2465 - accuracy: 0.5544 - val_loss: 1.4388 - val_accuracy: 0.4956\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2321 - accuracy: 0.5575 - val_loss: 1.4207 - val_accuracy: 0.5050\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2224 - accuracy: 0.5617 - val_loss: 1.4529 - val_accuracy: 0.4916\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2111 - accuracy: 0.5632 - val_loss: 1.4263 - val_accuracy: 0.4987\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1919 - accuracy: 0.5725 - val_loss: 1.4471 - val_accuracy: 0.4963\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1912 - accuracy: 0.5694 - val_loss: 1.4495 - val_accuracy: 0.5002\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1706 - accuracy: 0.5758 - val_loss: 1.4367 - val_accuracy: 0.4990\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1691 - accuracy: 0.5801 - val_loss: 1.4632 - val_accuracy: 0.4917\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1592 - accuracy: 0.5801 - val_loss: 1.4725 - val_accuracy: 0.4939\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1471 - accuracy: 0.5830 - val_loss: 1.4867 - val_accuracy: 0.4900\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1284 - accuracy: 0.5944 - val_loss: 1.4513 - val_accuracy: 0.5002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1198 - accuracy: 0.5960 - val_loss: 1.4644 - val_accuracy: 0.4989\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1148 - accuracy: 0.5954 - val_loss: 1.4759 - val_accuracy: 0.5045\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1086 - accuracy: 0.6020 - val_loss: 1.5012 - val_accuracy: 0.4957\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0960 - accuracy: 0.6043 - val_loss: 1.5225 - val_accuracy: 0.4951\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0883 - accuracy: 0.6082 - val_loss: 1.4970 - val_accuracy: 0.4963\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0698 - accuracy: 0.6136 - val_loss: 1.5037 - val_accuracy: 0.4942\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0606 - accuracy: 0.6153 - val_loss: 1.5247 - val_accuracy: 0.5012\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0535 - accuracy: 0.6220 - val_loss: 1.5138 - val_accuracy: 0.4985\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0459 - accuracy: 0.6225 - val_loss: 1.5345 - val_accuracy: 0.4971\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0215 - accuracy: 0.6284 - val_loss: 1.5261 - val_accuracy: 0.5092\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0282 - accuracy: 0.6273 - val_loss: 1.5631 - val_accuracy: 0.4983\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0188 - accuracy: 0.6303 - val_loss: 1.6033 - val_accuracy: 0.4805\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0143 - accuracy: 0.6321 - val_loss: 1.5402 - val_accuracy: 0.4987\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9982 - accuracy: 0.6407 - val_loss: 1.5950 - val_accuracy: 0.4967\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9974 - accuracy: 0.6365 - val_loss: 1.5630 - val_accuracy: 0.4991\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9772 - accuracy: 0.6455 - val_loss: 1.6088 - val_accuracy: 0.4985\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9744 - accuracy: 0.6464 - val_loss: 1.6195 - val_accuracy: 0.4945\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9714 - accuracy: 0.6475 - val_loss: 1.5981 - val_accuracy: 0.4911\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9675 - accuracy: 0.6493 - val_loss: 1.6227 - val_accuracy: 0.4924\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.9327 - accuracy: 0.6621\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6227 - accuracy: 0.4924\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 110)               338030    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 110)               12210     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 110)               12210     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 110)               12210     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 110)               12210     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1110      \n",
      "=================================================================\n",
      "Total params: 387,980\n",
      "Trainable params: 387,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "110 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.8898 - accuracy: 0.3095 - val_loss: 1.7134 - val_accuracy: 0.3797\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.6981 - accuracy: 0.3895 - val_loss: 1.6406 - val_accuracy: 0.4031\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.6198 - accuracy: 0.4180 - val_loss: 1.5879 - val_accuracy: 0.4253\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.5738 - accuracy: 0.4334 - val_loss: 1.5402 - val_accuracy: 0.4421\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.5253 - accuracy: 0.4524 - val_loss: 1.5622 - val_accuracy: 0.4382\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4898 - accuracy: 0.4642 - val_loss: 1.5273 - val_accuracy: 0.4538\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4603 - accuracy: 0.4768 - val_loss: 1.4816 - val_accuracy: 0.4705\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4419 - accuracy: 0.4827 - val_loss: 1.4739 - val_accuracy: 0.4744\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4182 - accuracy: 0.4868 - val_loss: 1.4913 - val_accuracy: 0.4679\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3948 - accuracy: 0.4997 - val_loss: 1.4525 - val_accuracy: 0.4827\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3729 - accuracy: 0.5083 - val_loss: 1.4482 - val_accuracy: 0.4881\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3602 - accuracy: 0.5120 - val_loss: 1.4555 - val_accuracy: 0.4796\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3352 - accuracy: 0.5195 - val_loss: 1.4738 - val_accuracy: 0.4773\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3268 - accuracy: 0.5235 - val_loss: 1.4399 - val_accuracy: 0.4918\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3023 - accuracy: 0.5343 - val_loss: 1.4726 - val_accuracy: 0.4797\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2837 - accuracy: 0.5396 - val_loss: 1.4027 - val_accuracy: 0.5097\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2692 - accuracy: 0.5440 - val_loss: 1.4087 - val_accuracy: 0.5047\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2557 - accuracy: 0.5459 - val_loss: 1.4216 - val_accuracy: 0.5072\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2349 - accuracy: 0.5566 - val_loss: 1.4318 - val_accuracy: 0.5010\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2188 - accuracy: 0.5624 - val_loss: 1.4552 - val_accuracy: 0.4934\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2089 - accuracy: 0.5657 - val_loss: 1.4376 - val_accuracy: 0.4991\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1957 - accuracy: 0.5678 - val_loss: 1.4480 - val_accuracy: 0.4936\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1807 - accuracy: 0.5748 - val_loss: 1.4451 - val_accuracy: 0.5040\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1694 - accuracy: 0.5785 - val_loss: 1.4548 - val_accuracy: 0.4964\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1605 - accuracy: 0.5834 - val_loss: 1.4731 - val_accuracy: 0.4902\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1399 - accuracy: 0.5897 - val_loss: 1.4401 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1343 - accuracy: 0.5893 - val_loss: 1.4516 - val_accuracy: 0.4998\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1157 - accuracy: 0.5991 - val_loss: 1.4851 - val_accuracy: 0.4923\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0984 - accuracy: 0.6023 - val_loss: 1.4833 - val_accuracy: 0.4984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0935 - accuracy: 0.6029 - val_loss: 1.4994 - val_accuracy: 0.4983\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0930 - accuracy: 0.6056 - val_loss: 1.4902 - val_accuracy: 0.5037\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0689 - accuracy: 0.6130 - val_loss: 1.4902 - val_accuracy: 0.4971\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0655 - accuracy: 0.6147 - val_loss: 1.4923 - val_accuracy: 0.4989\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0471 - accuracy: 0.6232 - val_loss: 1.5273 - val_accuracy: 0.4910\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0394 - accuracy: 0.6240 - val_loss: 1.5110 - val_accuracy: 0.4987\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0291 - accuracy: 0.6294 - val_loss: 1.5277 - val_accuracy: 0.4994\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0268 - accuracy: 0.6273 - val_loss: 1.5169 - val_accuracy: 0.5005\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0062 - accuracy: 0.6359 - val_loss: 1.5467 - val_accuracy: 0.4896\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0044 - accuracy: 0.6340 - val_loss: 1.5434 - val_accuracy: 0.4906\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9839 - accuracy: 0.6426 - val_loss: 1.5304 - val_accuracy: 0.4966\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9717 - accuracy: 0.6465 - val_loss: 1.6008 - val_accuracy: 0.4943\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9586 - accuracy: 0.6511 - val_loss: 1.5854 - val_accuracy: 0.5026\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9515 - accuracy: 0.6543 - val_loss: 1.5917 - val_accuracy: 0.4865\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9558 - accuracy: 0.6538 - val_loss: 1.6146 - val_accuracy: 0.4981\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9432 - accuracy: 0.6576 - val_loss: 1.6262 - val_accuracy: 0.4990\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9265 - accuracy: 0.6641 - val_loss: 1.5952 - val_accuracy: 0.4981\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9200 - accuracy: 0.6654 - val_loss: 1.6800 - val_accuracy: 0.4878\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9137 - accuracy: 0.6682 - val_loss: 1.7278 - val_accuracy: 0.4884\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9031 - accuracy: 0.6703 - val_loss: 1.6303 - val_accuracy: 0.5006\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.8895 - accuracy: 0.6749 - val_loss: 1.6743 - val_accuracy: 0.4879\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8705 - accuracy: 0.6823\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6743 - accuracy: 0.4879\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 120)               368760    \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1210      \n",
      "=================================================================\n",
      "Total params: 428,050\n",
      "Trainable params: 428,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "120 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.8921 - accuracy: 0.3099 - val_loss: 1.7322 - val_accuracy: 0.3707\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.7109 - accuracy: 0.3835 - val_loss: 1.6458 - val_accuracy: 0.4092\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.6289 - accuracy: 0.4126 - val_loss: 1.6114 - val_accuracy: 0.4254\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.5670 - accuracy: 0.4356 - val_loss: 1.5904 - val_accuracy: 0.4321\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.5289 - accuracy: 0.4483 - val_loss: 1.5610 - val_accuracy: 0.4433\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4862 - accuracy: 0.4634 - val_loss: 1.5414 - val_accuracy: 0.4488\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4626 - accuracy: 0.4729 - val_loss: 1.4923 - val_accuracy: 0.4641\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4362 - accuracy: 0.4831 - val_loss: 1.4957 - val_accuracy: 0.4671\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.4120 - accuracy: 0.4934 - val_loss: 1.4837 - val_accuracy: 0.4762\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3960 - accuracy: 0.4976 - val_loss: 1.4532 - val_accuracy: 0.4790\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3758 - accuracy: 0.5046 - val_loss: 1.4414 - val_accuracy: 0.4845\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3544 - accuracy: 0.5136 - val_loss: 1.4796 - val_accuracy: 0.4780\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3350 - accuracy: 0.5188 - val_loss: 1.4650 - val_accuracy: 0.4852\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3218 - accuracy: 0.5259 - val_loss: 1.4268 - val_accuracy: 0.4951\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.3056 - accuracy: 0.5298 - val_loss: 1.4372 - val_accuracy: 0.4922\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2879 - accuracy: 0.5349 - val_loss: 1.4194 - val_accuracy: 0.5008\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2671 - accuracy: 0.5443 - val_loss: 1.4401 - val_accuracy: 0.4940\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2528 - accuracy: 0.5487 - val_loss: 1.4484 - val_accuracy: 0.4902\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2392 - accuracy: 0.5534 - val_loss: 1.4287 - val_accuracy: 0.4965\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2297 - accuracy: 0.5568 - val_loss: 1.4683 - val_accuracy: 0.4857\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2081 - accuracy: 0.5648 - val_loss: 1.4833 - val_accuracy: 0.4796\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.2023 - accuracy: 0.5661 - val_loss: 1.4916 - val_accuracy: 0.4817\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1828 - accuracy: 0.5736 - val_loss: 1.4295 - val_accuracy: 0.5020\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1672 - accuracy: 0.5795 - val_loss: 1.4699 - val_accuracy: 0.4857\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1477 - accuracy: 0.5834 - val_loss: 1.4478 - val_accuracy: 0.4911\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1368 - accuracy: 0.5902 - val_loss: 1.5074 - val_accuracy: 0.4892\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1222 - accuracy: 0.5943 - val_loss: 1.4551 - val_accuracy: 0.4971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1147 - accuracy: 0.5960 - val_loss: 1.5168 - val_accuracy: 0.4831\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1003 - accuracy: 0.6030 - val_loss: 1.4748 - val_accuracy: 0.4956\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.0805 - accuracy: 0.6096 - val_loss: 1.5319 - val_accuracy: 0.4966\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0718 - accuracy: 0.6121 - val_loss: 1.5070 - val_accuracy: 0.4932\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0615 - accuracy: 0.6167 - val_loss: 1.5536 - val_accuracy: 0.4822\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0507 - accuracy: 0.6185 - val_loss: 1.5205 - val_accuracy: 0.4986\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0362 - accuracy: 0.6238 - val_loss: 1.5327 - val_accuracy: 0.4790\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0246 - accuracy: 0.6295 - val_loss: 1.5325 - val_accuracy: 0.4974\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0125 - accuracy: 0.6315 - val_loss: 1.5693 - val_accuracy: 0.4842\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0043 - accuracy: 0.6358 - val_loss: 1.5765 - val_accuracy: 0.4867\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9969 - accuracy: 0.6398 - val_loss: 1.5811 - val_accuracy: 0.4898\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9809 - accuracy: 0.6439 - val_loss: 1.5940 - val_accuracy: 0.4960\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9659 - accuracy: 0.6481 - val_loss: 1.6130 - val_accuracy: 0.4935\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9573 - accuracy: 0.6535 - val_loss: 1.6110 - val_accuracy: 0.4912\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9449 - accuracy: 0.6567 - val_loss: 1.6136 - val_accuracy: 0.4949\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9370 - accuracy: 0.6588 - val_loss: 1.6407 - val_accuracy: 0.4928\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9244 - accuracy: 0.6634 - val_loss: 1.6721 - val_accuracy: 0.4848\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9125 - accuracy: 0.6680 - val_loss: 1.6546 - val_accuracy: 0.4887\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9182 - accuracy: 0.6651 - val_loss: 1.6847 - val_accuracy: 0.4867\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.8896 - accuracy: 0.6763 - val_loss: 1.7112 - val_accuracy: 0.4854\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8953 - accuracy: 0.6730 - val_loss: 1.6833 - val_accuracy: 0.4927\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.8769 - accuracy: 0.6785 - val_loss: 1.7213 - val_accuracy: 0.4844\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.8668 - accuracy: 0.6832 - val_loss: 1.7727 - val_accuracy: 0.4826\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8581 - accuracy: 0.6875\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7727 - accuracy: 0.4826\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 130)               399490    \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 130)               17030     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 130)               17030     \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 130)               17030     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 130)               17030     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1310      \n",
      "=================================================================\n",
      "Total params: 468,920\n",
      "Trainable params: 468,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "130 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.8831 - accuracy: 0.3114 - val_loss: 1.7317 - val_accuracy: 0.3689\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6954 - accuracy: 0.3880 - val_loss: 1.6690 - val_accuracy: 0.3975\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6207 - accuracy: 0.4182 - val_loss: 1.5772 - val_accuracy: 0.4277\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5627 - accuracy: 0.4400 - val_loss: 1.5478 - val_accuracy: 0.4438\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5272 - accuracy: 0.4527 - val_loss: 1.5398 - val_accuracy: 0.4510\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4950 - accuracy: 0.4619 - val_loss: 1.4896 - val_accuracy: 0.4724\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4574 - accuracy: 0.4782 - val_loss: 1.4881 - val_accuracy: 0.4685\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4363 - accuracy: 0.4853 - val_loss: 1.4509 - val_accuracy: 0.4837\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4081 - accuracy: 0.4942 - val_loss: 1.4852 - val_accuracy: 0.4734\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3942 - accuracy: 0.5012 - val_loss: 1.4600 - val_accuracy: 0.4779\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3653 - accuracy: 0.5086 - val_loss: 1.4444 - val_accuracy: 0.4897\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3491 - accuracy: 0.5132 - val_loss: 1.4389 - val_accuracy: 0.4904\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3260 - accuracy: 0.5253 - val_loss: 1.4275 - val_accuracy: 0.4932\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3061 - accuracy: 0.5296 - val_loss: 1.4367 - val_accuracy: 0.4891\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2937 - accuracy: 0.5329 - val_loss: 1.4496 - val_accuracy: 0.4877\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2830 - accuracy: 0.5387 - val_loss: 1.4432 - val_accuracy: 0.4901\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2597 - accuracy: 0.5482 - val_loss: 1.4338 - val_accuracy: 0.4913\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2435 - accuracy: 0.5528 - val_loss: 1.4796 - val_accuracy: 0.4821\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2336 - accuracy: 0.5554 - val_loss: 1.4316 - val_accuracy: 0.4987\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2051 - accuracy: 0.5668 - val_loss: 1.4226 - val_accuracy: 0.5008\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1900 - accuracy: 0.5710 - val_loss: 1.4769 - val_accuracy: 0.4897\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1876 - accuracy: 0.5744 - val_loss: 1.4650 - val_accuracy: 0.4869\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1693 - accuracy: 0.5801 - val_loss: 1.4696 - val_accuracy: 0.4966\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1539 - accuracy: 0.5842 - val_loss: 1.4514 - val_accuracy: 0.4925\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1320 - accuracy: 0.5903 - val_loss: 1.4502 - val_accuracy: 0.5004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1179 - accuracy: 0.5946 - val_loss: 1.4629 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1088 - accuracy: 0.5990 - val_loss: 1.4885 - val_accuracy: 0.4988\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0903 - accuracy: 0.6070 - val_loss: 1.5002 - val_accuracy: 0.4954\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0751 - accuracy: 0.6092 - val_loss: 1.5014 - val_accuracy: 0.4990\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0629 - accuracy: 0.6133 - val_loss: 1.5081 - val_accuracy: 0.4956\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0410 - accuracy: 0.6221 - val_loss: 1.5173 - val_accuracy: 0.5025\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0321 - accuracy: 0.6252 - val_loss: 1.5110 - val_accuracy: 0.5002\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0117 - accuracy: 0.6328 - val_loss: 1.5406 - val_accuracy: 0.4900\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0015 - accuracy: 0.6365 - val_loss: 1.6056 - val_accuracy: 0.4815\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9881 - accuracy: 0.6420 - val_loss: 1.5744 - val_accuracy: 0.4901\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9850 - accuracy: 0.6425 - val_loss: 1.5719 - val_accuracy: 0.4943\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9711 - accuracy: 0.6460 - val_loss: 1.6454 - val_accuracy: 0.4851\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9620 - accuracy: 0.6526 - val_loss: 1.6120 - val_accuracy: 0.4857\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9400 - accuracy: 0.6590 - val_loss: 1.6986 - val_accuracy: 0.4775\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9319 - accuracy: 0.6622 - val_loss: 1.6543 - val_accuracy: 0.4837\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9182 - accuracy: 0.6665 - val_loss: 1.6934 - val_accuracy: 0.4784\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9172 - accuracy: 0.6649 - val_loss: 1.7197 - val_accuracy: 0.4842\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8874 - accuracy: 0.6775 - val_loss: 1.7047 - val_accuracy: 0.4845\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8889 - accuracy: 0.6768 - val_loss: 1.7720 - val_accuracy: 0.4812\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8713 - accuracy: 0.6816 - val_loss: 1.7038 - val_accuracy: 0.4916\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8630 - accuracy: 0.6860 - val_loss: 1.7919 - val_accuracy: 0.4803\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8523 - accuracy: 0.6893 - val_loss: 1.8185 - val_accuracy: 0.4820\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8457 - accuracy: 0.6901 - val_loss: 1.8767 - val_accuracy: 0.4735\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8404 - accuracy: 0.6934 - val_loss: 1.8102 - val_accuracy: 0.4757\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8242 - accuracy: 0.6988 - val_loss: 1.8104 - val_accuracy: 0.4784\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7412 - accuracy: 0.7341\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8104 - accuracy: 0.4784\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 140)               430220    \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 140)               19740     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 140)               19740     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 140)               19740     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 140)               19740     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1410      \n",
      "=================================================================\n",
      "Total params: 510,590\n",
      "Trainable params: 510,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "140 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.8736 - accuracy: 0.3166 - val_loss: 1.7483 - val_accuracy: 0.3705\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6938 - accuracy: 0.3911 - val_loss: 1.6218 - val_accuracy: 0.4231\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6086 - accuracy: 0.4191 - val_loss: 1.5866 - val_accuracy: 0.4300\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5496 - accuracy: 0.4455 - val_loss: 1.5394 - val_accuracy: 0.4561\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5021 - accuracy: 0.4603 - val_loss: 1.5665 - val_accuracy: 0.4432\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4728 - accuracy: 0.4711 - val_loss: 1.4788 - val_accuracy: 0.4659\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4315 - accuracy: 0.4874 - val_loss: 1.4957 - val_accuracy: 0.4692\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4090 - accuracy: 0.4942 - val_loss: 1.4363 - val_accuracy: 0.4935\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3804 - accuracy: 0.5064 - val_loss: 1.4541 - val_accuracy: 0.4807\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3637 - accuracy: 0.5088 - val_loss: 1.4219 - val_accuracy: 0.4907\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3397 - accuracy: 0.5212 - val_loss: 1.4613 - val_accuracy: 0.4796\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3188 - accuracy: 0.5270 - val_loss: 1.4283 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2900 - accuracy: 0.5368 - val_loss: 1.3998 - val_accuracy: 0.5074\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2713 - accuracy: 0.5427 - val_loss: 1.4233 - val_accuracy: 0.4997\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2557 - accuracy: 0.5517 - val_loss: 1.4259 - val_accuracy: 0.4956\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2322 - accuracy: 0.5577 - val_loss: 1.4525 - val_accuracy: 0.4975\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2158 - accuracy: 0.5642 - val_loss: 1.4101 - val_accuracy: 0.5073\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1878 - accuracy: 0.5725 - val_loss: 1.4445 - val_accuracy: 0.5004\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1747 - accuracy: 0.5771 - val_loss: 1.4210 - val_accuracy: 0.5025\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1647 - accuracy: 0.5797 - val_loss: 1.4658 - val_accuracy: 0.5015\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1502 - accuracy: 0.5839 - val_loss: 1.4597 - val_accuracy: 0.4984\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1240 - accuracy: 0.5962 - val_loss: 1.4463 - val_accuracy: 0.5056\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1069 - accuracy: 0.6014 - val_loss: 1.4379 - val_accuracy: 0.5056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0884 - accuracy: 0.6065 - val_loss: 1.4815 - val_accuracy: 0.5026\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0754 - accuracy: 0.6095 - val_loss: 1.4489 - val_accuracy: 0.5091\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0649 - accuracy: 0.6162 - val_loss: 1.4793 - val_accuracy: 0.4945\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0401 - accuracy: 0.6245 - val_loss: 1.5005 - val_accuracy: 0.5068\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0235 - accuracy: 0.6284 - val_loss: 1.5156 - val_accuracy: 0.4950\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9977 - accuracy: 0.6392 - val_loss: 1.5278 - val_accuracy: 0.4917\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9922 - accuracy: 0.6414 - val_loss: 1.5229 - val_accuracy: 0.5037\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9782 - accuracy: 0.6462 - val_loss: 1.5451 - val_accuracy: 0.4937\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9573 - accuracy: 0.6520 - val_loss: 1.5833 - val_accuracy: 0.4882\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9450 - accuracy: 0.6572 - val_loss: 1.6265 - val_accuracy: 0.4884\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9311 - accuracy: 0.6625 - val_loss: 1.6375 - val_accuracy: 0.4928\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9202 - accuracy: 0.6671 - val_loss: 1.6463 - val_accuracy: 0.4959\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8927 - accuracy: 0.6762 - val_loss: 1.6393 - val_accuracy: 0.5017\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8773 - accuracy: 0.6829 - val_loss: 1.6737 - val_accuracy: 0.4938\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8776 - accuracy: 0.6809 - val_loss: 1.7073 - val_accuracy: 0.4956\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8553 - accuracy: 0.6880 - val_loss: 1.7018 - val_accuracy: 0.5001\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8509 - accuracy: 0.6930 - val_loss: 1.7555 - val_accuracy: 0.4870\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8375 - accuracy: 0.6968 - val_loss: 1.7861 - val_accuracy: 0.4883\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8114 - accuracy: 0.7038 - val_loss: 1.8576 - val_accuracy: 0.4861\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8068 - accuracy: 0.7045 - val_loss: 1.8009 - val_accuracy: 0.4908\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7841 - accuracy: 0.7155 - val_loss: 1.8310 - val_accuracy: 0.4894\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7790 - accuracy: 0.7149 - val_loss: 1.8353 - val_accuracy: 0.4832\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7631 - accuracy: 0.7211 - val_loss: 1.8979 - val_accuracy: 0.4874\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7587 - accuracy: 0.7233 - val_loss: 1.8988 - val_accuracy: 0.4790\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7427 - accuracy: 0.7289 - val_loss: 1.9221 - val_accuracy: 0.4860\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7388 - accuracy: 0.7298 - val_loss: 1.9795 - val_accuracy: 0.4866\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7313 - accuracy: 0.7336 - val_loss: 1.9792 - val_accuracy: 0.4707\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6815 - accuracy: 0.7524\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.9792 - accuracy: 0.4707\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 150)               460950    \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1510      \n",
      "=================================================================\n",
      "Total params: 553,060\n",
      "Trainable params: 553,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "150 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.8751 - accuracy: 0.3113 - val_loss: 1.7580 - val_accuracy: 0.3687\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6882 - accuracy: 0.3925 - val_loss: 1.6270 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6071 - accuracy: 0.4219 - val_loss: 1.6154 - val_accuracy: 0.4139\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5543 - accuracy: 0.4401 - val_loss: 1.5189 - val_accuracy: 0.4550\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5179 - accuracy: 0.4543 - val_loss: 1.5042 - val_accuracy: 0.4604\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4782 - accuracy: 0.4698 - val_loss: 1.4677 - val_accuracy: 0.4725\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4464 - accuracy: 0.4821 - val_loss: 1.4610 - val_accuracy: 0.4737\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4248 - accuracy: 0.4886 - val_loss: 1.4714 - val_accuracy: 0.4738\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3986 - accuracy: 0.4986 - val_loss: 1.4590 - val_accuracy: 0.4792\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3662 - accuracy: 0.5100 - val_loss: 1.4596 - val_accuracy: 0.4840\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3521 - accuracy: 0.5156 - val_loss: 1.4379 - val_accuracy: 0.4949\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3242 - accuracy: 0.5269 - val_loss: 1.4496 - val_accuracy: 0.4861\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3023 - accuracy: 0.5326 - val_loss: 1.4319 - val_accuracy: 0.4943\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2841 - accuracy: 0.5387 - val_loss: 1.4069 - val_accuracy: 0.5086\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2555 - accuracy: 0.5510 - val_loss: 1.4507 - val_accuracy: 0.4907\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2393 - accuracy: 0.5560 - val_loss: 1.4180 - val_accuracy: 0.5020\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2191 - accuracy: 0.5633 - val_loss: 1.4407 - val_accuracy: 0.4989\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2072 - accuracy: 0.5633 - val_loss: 1.4126 - val_accuracy: 0.5043\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1830 - accuracy: 0.5723 - val_loss: 1.4344 - val_accuracy: 0.5009\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1614 - accuracy: 0.5805 - val_loss: 1.4268 - val_accuracy: 0.5026\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1386 - accuracy: 0.5890 - val_loss: 1.4344 - val_accuracy: 0.5014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1165 - accuracy: 0.5978 - val_loss: 1.5020 - val_accuracy: 0.4892\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1045 - accuracy: 0.6019 - val_loss: 1.4889 - val_accuracy: 0.5006\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0834 - accuracy: 0.6079 - val_loss: 1.5390 - val_accuracy: 0.4860\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0636 - accuracy: 0.6159 - val_loss: 1.4527 - val_accuracy: 0.5059\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0475 - accuracy: 0.6210 - val_loss: 1.5175 - val_accuracy: 0.4962\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0218 - accuracy: 0.6312 - val_loss: 1.5379 - val_accuracy: 0.5020\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0129 - accuracy: 0.6342 - val_loss: 1.5502 - val_accuracy: 0.4964\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9934 - accuracy: 0.6396 - val_loss: 1.5366 - val_accuracy: 0.4971\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9736 - accuracy: 0.6499 - val_loss: 1.5723 - val_accuracy: 0.4908\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9586 - accuracy: 0.6507 - val_loss: 1.5702 - val_accuracy: 0.5030\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9363 - accuracy: 0.6611 - val_loss: 1.6155 - val_accuracy: 0.4975\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9267 - accuracy: 0.6637 - val_loss: 1.5882 - val_accuracy: 0.4907\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9077 - accuracy: 0.6672 - val_loss: 1.6562 - val_accuracy: 0.4951\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8915 - accuracy: 0.6764 - val_loss: 1.6730 - val_accuracy: 0.5006\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8792 - accuracy: 0.6804 - val_loss: 1.6917 - val_accuracy: 0.4833\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8689 - accuracy: 0.6870 - val_loss: 1.7081 - val_accuracy: 0.4964\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8448 - accuracy: 0.6924 - val_loss: 1.6658 - val_accuracy: 0.4980\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8419 - accuracy: 0.6912 - val_loss: 1.7246 - val_accuracy: 0.4989\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8223 - accuracy: 0.6995 - val_loss: 1.7595 - val_accuracy: 0.4963\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8039 - accuracy: 0.7048 - val_loss: 1.8218 - val_accuracy: 0.4935\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7946 - accuracy: 0.7093 - val_loss: 1.8036 - val_accuracy: 0.4815\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7731 - accuracy: 0.7175 - val_loss: 1.8616 - val_accuracy: 0.4963\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7844 - accuracy: 0.7123 - val_loss: 1.8291 - val_accuracy: 0.4861\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7536 - accuracy: 0.7268 - val_loss: 1.8882 - val_accuracy: 0.4890\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7498 - accuracy: 0.7267 - val_loss: 1.9641 - val_accuracy: 0.4769\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7319 - accuracy: 0.7328 - val_loss: 1.9215 - val_accuracy: 0.4888\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7233 - accuracy: 0.7359 - val_loss: 1.9527 - val_accuracy: 0.4929\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7011 - accuracy: 0.7434 - val_loss: 2.0481 - val_accuracy: 0.4836\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6938 - accuracy: 0.7460 - val_loss: 2.0638 - val_accuracy: 0.4824\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6731 - accuracy: 0.7532\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0638 - accuracy: 0.4824\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 160)               491680    \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1610      \n",
      "=================================================================\n",
      "Total params: 596,330\n",
      "Trainable params: 596,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "160 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.8723 - accuracy: 0.3154 - val_loss: 1.7513 - val_accuracy: 0.3635\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6922 - accuracy: 0.3891 - val_loss: 1.6545 - val_accuracy: 0.4133\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6129 - accuracy: 0.4211 - val_loss: 1.6025 - val_accuracy: 0.4248\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5600 - accuracy: 0.4361 - val_loss: 1.5376 - val_accuracy: 0.4455\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5054 - accuracy: 0.4616 - val_loss: 1.5673 - val_accuracy: 0.4472\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4758 - accuracy: 0.4697 - val_loss: 1.5033 - val_accuracy: 0.4650\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4407 - accuracy: 0.4817 - val_loss: 1.4801 - val_accuracy: 0.4736\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4153 - accuracy: 0.4915 - val_loss: 1.4494 - val_accuracy: 0.4814\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3877 - accuracy: 0.4999 - val_loss: 1.4402 - val_accuracy: 0.4902\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3665 - accuracy: 0.5082 - val_loss: 1.4779 - val_accuracy: 0.4766\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3361 - accuracy: 0.5190 - val_loss: 1.4452 - val_accuracy: 0.4832\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3195 - accuracy: 0.5258 - val_loss: 1.4459 - val_accuracy: 0.4874\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2922 - accuracy: 0.5335 - val_loss: 1.4203 - val_accuracy: 0.5005\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2718 - accuracy: 0.5418 - val_loss: 1.4146 - val_accuracy: 0.4990\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.2562 - accuracy: 0.5476 - val_loss: 1.4473 - val_accuracy: 0.4963\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2306 - accuracy: 0.5561 - val_loss: 1.4378 - val_accuracy: 0.4967\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2054 - accuracy: 0.5649 - val_loss: 1.4364 - val_accuracy: 0.4992\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1864 - accuracy: 0.5689 - val_loss: 1.4528 - val_accuracy: 0.4994\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1671 - accuracy: 0.5775 - val_loss: 1.4459 - val_accuracy: 0.5030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1404 - accuracy: 0.5874 - val_loss: 1.4681 - val_accuracy: 0.4958\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1234 - accuracy: 0.5957 - val_loss: 1.4673 - val_accuracy: 0.4951\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1034 - accuracy: 0.6017 - val_loss: 1.4710 - val_accuracy: 0.4981\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0832 - accuracy: 0.6083 - val_loss: 1.4683 - val_accuracy: 0.5021\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0618 - accuracy: 0.6154 - val_loss: 1.4925 - val_accuracy: 0.4990\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0482 - accuracy: 0.6185 - val_loss: 1.5080 - val_accuracy: 0.5014\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0288 - accuracy: 0.6256 - val_loss: 1.5033 - val_accuracy: 0.5069\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9960 - accuracy: 0.6384 - val_loss: 1.5183 - val_accuracy: 0.5072\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9822 - accuracy: 0.6433 - val_loss: 1.5823 - val_accuracy: 0.4991\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9666 - accuracy: 0.6486 - val_loss: 1.5841 - val_accuracy: 0.4969\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9516 - accuracy: 0.6554 - val_loss: 1.5775 - val_accuracy: 0.5083\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9238 - accuracy: 0.6649 - val_loss: 1.6875 - val_accuracy: 0.4938\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9119 - accuracy: 0.6694 - val_loss: 1.6128 - val_accuracy: 0.5013\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8962 - accuracy: 0.6735 - val_loss: 1.6800 - val_accuracy: 0.4843\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8726 - accuracy: 0.6834 - val_loss: 1.6786 - val_accuracy: 0.4989\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8441 - accuracy: 0.6920 - val_loss: 1.7438 - val_accuracy: 0.4839\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8415 - accuracy: 0.6941 - val_loss: 1.7179 - val_accuracy: 0.4875\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8156 - accuracy: 0.7035 - val_loss: 1.7828 - val_accuracy: 0.4825\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8007 - accuracy: 0.7088 - val_loss: 1.8270 - val_accuracy: 0.4767\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7888 - accuracy: 0.7106 - val_loss: 1.8263 - val_accuracy: 0.4953\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7824 - accuracy: 0.7159 - val_loss: 1.8175 - val_accuracy: 0.4887\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7617 - accuracy: 0.7232 - val_loss: 1.8881 - val_accuracy: 0.4859\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7301 - accuracy: 0.7339 - val_loss: 1.9571 - val_accuracy: 0.4818\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7181 - accuracy: 0.7373 - val_loss: 2.0042 - val_accuracy: 0.4753\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7160 - accuracy: 0.7371 - val_loss: 1.9734 - val_accuracy: 0.4847\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6972 - accuracy: 0.7457 - val_loss: 2.0744 - val_accuracy: 0.4799\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6868 - accuracy: 0.7466 - val_loss: 2.0308 - val_accuracy: 0.4784\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6869 - accuracy: 0.7485 - val_loss: 2.0732 - val_accuracy: 0.4837\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6612 - accuracy: 0.7590 - val_loss: 2.1773 - val_accuracy: 0.4806\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6568 - accuracy: 0.7598 - val_loss: 2.2280 - val_accuracy: 0.4840\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6360 - accuracy: 0.7673 - val_loss: 2.1832 - val_accuracy: 0.4738\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5985 - accuracy: 0.7836\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1832 - accuracy: 0.4738\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_80 (Dense)             (None, 170)               522410    \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1710      \n",
      "=================================================================\n",
      "Total params: 640,400\n",
      "Trainable params: 640,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "170 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.8776 - accuracy: 0.3143 - val_loss: 1.7339 - val_accuracy: 0.3698\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6912 - accuracy: 0.3881 - val_loss: 1.6089 - val_accuracy: 0.4191\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5957 - accuracy: 0.4253 - val_loss: 1.5732 - val_accuracy: 0.4306\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5407 - accuracy: 0.4458 - val_loss: 1.5226 - val_accuracy: 0.4601\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4944 - accuracy: 0.4641 - val_loss: 1.4974 - val_accuracy: 0.4665\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4576 - accuracy: 0.4763 - val_loss: 1.4717 - val_accuracy: 0.4747\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4289 - accuracy: 0.4861 - val_loss: 1.4584 - val_accuracy: 0.4826\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3960 - accuracy: 0.4995 - val_loss: 1.4338 - val_accuracy: 0.4952\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3735 - accuracy: 0.5066 - val_loss: 1.4862 - val_accuracy: 0.4742\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3428 - accuracy: 0.5196 - val_loss: 1.4428 - val_accuracy: 0.4854\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3229 - accuracy: 0.5259 - val_loss: 1.4216 - val_accuracy: 0.4950\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3045 - accuracy: 0.5326 - val_loss: 1.4070 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2800 - accuracy: 0.5396 - val_loss: 1.4225 - val_accuracy: 0.4950\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2559 - accuracy: 0.5482 - val_loss: 1.4546 - val_accuracy: 0.4914\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2333 - accuracy: 0.5570 - val_loss: 1.4562 - val_accuracy: 0.4920\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2055 - accuracy: 0.5652 - val_loss: 1.4183 - val_accuracy: 0.5032\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1844 - accuracy: 0.5732 - val_loss: 1.4453 - val_accuracy: 0.4983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1647 - accuracy: 0.5817 - val_loss: 1.4306 - val_accuracy: 0.5150\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1397 - accuracy: 0.5895 - val_loss: 1.4376 - val_accuracy: 0.5164\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1206 - accuracy: 0.5941 - val_loss: 1.4621 - val_accuracy: 0.5022\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0850 - accuracy: 0.6063 - val_loss: 1.4733 - val_accuracy: 0.5044\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0739 - accuracy: 0.6112 - val_loss: 1.4637 - val_accuracy: 0.5084\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0523 - accuracy: 0.6203 - val_loss: 1.5022 - val_accuracy: 0.5023\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0319 - accuracy: 0.6276 - val_loss: 1.4967 - val_accuracy: 0.5073\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0068 - accuracy: 0.6363 - val_loss: 1.5074 - val_accuracy: 0.5000\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9793 - accuracy: 0.6442 - val_loss: 1.5353 - val_accuracy: 0.5041\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9576 - accuracy: 0.6529 - val_loss: 1.5605 - val_accuracy: 0.4989\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9402 - accuracy: 0.6576 - val_loss: 1.5960 - val_accuracy: 0.4924\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9088 - accuracy: 0.6695 - val_loss: 1.5856 - val_accuracy: 0.5012\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9008 - accuracy: 0.6707 - val_loss: 1.6315 - val_accuracy: 0.4904\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8763 - accuracy: 0.6825 - val_loss: 1.7030 - val_accuracy: 0.4818\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8656 - accuracy: 0.6832 - val_loss: 1.6875 - val_accuracy: 0.4965\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8365 - accuracy: 0.6940 - val_loss: 1.7382 - val_accuracy: 0.4900\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8161 - accuracy: 0.7023 - val_loss: 1.7202 - val_accuracy: 0.5014\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7965 - accuracy: 0.7094 - val_loss: 1.7677 - val_accuracy: 0.4898\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7730 - accuracy: 0.7166 - val_loss: 1.8150 - val_accuracy: 0.4868\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7649 - accuracy: 0.7203 - val_loss: 1.8407 - val_accuracy: 0.4889\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7341 - accuracy: 0.7307 - val_loss: 1.8697 - val_accuracy: 0.4972\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7248 - accuracy: 0.7338 - val_loss: 1.9251 - val_accuracy: 0.4906\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7137 - accuracy: 0.7414 - val_loss: 1.9608 - val_accuracy: 0.4812\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6993 - accuracy: 0.7434 - val_loss: 1.9798 - val_accuracy: 0.4831\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6786 - accuracy: 0.7524 - val_loss: 2.0094 - val_accuracy: 0.4779\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6608 - accuracy: 0.7585 - val_loss: 2.0781 - val_accuracy: 0.4781\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6450 - accuracy: 0.7627 - val_loss: 2.0981 - val_accuracy: 0.4837\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6325 - accuracy: 0.7684 - val_loss: 2.2190 - val_accuracy: 0.4721\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6297 - accuracy: 0.7701 - val_loss: 2.1560 - val_accuracy: 0.4816\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6156 - accuracy: 0.7749 - val_loss: 2.1659 - val_accuracy: 0.4845\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6029 - accuracy: 0.7803 - val_loss: 2.2229 - val_accuracy: 0.4842\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5934 - accuracy: 0.7844 - val_loss: 2.2469 - val_accuracy: 0.4864\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5732 - accuracy: 0.7895 - val_loss: 2.3989 - val_accuracy: 0.4690\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6006 - accuracy: 0.7810\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3989 - accuracy: 0.4690\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 180)               553140    \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 180)               32580     \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 180)               32580     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 180)               32580     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 180)               32580     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1810      \n",
      "=================================================================\n",
      "Total params: 685,270\n",
      "Trainable params: 685,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "180 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.8725 - accuracy: 0.3119 - val_loss: 1.7500 - val_accuracy: 0.3550\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6916 - accuracy: 0.3865 - val_loss: 1.6193 - val_accuracy: 0.4182\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6177 - accuracy: 0.4171 - val_loss: 1.7356 - val_accuracy: 0.3847\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5580 - accuracy: 0.4381 - val_loss: 1.5404 - val_accuracy: 0.4461\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5067 - accuracy: 0.4583 - val_loss: 1.4902 - val_accuracy: 0.4653\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4680 - accuracy: 0.4719 - val_loss: 1.4728 - val_accuracy: 0.4759\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4247 - accuracy: 0.4887 - val_loss: 1.4405 - val_accuracy: 0.4876\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4009 - accuracy: 0.4975 - val_loss: 1.4448 - val_accuracy: 0.4784\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3681 - accuracy: 0.5090 - val_loss: 1.4404 - val_accuracy: 0.4878\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3467 - accuracy: 0.5174 - val_loss: 1.4518 - val_accuracy: 0.4867\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3251 - accuracy: 0.5237 - val_loss: 1.4225 - val_accuracy: 0.4928\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2995 - accuracy: 0.5303 - val_loss: 1.4466 - val_accuracy: 0.4889\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2762 - accuracy: 0.5391 - val_loss: 1.4091 - val_accuracy: 0.5031\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2465 - accuracy: 0.5488 - val_loss: 1.4644 - val_accuracy: 0.4842\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2236 - accuracy: 0.5572 - val_loss: 1.4315 - val_accuracy: 0.4990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1992 - accuracy: 0.5676 - val_loss: 1.4303 - val_accuracy: 0.4986\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1761 - accuracy: 0.5735 - val_loss: 1.4285 - val_accuracy: 0.4959\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1542 - accuracy: 0.5827 - val_loss: 1.4689 - val_accuracy: 0.4837\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1237 - accuracy: 0.5917 - val_loss: 1.4385 - val_accuracy: 0.5060\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1086 - accuracy: 0.5987 - val_loss: 1.4356 - val_accuracy: 0.5046\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0845 - accuracy: 0.6057 - val_loss: 1.4556 - val_accuracy: 0.5022\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0607 - accuracy: 0.6156 - val_loss: 1.4958 - val_accuracy: 0.4966\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0346 - accuracy: 0.6228 - val_loss: 1.5011 - val_accuracy: 0.5010\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0051 - accuracy: 0.6355 - val_loss: 1.5140 - val_accuracy: 0.5031\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9937 - accuracy: 0.6383 - val_loss: 1.5069 - val_accuracy: 0.5029\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9658 - accuracy: 0.6475 - val_loss: 1.5658 - val_accuracy: 0.4934\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9453 - accuracy: 0.6562 - val_loss: 1.5896 - val_accuracy: 0.4953\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9219 - accuracy: 0.6637 - val_loss: 1.6111 - val_accuracy: 0.4955\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8962 - accuracy: 0.6708 - val_loss: 1.6396 - val_accuracy: 0.4949\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8854 - accuracy: 0.6765 - val_loss: 1.6535 - val_accuracy: 0.4946\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8600 - accuracy: 0.6847 - val_loss: 1.6898 - val_accuracy: 0.5026\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8365 - accuracy: 0.6937 - val_loss: 1.7259 - val_accuracy: 0.4910\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8149 - accuracy: 0.7016 - val_loss: 1.7409 - val_accuracy: 0.4997\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7880 - accuracy: 0.7103 - val_loss: 1.7773 - val_accuracy: 0.4939\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7782 - accuracy: 0.7125 - val_loss: 1.8269 - val_accuracy: 0.4931\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7527 - accuracy: 0.7240 - val_loss: 1.8669 - val_accuracy: 0.4962\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7356 - accuracy: 0.7304 - val_loss: 1.9199 - val_accuracy: 0.4897\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7192 - accuracy: 0.7354 - val_loss: 1.9558 - val_accuracy: 0.4833\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7108 - accuracy: 0.7393 - val_loss: 2.0452 - val_accuracy: 0.4849\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6972 - accuracy: 0.7434 - val_loss: 2.0482 - val_accuracy: 0.4877\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6756 - accuracy: 0.7500 - val_loss: 2.0996 - val_accuracy: 0.4863\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6628 - accuracy: 0.7581 - val_loss: 2.1042 - val_accuracy: 0.4838\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6524 - accuracy: 0.7589 - val_loss: 2.1465 - val_accuracy: 0.4893\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6204 - accuracy: 0.7729 - val_loss: 2.2197 - val_accuracy: 0.4793\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6113 - accuracy: 0.7775 - val_loss: 2.2179 - val_accuracy: 0.4778\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6116 - accuracy: 0.7756 - val_loss: 2.2675 - val_accuracy: 0.4817\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6080 - accuracy: 0.7757 - val_loss: 2.2427 - val_accuracy: 0.4752\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5817 - accuracy: 0.7879 - val_loss: 2.3069 - val_accuracy: 0.4812\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5525 - accuracy: 0.7966 - val_loss: 2.4174 - val_accuracy: 0.4852\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5600 - accuracy: 0.7948 - val_loss: 2.3771 - val_accuracy: 0.4724\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5960 - accuracy: 0.7836\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3771 - accuracy: 0.4724\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 190)               583870    \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 190)               36290     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 190)               36290     \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 190)               36290     \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 190)               36290     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1910      \n",
      "=================================================================\n",
      "Total params: 730,940\n",
      "Trainable params: 730,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "190 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.8629 - accuracy: 0.3213 - val_loss: 1.7267 - val_accuracy: 0.3806\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6886 - accuracy: 0.3927 - val_loss: 1.6383 - val_accuracy: 0.4128\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6138 - accuracy: 0.4180 - val_loss: 1.5740 - val_accuracy: 0.4421\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5498 - accuracy: 0.4449 - val_loss: 1.5456 - val_accuracy: 0.4526\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4961 - accuracy: 0.4631 - val_loss: 1.4985 - val_accuracy: 0.4626\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4705 - accuracy: 0.4729 - val_loss: 1.4612 - val_accuracy: 0.4775\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4304 - accuracy: 0.4873 - val_loss: 1.4658 - val_accuracy: 0.4754\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4011 - accuracy: 0.4967 - val_loss: 1.4356 - val_accuracy: 0.4864\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3703 - accuracy: 0.5085 - val_loss: 1.4714 - val_accuracy: 0.4816\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3469 - accuracy: 0.5162 - val_loss: 1.4389 - val_accuracy: 0.4904\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3199 - accuracy: 0.5253 - val_loss: 1.4211 - val_accuracy: 0.4936\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2989 - accuracy: 0.5354 - val_loss: 1.4306 - val_accuracy: 0.4919\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2685 - accuracy: 0.5453 - val_loss: 1.4463 - val_accuracy: 0.4826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2396 - accuracy: 0.5527 - val_loss: 1.4813 - val_accuracy: 0.4900\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2146 - accuracy: 0.5639 - val_loss: 1.4588 - val_accuracy: 0.4885\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1857 - accuracy: 0.5753 - val_loss: 1.4224 - val_accuracy: 0.5064\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1704 - accuracy: 0.5768 - val_loss: 1.4613 - val_accuracy: 0.4920\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1450 - accuracy: 0.5876 - val_loss: 1.4399 - val_accuracy: 0.5110\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1223 - accuracy: 0.5955 - val_loss: 1.4643 - val_accuracy: 0.4954\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0933 - accuracy: 0.6055 - val_loss: 1.4810 - val_accuracy: 0.5011\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0792 - accuracy: 0.6101 - val_loss: 1.4700 - val_accuracy: 0.5083\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0506 - accuracy: 0.6196 - val_loss: 1.4980 - val_accuracy: 0.4977\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0132 - accuracy: 0.6335 - val_loss: 1.5206 - val_accuracy: 0.4946\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0027 - accuracy: 0.6374 - val_loss: 1.5145 - val_accuracy: 0.5004\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9713 - accuracy: 0.6486 - val_loss: 1.5573 - val_accuracy: 0.4906\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9451 - accuracy: 0.6546 - val_loss: 1.5532 - val_accuracy: 0.5051\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9304 - accuracy: 0.6607 - val_loss: 1.6007 - val_accuracy: 0.5031\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8975 - accuracy: 0.6754 - val_loss: 1.6639 - val_accuracy: 0.4948\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8808 - accuracy: 0.6797 - val_loss: 1.6828 - val_accuracy: 0.4956\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8473 - accuracy: 0.6919 - val_loss: 1.7162 - val_accuracy: 0.4887\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8342 - accuracy: 0.6966 - val_loss: 1.7216 - val_accuracy: 0.4936\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8144 - accuracy: 0.7016 - val_loss: 1.7054 - val_accuracy: 0.5007\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7887 - accuracy: 0.7117 - val_loss: 1.7961 - val_accuracy: 0.4837\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7673 - accuracy: 0.7187 - val_loss: 1.8128 - val_accuracy: 0.4888\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7429 - accuracy: 0.7291 - val_loss: 1.8378 - val_accuracy: 0.4861\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7409 - accuracy: 0.7290 - val_loss: 1.8625 - val_accuracy: 0.4874\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7212 - accuracy: 0.7366 - val_loss: 1.9224 - val_accuracy: 0.4864\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6967 - accuracy: 0.7447 - val_loss: 1.9561 - val_accuracy: 0.4795\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6744 - accuracy: 0.7529 - val_loss: 2.0825 - val_accuracy: 0.4757\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6623 - accuracy: 0.7566 - val_loss: 2.0898 - val_accuracy: 0.4794\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6533 - accuracy: 0.7619 - val_loss: 2.0892 - val_accuracy: 0.4824\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6404 - accuracy: 0.7665 - val_loss: 2.1785 - val_accuracy: 0.4840\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6187 - accuracy: 0.7737 - val_loss: 2.1710 - val_accuracy: 0.4830\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5914 - accuracy: 0.7832 - val_loss: 2.1928 - val_accuracy: 0.4784\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5801 - accuracy: 0.7872 - val_loss: 2.3534 - val_accuracy: 0.4795\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5840 - accuracy: 0.7861 - val_loss: 2.2824 - val_accuracy: 0.4829\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5683 - accuracy: 0.7925 - val_loss: 2.4490 - val_accuracy: 0.4667\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.7923 - val_loss: 2.5308 - val_accuracy: 0.4753\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5449 - accuracy: 0.8005 - val_loss: 2.5388 - val_accuracy: 0.4773\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5388 - accuracy: 0.8037 - val_loss: 2.5321 - val_accuracy: 0.4798\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.4792 - accuracy: 0.8269\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.5321 - accuracy: 0.4798\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 200)               614600    \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 777,410\n",
      "Trainable params: 777,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "200 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.8720 - accuracy: 0.3156 - val_loss: 1.7044 - val_accuracy: 0.3854\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6872 - accuracy: 0.3910 - val_loss: 1.6066 - val_accuracy: 0.4273\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.6022 - accuracy: 0.4227 - val_loss: 1.5800 - val_accuracy: 0.4353\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.5521 - accuracy: 0.4415 - val_loss: 1.5220 - val_accuracy: 0.4574\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4929 - accuracy: 0.4632 - val_loss: 1.5448 - val_accuracy: 0.4478\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4687 - accuracy: 0.4738 - val_loss: 1.4736 - val_accuracy: 0.4787\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.4310 - accuracy: 0.4885 - val_loss: 1.4942 - val_accuracy: 0.4705\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4072 - accuracy: 0.4937 - val_loss: 1.4786 - val_accuracy: 0.4764\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3742 - accuracy: 0.5072 - val_loss: 1.4388 - val_accuracy: 0.4907\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3422 - accuracy: 0.5179 - val_loss: 1.4651 - val_accuracy: 0.4807\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3252 - accuracy: 0.5244 - val_loss: 1.4487 - val_accuracy: 0.4874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3057 - accuracy: 0.5302 - val_loss: 1.4520 - val_accuracy: 0.4814\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2705 - accuracy: 0.5423 - val_loss: 1.4160 - val_accuracy: 0.5018\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2442 - accuracy: 0.5503 - val_loss: 1.4220 - val_accuracy: 0.4943\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.2183 - accuracy: 0.5620 - val_loss: 1.4394 - val_accuracy: 0.4968\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1939 - accuracy: 0.5669 - val_loss: 1.4177 - val_accuracy: 0.5093\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1643 - accuracy: 0.5786 - val_loss: 1.4278 - val_accuracy: 0.4985\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1410 - accuracy: 0.5876 - val_loss: 1.4736 - val_accuracy: 0.4911\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.1122 - accuracy: 0.5952 - val_loss: 1.4468 - val_accuracy: 0.5089\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0932 - accuracy: 0.6023 - val_loss: 1.5045 - val_accuracy: 0.4897\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0732 - accuracy: 0.6086 - val_loss: 1.5202 - val_accuracy: 0.5020\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0432 - accuracy: 0.6208 - val_loss: 1.4661 - val_accuracy: 0.5077\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.0134 - accuracy: 0.6308 - val_loss: 1.5376 - val_accuracy: 0.4919\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9815 - accuracy: 0.6416 - val_loss: 1.5612 - val_accuracy: 0.4878\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9660 - accuracy: 0.6471 - val_loss: 1.6135 - val_accuracy: 0.4926\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9336 - accuracy: 0.6598 - val_loss: 1.6218 - val_accuracy: 0.4837\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.9206 - accuracy: 0.6631 - val_loss: 1.6247 - val_accuracy: 0.4926\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8942 - accuracy: 0.6735 - val_loss: 1.6774 - val_accuracy: 0.4871\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8674 - accuracy: 0.6828 - val_loss: 1.6587 - val_accuracy: 0.4882\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8411 - accuracy: 0.6933 - val_loss: 1.7158 - val_accuracy: 0.4914\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8252 - accuracy: 0.6985 - val_loss: 1.7585 - val_accuracy: 0.4888\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.8006 - accuracy: 0.7071 - val_loss: 1.7675 - val_accuracy: 0.4945\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7895 - accuracy: 0.7118 - val_loss: 1.8036 - val_accuracy: 0.4884\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7545 - accuracy: 0.7233 - val_loss: 1.9157 - val_accuracy: 0.4891\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7309 - accuracy: 0.7317 - val_loss: 2.0287 - val_accuracy: 0.4753\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7189 - accuracy: 0.7361 - val_loss: 1.9792 - val_accuracy: 0.4811\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6999 - accuracy: 0.7446 - val_loss: 2.0116 - val_accuracy: 0.4800\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6724 - accuracy: 0.7531 - val_loss: 2.0388 - val_accuracy: 0.4877\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6665 - accuracy: 0.7531 - val_loss: 2.1489 - val_accuracy: 0.4619\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6481 - accuracy: 0.7640 - val_loss: 2.1912 - val_accuracy: 0.4769\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6277 - accuracy: 0.7692 - val_loss: 2.2065 - val_accuracy: 0.4753\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5947 - accuracy: 0.7808 - val_loss: 2.2813 - val_accuracy: 0.4687\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.6049 - accuracy: 0.7789 - val_loss: 2.2312 - val_accuracy: 0.4733\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5878 - accuracy: 0.7856 - val_loss: 2.3814 - val_accuracy: 0.4729\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5649 - accuracy: 0.7909 - val_loss: 2.3394 - val_accuracy: 0.4770\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.7930 - val_loss: 2.4013 - val_accuracy: 0.4781\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5421 - accuracy: 0.8026 - val_loss: 2.4234 - val_accuracy: 0.4711\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5189 - accuracy: 0.8086 - val_loss: 2.5986 - val_accuracy: 0.4742\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5047 - accuracy: 0.8159 - val_loss: 2.6080 - val_accuracy: 0.4746\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5108 - accuracy: 0.8131 - val_loss: 2.6437 - val_accuracy: 0.4690\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.4638 - accuracy: 0.8318\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.6437 - accuracy: 0.4690\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y_train_error = []\n",
    "y_test_error = []\n",
    "for i in range(10,210,10):\n",
    "    x.append(i)\n",
    "    model = create_model((x_train.shape[1],), no_classes, 5, i)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print('%d neurons per layer' % i)\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=128, verbose=1, validation_data=(x_test, y_test))\n",
    "    #train error\n",
    "    _, train_accuracy = model.evaluate(x_train, y_train)\n",
    "    train_error = (1 - train_accuracy)*100\n",
    "    y_train_error.append(train_error)\n",
    "    #test_error\n",
    "    _, test_accuracy = model.evaluate(x_test, y_test)\n",
    "    test_error = (1 - test_accuracy)*100\n",
    "    y_test_error.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f23942cc1c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"number of neurons per layer\")\n",
    "plt.ylabel('test set error %')\n",
    "plt.plot(x, y_train_error, 'b', label='train error')\n",
    "plt.plot(x, y_test_error, 'r', label='test error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('number_of_neurons_per_layer___test_set_error.txt', 'w')\n",
    "\n",
    "f.write('number of neurons per layer, train error, test error\\n')\n",
    "for i in range(len(x)):\n",
    "    f.write('{}, {}, {}'.format(x[i], y_train_error[i], y_test_error[i]))\n",
    "    f.write('\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

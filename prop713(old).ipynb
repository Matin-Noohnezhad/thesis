{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "#Transfering data to GPU memory will take time and we only do it, if we really need to use GPU\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],-1) #reshape 2D image into a 1D vector\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) #reshape 2D image into a 1D vector\n",
    "##\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the input vectors\n",
    "x_train /= 255 \n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the output to one-hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train, no_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, no_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(shape_of_input, no_classes, no_hidden_layers=0, no_units_per_layer=50):\n",
    "    model = Sequential()\n",
    "    if (no_hidden_layers == 0):\n",
    "        model.add(Dense(no_classes, input_shape = shape_of_input, name='output_layer', activation='softmax'))\n",
    "        return model\n",
    "    model.add(Dense(no_units_per_layer, input_shape = shape_of_input,  activation='relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(BatchNormalization())\n",
    "    for i in range(no_hidden_layers-1):\n",
    "        model.add(Dense(no_units_per_layer, activation='relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(no_classes, name='output_layer', activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                30730     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 31,480\n",
      "Trainable params: 31,380\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "10 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.3493 - accuracy: 0.1389 - val_loss: 2.1183 - val_accuracy: 0.2061\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1426 - accuracy: 0.1917 - val_loss: 2.0421 - val_accuracy: 0.2505\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 2.0794 - accuracy: 0.2047 - val_loss: 1.9566 - val_accuracy: 0.2925\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 2.0494 - accuracy: 0.2204 - val_loss: 1.9428 - val_accuracy: 0.2932\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 2.0300 - accuracy: 0.2292 - val_loss: 1.9305 - val_accuracy: 0.2697\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.0128 - accuracy: 0.2339 - val_loss: 1.9274 - val_accuracy: 0.2844\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9994 - accuracy: 0.2401 - val_loss: 1.8936 - val_accuracy: 0.3164\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9926 - accuracy: 0.2444 - val_loss: 1.9005 - val_accuracy: 0.2958\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9867 - accuracy: 0.2481 - val_loss: 1.9155 - val_accuracy: 0.2894\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9759 - accuracy: 0.2533 - val_loss: 1.9054 - val_accuracy: 0.2723\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9627 - accuracy: 0.2581 - val_loss: 1.9140 - val_accuracy: 0.2518\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9634 - accuracy: 0.2586 - val_loss: 1.9012 - val_accuracy: 0.2986\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9631 - accuracy: 0.2599 - val_loss: 1.8629 - val_accuracy: 0.3089\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9571 - accuracy: 0.2618 - val_loss: 1.8700 - val_accuracy: 0.2951\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9551 - accuracy: 0.2652 - val_loss: 1.8631 - val_accuracy: 0.2998\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9543 - accuracy: 0.2681 - val_loss: 1.8644 - val_accuracy: 0.3041\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9507 - accuracy: 0.2677 - val_loss: 1.8918 - val_accuracy: 0.3030\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9468 - accuracy: 0.2686 - val_loss: 1.8497 - val_accuracy: 0.3020\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9462 - accuracy: 0.2694 - val_loss: 1.8668 - val_accuracy: 0.2993\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9445 - accuracy: 0.2698 - val_loss: 1.8537 - val_accuracy: 0.3141\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9446 - accuracy: 0.2715 - val_loss: 1.8473 - val_accuracy: 0.3061\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9376 - accuracy: 0.2753 - val_loss: 1.8276 - val_accuracy: 0.3231\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9378 - accuracy: 0.2769 - val_loss: 1.8777 - val_accuracy: 0.3037\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9361 - accuracy: 0.2758 - val_loss: 1.8914 - val_accuracy: 0.2877\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9359 - accuracy: 0.2750 - val_loss: 1.8575 - val_accuracy: 0.2949\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9297 - accuracy: 0.2766 - val_loss: 1.8451 - val_accuracy: 0.3255\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9345 - accuracy: 0.2765 - val_loss: 1.8610 - val_accuracy: 0.3003\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9333 - accuracy: 0.2770 - val_loss: 1.8287 - val_accuracy: 0.3167\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9350 - accuracy: 0.2768 - val_loss: 1.8495 - val_accuracy: 0.3066\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9323 - accuracy: 0.2778 - val_loss: 1.8610 - val_accuracy: 0.3021\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9274 - accuracy: 0.2844 - val_loss: 1.8510 - val_accuracy: 0.3090\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9272 - accuracy: 0.2801 - val_loss: 1.8296 - val_accuracy: 0.3219\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9276 - accuracy: 0.2831 - val_loss: 1.8289 - val_accuracy: 0.3177\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9236 - accuracy: 0.2832 - val_loss: 1.8331 - val_accuracy: 0.3081\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9221 - accuracy: 0.2846 - val_loss: 1.8640 - val_accuracy: 0.3241\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9280 - accuracy: 0.2800 - val_loss: 1.8648 - val_accuracy: 0.2946\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.9224 - accuracy: 0.2831 - val_loss: 1.8395 - val_accuracy: 0.3156\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9210 - accuracy: 0.2829 - val_loss: 1.8160 - val_accuracy: 0.3249\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9260 - accuracy: 0.2857 - val_loss: 1.8364 - val_accuracy: 0.3171\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9227 - accuracy: 0.2839 - val_loss: 1.8420 - val_accuracy: 0.3107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9235 - accuracy: 0.2834 - val_loss: 1.8146 - val_accuracy: 0.3285\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9155 - accuracy: 0.2864 - val_loss: 1.8747 - val_accuracy: 0.2849\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9217 - accuracy: 0.2852 - val_loss: 1.8243 - val_accuracy: 0.3192\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9169 - accuracy: 0.2841 - val_loss: 1.9254 - val_accuracy: 0.2706\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9186 - accuracy: 0.2876 - val_loss: 1.8865 - val_accuracy: 0.2884\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9177 - accuracy: 0.2866 - val_loss: 1.8835 - val_accuracy: 0.2902\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9188 - accuracy: 0.2841 - val_loss: 1.8356 - val_accuracy: 0.3123\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9169 - accuracy: 0.2877 - val_loss: 1.8043 - val_accuracy: 0.3326\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9133 - accuracy: 0.2895 - val_loss: 1.8165 - val_accuracy: 0.3183\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9215 - accuracy: 0.2865 - val_loss: 1.8428 - val_accuracy: 0.3074\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.8167 - accuracy: 0.3271\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8428 - accuracy: 0.3074\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 20)                61460     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 63,750\n",
      "Trainable params: 63,550\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "20 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.3316 - accuracy: 0.1524 - val_loss: 2.0709 - val_accuracy: 0.2189\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 2.0752 - accuracy: 0.2130 - val_loss: 1.9354 - val_accuracy: 0.2734\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 2.0181 - accuracy: 0.2356 - val_loss: 1.9302 - val_accuracy: 0.2826\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9810 - accuracy: 0.2510 - val_loss: 1.9315 - val_accuracy: 0.2777\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9531 - accuracy: 0.2642 - val_loss: 1.9227 - val_accuracy: 0.2962\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9351 - accuracy: 0.2755 - val_loss: 1.8770 - val_accuracy: 0.3101\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9230 - accuracy: 0.2831 - val_loss: 1.8279 - val_accuracy: 0.3288\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9154 - accuracy: 0.2879 - val_loss: 1.8586 - val_accuracy: 0.3157\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9070 - accuracy: 0.2915 - val_loss: 1.8516 - val_accuracy: 0.3060\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8985 - accuracy: 0.2971 - val_loss: 1.8399 - val_accuracy: 0.3192\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8956 - accuracy: 0.3010 - val_loss: 1.8781 - val_accuracy: 0.3045\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8895 - accuracy: 0.3004 - val_loss: 1.8314 - val_accuracy: 0.3329\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8786 - accuracy: 0.3060 - val_loss: 1.8085 - val_accuracy: 0.3454\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8816 - accuracy: 0.3061 - val_loss: 1.8396 - val_accuracy: 0.3235\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8785 - accuracy: 0.3081 - val_loss: 1.9050 - val_accuracy: 0.2962\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8730 - accuracy: 0.3106 - val_loss: 1.8005 - val_accuracy: 0.3380\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8673 - accuracy: 0.3148 - val_loss: 1.8019 - val_accuracy: 0.3513\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8644 - accuracy: 0.3147 - val_loss: 1.8157 - val_accuracy: 0.3275\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8694 - accuracy: 0.3143 - val_loss: 1.7950 - val_accuracy: 0.3450\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8610 - accuracy: 0.3175 - val_loss: 1.8246 - val_accuracy: 0.3364\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8606 - accuracy: 0.3157 - val_loss: 1.8132 - val_accuracy: 0.3311\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8552 - accuracy: 0.3179 - val_loss: 1.7913 - val_accuracy: 0.3389\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8551 - accuracy: 0.3217 - val_loss: 1.8104 - val_accuracy: 0.3448\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8572 - accuracy: 0.3194 - val_loss: 1.8025 - val_accuracy: 0.3336\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8510 - accuracy: 0.3211 - val_loss: 1.8194 - val_accuracy: 0.3339\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8493 - accuracy: 0.3246 - val_loss: 1.8013 - val_accuracy: 0.3455\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8496 - accuracy: 0.3247 - val_loss: 1.8078 - val_accuracy: 0.3425\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8468 - accuracy: 0.3254 - val_loss: 1.8283 - val_accuracy: 0.3360\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8453 - accuracy: 0.3266 - val_loss: 1.8345 - val_accuracy: 0.3339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8442 - accuracy: 0.3278 - val_loss: 1.8209 - val_accuracy: 0.3427\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8477 - accuracy: 0.3255 - val_loss: 1.8337 - val_accuracy: 0.3267\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8461 - accuracy: 0.3254 - val_loss: 1.8012 - val_accuracy: 0.3386\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8388 - accuracy: 0.3299 - val_loss: 1.7933 - val_accuracy: 0.3429\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8432 - accuracy: 0.3286 - val_loss: 1.8053 - val_accuracy: 0.3391\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8423 - accuracy: 0.3260 - val_loss: 1.7867 - val_accuracy: 0.3454\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8350 - accuracy: 0.3331 - val_loss: 1.8003 - val_accuracy: 0.3483\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8355 - accuracy: 0.3312 - val_loss: 1.8468 - val_accuracy: 0.3236\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8357 - accuracy: 0.3274 - val_loss: 1.7860 - val_accuracy: 0.3513\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8402 - accuracy: 0.3288 - val_loss: 1.7883 - val_accuracy: 0.3450\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8406 - accuracy: 0.3307 - val_loss: 1.7715 - val_accuracy: 0.3553\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8339 - accuracy: 0.3284 - val_loss: 1.8350 - val_accuracy: 0.3240\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8353 - accuracy: 0.3316 - val_loss: 1.8433 - val_accuracy: 0.3246\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8351 - accuracy: 0.3301 - val_loss: 1.8020 - val_accuracy: 0.3395\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8303 - accuracy: 0.3333 - val_loss: 1.7859 - val_accuracy: 0.3501\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8361 - accuracy: 0.3304 - val_loss: 1.7860 - val_accuracy: 0.3555\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8326 - accuracy: 0.3315 - val_loss: 1.7989 - val_accuracy: 0.3495\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8321 - accuracy: 0.3310 - val_loss: 1.8019 - val_accuracy: 0.3491\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8338 - accuracy: 0.3330 - val_loss: 1.7940 - val_accuracy: 0.3493\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8333 - accuracy: 0.3307 - val_loss: 1.8264 - val_accuracy: 0.3229\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8298 - accuracy: 0.3319 - val_loss: 1.8106 - val_accuracy: 0.3366\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.7695 - accuracy: 0.3545\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8106 - accuracy: 0.3366\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 30)                92190     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 96,820\n",
      "Trainable params: 96,520\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n",
      "30 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.2973 - accuracy: 0.1655 - val_loss: 2.0247 - val_accuracy: 0.2403\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 2.0267 - accuracy: 0.2336 - val_loss: 1.9428 - val_accuracy: 0.2807\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9568 - accuracy: 0.2670 - val_loss: 1.8489 - val_accuracy: 0.3246\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9121 - accuracy: 0.2849 - val_loss: 1.9639 - val_accuracy: 0.2854\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8918 - accuracy: 0.2992 - val_loss: 1.8052 - val_accuracy: 0.3346\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8699 - accuracy: 0.3114 - val_loss: 1.7660 - val_accuracy: 0.3516\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8473 - accuracy: 0.3239 - val_loss: 1.7970 - val_accuracy: 0.3585\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8332 - accuracy: 0.3302 - val_loss: 1.7779 - val_accuracy: 0.3434\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8266 - accuracy: 0.3336 - val_loss: 1.7472 - val_accuracy: 0.3626\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8217 - accuracy: 0.3366 - val_loss: 1.7477 - val_accuracy: 0.3568\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8242 - accuracy: 0.3344 - val_loss: 1.7439 - val_accuracy: 0.3585\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8179 - accuracy: 0.3383 - val_loss: 1.7787 - val_accuracy: 0.3578\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8168 - accuracy: 0.3387 - val_loss: 1.7355 - val_accuracy: 0.3683\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8127 - accuracy: 0.3396 - val_loss: 1.8392 - val_accuracy: 0.3260\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8039 - accuracy: 0.3437 - val_loss: 1.7228 - val_accuracy: 0.3687\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8035 - accuracy: 0.3425 - val_loss: 1.7575 - val_accuracy: 0.3565\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7972 - accuracy: 0.3455 - val_loss: 1.7671 - val_accuracy: 0.3630\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7954 - accuracy: 0.3459 - val_loss: 1.7266 - val_accuracy: 0.3744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7958 - accuracy: 0.3449 - val_loss: 1.8136 - val_accuracy: 0.3532\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7928 - accuracy: 0.3475 - val_loss: 1.7222 - val_accuracy: 0.3753\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7837 - accuracy: 0.3521 - val_loss: 1.7630 - val_accuracy: 0.3634\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7829 - accuracy: 0.3490 - val_loss: 1.7263 - val_accuracy: 0.3714\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7769 - accuracy: 0.3525 - val_loss: 1.7307 - val_accuracy: 0.3613\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7774 - accuracy: 0.3539 - val_loss: 1.7429 - val_accuracy: 0.3628\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7736 - accuracy: 0.3556 - val_loss: 1.7283 - val_accuracy: 0.3674\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7735 - accuracy: 0.3555 - val_loss: 1.7903 - val_accuracy: 0.3481\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7683 - accuracy: 0.3589 - val_loss: 1.7296 - val_accuracy: 0.3755\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7726 - accuracy: 0.3572 - val_loss: 1.7402 - val_accuracy: 0.3645\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7655 - accuracy: 0.3593 - val_loss: 1.7549 - val_accuracy: 0.3568\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7677 - accuracy: 0.3607 - val_loss: 1.7838 - val_accuracy: 0.3519\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7656 - accuracy: 0.3585 - val_loss: 1.8044 - val_accuracy: 0.3419\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7672 - accuracy: 0.3605 - val_loss: 1.7282 - val_accuracy: 0.3693\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7560 - accuracy: 0.3653 - val_loss: 1.6946 - val_accuracy: 0.3832\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7568 - accuracy: 0.3632 - val_loss: 1.7985 - val_accuracy: 0.3500\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7565 - accuracy: 0.3642 - val_loss: 1.7507 - val_accuracy: 0.3657\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7538 - accuracy: 0.3639 - val_loss: 1.6978 - val_accuracy: 0.3886\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7520 - accuracy: 0.3678 - val_loss: 1.6981 - val_accuracy: 0.3857\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7544 - accuracy: 0.3638 - val_loss: 1.6963 - val_accuracy: 0.3833\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7508 - accuracy: 0.3673 - val_loss: 1.7257 - val_accuracy: 0.3781\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7504 - accuracy: 0.3676 - val_loss: 1.7175 - val_accuracy: 0.3764\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7489 - accuracy: 0.3704 - val_loss: 1.7260 - val_accuracy: 0.3774\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7433 - accuracy: 0.3694 - val_loss: 1.7364 - val_accuracy: 0.3713\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7497 - accuracy: 0.3682 - val_loss: 1.7546 - val_accuracy: 0.3699\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7388 - accuracy: 0.3705 - val_loss: 1.7147 - val_accuracy: 0.3824\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7483 - accuracy: 0.3668 - val_loss: 1.6809 - val_accuracy: 0.3895\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7441 - accuracy: 0.3701 - val_loss: 1.6802 - val_accuracy: 0.3921\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7405 - accuracy: 0.3700 - val_loss: 1.6954 - val_accuracy: 0.3838\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7370 - accuracy: 0.3713 - val_loss: 1.6887 - val_accuracy: 0.3848\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7381 - accuracy: 0.3716 - val_loss: 1.7047 - val_accuracy: 0.3852\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7410 - accuracy: 0.3724 - val_loss: 1.7132 - val_accuracy: 0.3792\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.6662 - accuracy: 0.4050\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7132 - accuracy: 0.3792\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 40)                122920    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                410       \n",
      "=================================================================\n",
      "Total params: 130,690\n",
      "Trainable params: 130,290\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n",
      "40 neurons per layer\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.2375 - accuracy: 0.1845 - val_loss: 1.9360 - val_accuracy: 0.2858\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9735 - accuracy: 0.2684 - val_loss: 1.8810 - val_accuracy: 0.2940\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9132 - accuracy: 0.2930 - val_loss: 1.8388 - val_accuracy: 0.3012\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8845 - accuracy: 0.3093 - val_loss: 1.7690 - val_accuracy: 0.3619\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8497 - accuracy: 0.3257 - val_loss: 1.7282 - val_accuracy: 0.3817\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8287 - accuracy: 0.3347 - val_loss: 1.7277 - val_accuracy: 0.3707\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8101 - accuracy: 0.3435 - val_loss: 1.6975 - val_accuracy: 0.3872\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8001 - accuracy: 0.3470 - val_loss: 1.7307 - val_accuracy: 0.3686\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7857 - accuracy: 0.3541 - val_loss: 1.7088 - val_accuracy: 0.3859\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7729 - accuracy: 0.3579 - val_loss: 1.6930 - val_accuracy: 0.3875\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7682 - accuracy: 0.3615 - val_loss: 1.6763 - val_accuracy: 0.3986\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7617 - accuracy: 0.3639 - val_loss: 1.6717 - val_accuracy: 0.4050\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7527 - accuracy: 0.3668 - val_loss: 1.6818 - val_accuracy: 0.3914\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7426 - accuracy: 0.3730 - val_loss: 1.6658 - val_accuracy: 0.4034\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7454 - accuracy: 0.3702 - val_loss: 1.7342 - val_accuracy: 0.3718\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7333 - accuracy: 0.3755 - val_loss: 1.6478 - val_accuracy: 0.4092\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7297 - accuracy: 0.3774 - val_loss: 1.6456 - val_accuracy: 0.4115\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7223 - accuracy: 0.3806 - val_loss: 1.6991 - val_accuracy: 0.3868\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7272 - accuracy: 0.3761 - val_loss: 1.6587 - val_accuracy: 0.4105\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7214 - accuracy: 0.3821 - val_loss: 1.6651 - val_accuracy: 0.4016\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7141 - accuracy: 0.3815 - val_loss: 1.6737 - val_accuracy: 0.4000\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7159 - accuracy: 0.3800 - val_loss: 1.6323 - val_accuracy: 0.4098\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7104 - accuracy: 0.3813 - val_loss: 1.6672 - val_accuracy: 0.4032\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7074 - accuracy: 0.3844 - val_loss: 1.6724 - val_accuracy: 0.4010\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7019 - accuracy: 0.3857 - val_loss: 1.6727 - val_accuracy: 0.3876\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7026 - accuracy: 0.3861 - val_loss: 1.6327 - val_accuracy: 0.4040\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6985 - accuracy: 0.3874 - val_loss: 1.6534 - val_accuracy: 0.4050\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7023 - accuracy: 0.3877 - val_loss: 1.6998 - val_accuracy: 0.3750\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6958 - accuracy: 0.3874 - val_loss: 1.6611 - val_accuracy: 0.4047\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6958 - accuracy: 0.3885 - val_loss: 1.6672 - val_accuracy: 0.4015\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6930 - accuracy: 0.3893 - val_loss: 1.6816 - val_accuracy: 0.3979\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6928 - accuracy: 0.3900 - val_loss: 1.6166 - val_accuracy: 0.4245\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6909 - accuracy: 0.3883 - val_loss: 1.6502 - val_accuracy: 0.4047\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6846 - accuracy: 0.3953 - val_loss: 1.6497 - val_accuracy: 0.4108\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6890 - accuracy: 0.3920 - val_loss: 1.6244 - val_accuracy: 0.4125\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6843 - accuracy: 0.3928 - val_loss: 1.6400 - val_accuracy: 0.4042\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6861 - accuracy: 0.3938 - val_loss: 1.6252 - val_accuracy: 0.4145\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6780 - accuracy: 0.3960 - val_loss: 1.6311 - val_accuracy: 0.4191\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6835 - accuracy: 0.3958 - val_loss: 1.6522 - val_accuracy: 0.3985\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6768 - accuracy: 0.3949 - val_loss: 1.6519 - val_accuracy: 0.4019\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6781 - accuracy: 0.3953 - val_loss: 1.6794 - val_accuracy: 0.4001\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6728 - accuracy: 0.3975 - val_loss: 1.6400 - val_accuracy: 0.4077\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6730 - accuracy: 0.3980 - val_loss: 1.6306 - val_accuracy: 0.4123\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6697 - accuracy: 0.3959 - val_loss: 1.6134 - val_accuracy: 0.4220\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6736 - accuracy: 0.3961 - val_loss: 1.7028 - val_accuracy: 0.3814\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6732 - accuracy: 0.3973 - val_loss: 1.6484 - val_accuracy: 0.4006\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6688 - accuracy: 0.4000 - val_loss: 1.6354 - val_accuracy: 0.4092\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6709 - accuracy: 0.3984 - val_loss: 1.6092 - val_accuracy: 0.4258\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6670 - accuracy: 0.4035 - val_loss: 1.6543 - val_accuracy: 0.4015\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6616 - accuracy: 0.4018 - val_loss: 1.6822 - val_accuracy: 0.4035\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.6162 - accuracy: 0.4202\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6822 - accuracy: 0.4035\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 50)                153650    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 165,360\n",
      "Trainable params: 164,860\n",
      "Non-trainable params: 500\n",
      "_________________________________________________________________\n",
      "50 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.2281 - accuracy: 0.1993 - val_loss: 2.0290 - val_accuracy: 0.2363\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9559 - accuracy: 0.2731 - val_loss: 1.8253 - val_accuracy: 0.3203\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8995 - accuracy: 0.3026 - val_loss: 1.9654 - val_accuracy: 0.2879\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8797 - accuracy: 0.3149 - val_loss: 1.8084 - val_accuracy: 0.3585\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8518 - accuracy: 0.3254 - val_loss: 1.7553 - val_accuracy: 0.3625\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8288 - accuracy: 0.3344 - val_loss: 1.7588 - val_accuracy: 0.3526\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8103 - accuracy: 0.3436 - val_loss: 1.7802 - val_accuracy: 0.3604\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8016 - accuracy: 0.3492 - val_loss: 1.7149 - val_accuracy: 0.3859\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7874 - accuracy: 0.3496 - val_loss: 1.7117 - val_accuracy: 0.3793\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7787 - accuracy: 0.3542 - val_loss: 1.6919 - val_accuracy: 0.3929\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7694 - accuracy: 0.3591 - val_loss: 1.7126 - val_accuracy: 0.3858\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7618 - accuracy: 0.3653 - val_loss: 1.6895 - val_accuracy: 0.3873\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7546 - accuracy: 0.3658 - val_loss: 1.7208 - val_accuracy: 0.3854\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7504 - accuracy: 0.3653 - val_loss: 1.7288 - val_accuracy: 0.3627\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7417 - accuracy: 0.3743 - val_loss: 1.6448 - val_accuracy: 0.4079\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7366 - accuracy: 0.3735 - val_loss: 1.6454 - val_accuracy: 0.4103\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7363 - accuracy: 0.3739 - val_loss: 1.7423 - val_accuracy: 0.3698\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7273 - accuracy: 0.3761 - val_loss: 1.6933 - val_accuracy: 0.3849\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7211 - accuracy: 0.3778 - val_loss: 1.6587 - val_accuracy: 0.3962\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7215 - accuracy: 0.3779 - val_loss: 1.6838 - val_accuracy: 0.3940\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7177 - accuracy: 0.3772 - val_loss: 1.7268 - val_accuracy: 0.3760\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7136 - accuracy: 0.3804 - val_loss: 1.6448 - val_accuracy: 0.4047\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7071 - accuracy: 0.3854 - val_loss: 1.6586 - val_accuracy: 0.4064\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7107 - accuracy: 0.3825 - val_loss: 1.6540 - val_accuracy: 0.4046\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7012 - accuracy: 0.3877 - val_loss: 1.6428 - val_accuracy: 0.4058\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7047 - accuracy: 0.3859 - val_loss: 1.6750 - val_accuracy: 0.4014\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7049 - accuracy: 0.3861 - val_loss: 1.6200 - val_accuracy: 0.4146\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7005 - accuracy: 0.3861 - val_loss: 1.6546 - val_accuracy: 0.4107\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6984 - accuracy: 0.3878 - val_loss: 1.6664 - val_accuracy: 0.4005\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6893 - accuracy: 0.3900 - val_loss: 1.6674 - val_accuracy: 0.3991\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6944 - accuracy: 0.3913 - val_loss: 1.6596 - val_accuracy: 0.3990\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6935 - accuracy: 0.3923 - val_loss: 1.6172 - val_accuracy: 0.4169\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6911 - accuracy: 0.3909 - val_loss: 1.7056 - val_accuracy: 0.3757\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6948 - accuracy: 0.3893 - val_loss: 1.6948 - val_accuracy: 0.3884\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6829 - accuracy: 0.3978 - val_loss: 1.6117 - val_accuracy: 0.4126\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6841 - accuracy: 0.3950 - val_loss: 1.6528 - val_accuracy: 0.4037\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6821 - accuracy: 0.3968 - val_loss: 1.6472 - val_accuracy: 0.4067\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6836 - accuracy: 0.3944 - val_loss: 1.6359 - val_accuracy: 0.4098\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6766 - accuracy: 0.3978 - val_loss: 1.6457 - val_accuracy: 0.3995\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6782 - accuracy: 0.3977 - val_loss: 1.6958 - val_accuracy: 0.3909\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6770 - accuracy: 0.3964 - val_loss: 1.6141 - val_accuracy: 0.4198\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6788 - accuracy: 0.3963 - val_loss: 1.6898 - val_accuracy: 0.3953\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6722 - accuracy: 0.3989 - val_loss: 1.6137 - val_accuracy: 0.4221\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6677 - accuracy: 0.3989 - val_loss: 1.6279 - val_accuracy: 0.4203\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6732 - accuracy: 0.3989 - val_loss: 1.6913 - val_accuracy: 0.3761\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6753 - accuracy: 0.3972 - val_loss: 1.6420 - val_accuracy: 0.4030\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6656 - accuracy: 0.4006 - val_loss: 1.6161 - val_accuracy: 0.4186\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6687 - accuracy: 0.3996 - val_loss: 1.6057 - val_accuracy: 0.4198\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6726 - accuracy: 0.3980 - val_loss: 1.6558 - val_accuracy: 0.3962\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6674 - accuracy: 0.4032 - val_loss: 1.6098 - val_accuracy: 0.4212\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.5472 - accuracy: 0.4520\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6098 - accuracy: 0.4212\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 60)                184380    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 200,830\n",
      "Trainable params: 200,230\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "60 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.2191 - accuracy: 0.2026 - val_loss: 1.9368 - val_accuracy: 0.2713\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9265 - accuracy: 0.2905 - val_loss: 1.8713 - val_accuracy: 0.3214\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8726 - accuracy: 0.3180 - val_loss: 1.7991 - val_accuracy: 0.3439\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8341 - accuracy: 0.3326 - val_loss: 1.7095 - val_accuracy: 0.3870\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8024 - accuracy: 0.3482 - val_loss: 1.7115 - val_accuracy: 0.3757\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7728 - accuracy: 0.3613 - val_loss: 1.7342 - val_accuracy: 0.3654\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7568 - accuracy: 0.3660 - val_loss: 1.6926 - val_accuracy: 0.3841\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7442 - accuracy: 0.3720 - val_loss: 1.6125 - val_accuracy: 0.4176\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7237 - accuracy: 0.3801 - val_loss: 1.5976 - val_accuracy: 0.4319\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7142 - accuracy: 0.3812 - val_loss: 1.6269 - val_accuracy: 0.4079\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7079 - accuracy: 0.3871 - val_loss: 1.6385 - val_accuracy: 0.4073\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.6994 - accuracy: 0.3897 - val_loss: 1.6203 - val_accuracy: 0.4134\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6899 - accuracy: 0.3947 - val_loss: 1.6400 - val_accuracy: 0.4084\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6898 - accuracy: 0.3920 - val_loss: 1.5833 - val_accuracy: 0.4275\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6787 - accuracy: 0.3964 - val_loss: 1.5994 - val_accuracy: 0.4246\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6748 - accuracy: 0.3984 - val_loss: 1.6001 - val_accuracy: 0.4255\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6672 - accuracy: 0.4025 - val_loss: 1.5878 - val_accuracy: 0.4295\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6619 - accuracy: 0.4043 - val_loss: 1.6213 - val_accuracy: 0.4145\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6541 - accuracy: 0.4039 - val_loss: 1.6653 - val_accuracy: 0.4058\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6543 - accuracy: 0.4028 - val_loss: 1.6243 - val_accuracy: 0.4105\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6478 - accuracy: 0.4068 - val_loss: 1.6534 - val_accuracy: 0.4111\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6516 - accuracy: 0.4077 - val_loss: 1.5845 - val_accuracy: 0.4289\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6456 - accuracy: 0.4125 - val_loss: 1.5876 - val_accuracy: 0.4230\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6383 - accuracy: 0.4134 - val_loss: 1.6493 - val_accuracy: 0.4034\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6345 - accuracy: 0.4121 - val_loss: 1.5545 - val_accuracy: 0.4357\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6292 - accuracy: 0.4142 - val_loss: 1.6074 - val_accuracy: 0.4164\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6319 - accuracy: 0.4114 - val_loss: 1.5778 - val_accuracy: 0.4335\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6258 - accuracy: 0.4157 - val_loss: 1.5673 - val_accuracy: 0.4356\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6208 - accuracy: 0.4166 - val_loss: 1.5964 - val_accuracy: 0.4224\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6185 - accuracy: 0.4194 - val_loss: 1.5638 - val_accuracy: 0.4392\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6165 - accuracy: 0.4211 - val_loss: 1.5622 - val_accuracy: 0.4380\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6151 - accuracy: 0.4213 - val_loss: 1.6161 - val_accuracy: 0.4176\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6152 - accuracy: 0.4216 - val_loss: 1.5572 - val_accuracy: 0.4451\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6066 - accuracy: 0.4239 - val_loss: 1.6327 - val_accuracy: 0.4182\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6128 - accuracy: 0.4218 - val_loss: 1.5614 - val_accuracy: 0.4471\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6001 - accuracy: 0.4255 - val_loss: 1.5613 - val_accuracy: 0.4443\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5974 - accuracy: 0.4278 - val_loss: 1.5309 - val_accuracy: 0.4502\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5968 - accuracy: 0.4266 - val_loss: 1.5548 - val_accuracy: 0.4458\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5961 - accuracy: 0.4272 - val_loss: 1.5728 - val_accuracy: 0.4319\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5941 - accuracy: 0.4261 - val_loss: 1.5702 - val_accuracy: 0.4402\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5940 - accuracy: 0.4293 - val_loss: 1.5528 - val_accuracy: 0.4457\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5964 - accuracy: 0.4283 - val_loss: 1.5441 - val_accuracy: 0.4434\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5869 - accuracy: 0.4305 - val_loss: 1.5547 - val_accuracy: 0.4344\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5882 - accuracy: 0.4291 - val_loss: 1.5458 - val_accuracy: 0.4508\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5819 - accuracy: 0.4301 - val_loss: 1.5819 - val_accuracy: 0.4241\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5837 - accuracy: 0.4319 - val_loss: 1.5803 - val_accuracy: 0.4363\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5782 - accuracy: 0.4366 - val_loss: 1.5435 - val_accuracy: 0.4495\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5829 - accuracy: 0.4364 - val_loss: 1.5151 - val_accuracy: 0.4573\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5709 - accuracy: 0.4354 - val_loss: 1.5348 - val_accuracy: 0.4510\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5737 - accuracy: 0.4356 - val_loss: 1.5419 - val_accuracy: 0.4422\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.4559 - accuracy: 0.4747\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5419 - accuracy: 0.4422\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 70)                215110    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                710       \n",
      "=================================================================\n",
      "Total params: 237,100\n",
      "Trainable params: 236,400\n",
      "Non-trainable params: 700\n",
      "_________________________________________________________________\n",
      "70 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1888 - accuracy: 0.2162 - val_loss: 1.9243 - val_accuracy: 0.2705\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9255 - accuracy: 0.2952 - val_loss: 1.9159 - val_accuracy: 0.3202\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8570 - accuracy: 0.3237 - val_loss: 1.7849 - val_accuracy: 0.3538\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8293 - accuracy: 0.3366 - val_loss: 1.7603 - val_accuracy: 0.3600\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8009 - accuracy: 0.3514 - val_loss: 1.6880 - val_accuracy: 0.3917\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7820 - accuracy: 0.3615 - val_loss: 1.6677 - val_accuracy: 0.3998\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7550 - accuracy: 0.3660 - val_loss: 1.6729 - val_accuracy: 0.3935\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7345 - accuracy: 0.3764 - val_loss: 1.6229 - val_accuracy: 0.4222\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7183 - accuracy: 0.3827 - val_loss: 1.6962 - val_accuracy: 0.3818\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7098 - accuracy: 0.3834 - val_loss: 1.6739 - val_accuracy: 0.4053\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7033 - accuracy: 0.3883 - val_loss: 1.6019 - val_accuracy: 0.4221\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6893 - accuracy: 0.3935 - val_loss: 1.6086 - val_accuracy: 0.4208\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6834 - accuracy: 0.3934 - val_loss: 1.6809 - val_accuracy: 0.3953\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6654 - accuracy: 0.4019 - val_loss: 1.6221 - val_accuracy: 0.4214\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6651 - accuracy: 0.4017 - val_loss: 1.6231 - val_accuracy: 0.4151\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6602 - accuracy: 0.4047 - val_loss: 1.5599 - val_accuracy: 0.4379\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6508 - accuracy: 0.4081 - val_loss: 1.5930 - val_accuracy: 0.4226\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6431 - accuracy: 0.4134 - val_loss: 1.5834 - val_accuracy: 0.4309\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6420 - accuracy: 0.4114 - val_loss: 1.6249 - val_accuracy: 0.4189\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6363 - accuracy: 0.4123 - val_loss: 1.6050 - val_accuracy: 0.4294\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6332 - accuracy: 0.4160 - val_loss: 1.5809 - val_accuracy: 0.4329\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6281 - accuracy: 0.4162 - val_loss: 1.6221 - val_accuracy: 0.4142\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6257 - accuracy: 0.4170 - val_loss: 1.5985 - val_accuracy: 0.4354\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6233 - accuracy: 0.4185 - val_loss: 1.5769 - val_accuracy: 0.4353\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6132 - accuracy: 0.4207 - val_loss: 1.5849 - val_accuracy: 0.4282\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6168 - accuracy: 0.4188 - val_loss: 1.5420 - val_accuracy: 0.4466\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6116 - accuracy: 0.4232 - val_loss: 1.5972 - val_accuracy: 0.4343\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6053 - accuracy: 0.4245 - val_loss: 1.5931 - val_accuracy: 0.4287\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6076 - accuracy: 0.4236 - val_loss: 1.5428 - val_accuracy: 0.4547\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6089 - accuracy: 0.4249 - val_loss: 1.5644 - val_accuracy: 0.4447\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6007 - accuracy: 0.4289 - val_loss: 1.5347 - val_accuracy: 0.4506\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5966 - accuracy: 0.4281 - val_loss: 1.6166 - val_accuracy: 0.4193\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5962 - accuracy: 0.4292 - val_loss: 1.5460 - val_accuracy: 0.4483\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5932 - accuracy: 0.4326 - val_loss: 1.5818 - val_accuracy: 0.4300\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5897 - accuracy: 0.4319 - val_loss: 1.5696 - val_accuracy: 0.4424\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5867 - accuracy: 0.4325 - val_loss: 1.5666 - val_accuracy: 0.4443\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5849 - accuracy: 0.4334 - val_loss: 1.5649 - val_accuracy: 0.4408\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5864 - accuracy: 0.4326 - val_loss: 1.5469 - val_accuracy: 0.4418\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5787 - accuracy: 0.4340 - val_loss: 1.5595 - val_accuracy: 0.4388\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5808 - accuracy: 0.4372 - val_loss: 1.5555 - val_accuracy: 0.4339\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5739 - accuracy: 0.4353 - val_loss: 1.5314 - val_accuracy: 0.4491\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5793 - accuracy: 0.4317 - val_loss: 1.5545 - val_accuracy: 0.4330\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5739 - accuracy: 0.4375 - val_loss: 1.5480 - val_accuracy: 0.4439\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5756 - accuracy: 0.4383 - val_loss: 1.5344 - val_accuracy: 0.4529\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5701 - accuracy: 0.4392 - val_loss: 1.5938 - val_accuracy: 0.4234\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5739 - accuracy: 0.4361 - val_loss: 1.5147 - val_accuracy: 0.4580\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5673 - accuracy: 0.4376 - val_loss: 1.5757 - val_accuracy: 0.4372\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5684 - accuracy: 0.4413 - val_loss: 1.5606 - val_accuracy: 0.4404\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5672 - accuracy: 0.4388 - val_loss: 1.5401 - val_accuracy: 0.4488\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5611 - accuracy: 0.4395 - val_loss: 1.5991 - val_accuracy: 0.4266\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.5226 - accuracy: 0.4539\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5991 - accuracy: 0.4266\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 80)                245840    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 274,170\n",
      "Trainable params: 273,370\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "80 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.2002 - accuracy: 0.2196 - val_loss: 1.8639 - val_accuracy: 0.3282\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.9111 - accuracy: 0.3031 - val_loss: 1.9237 - val_accuracy: 0.2770\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8382 - accuracy: 0.3345 - val_loss: 1.7576 - val_accuracy: 0.3595\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8064 - accuracy: 0.3453 - val_loss: 1.8547 - val_accuracy: 0.3359\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7706 - accuracy: 0.3581 - val_loss: 1.6800 - val_accuracy: 0.3866\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7545 - accuracy: 0.3657 - val_loss: 1.6689 - val_accuracy: 0.3851\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7396 - accuracy: 0.3740 - val_loss: 1.6308 - val_accuracy: 0.4012\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7332 - accuracy: 0.3731 - val_loss: 1.7114 - val_accuracy: 0.3778\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7113 - accuracy: 0.3837 - val_loss: 1.6660 - val_accuracy: 0.3931\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6911 - accuracy: 0.3901 - val_loss: 1.6070 - val_accuracy: 0.4188\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6800 - accuracy: 0.3943 - val_loss: 1.5885 - val_accuracy: 0.4314\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6723 - accuracy: 0.3971 - val_loss: 1.6004 - val_accuracy: 0.4191\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6627 - accuracy: 0.4037 - val_loss: 1.5954 - val_accuracy: 0.4319\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6536 - accuracy: 0.4060 - val_loss: 1.5816 - val_accuracy: 0.4379\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6529 - accuracy: 0.4059 - val_loss: 1.5861 - val_accuracy: 0.4256\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6444 - accuracy: 0.4084 - val_loss: 1.6112 - val_accuracy: 0.4134\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6388 - accuracy: 0.4113 - val_loss: 1.5613 - val_accuracy: 0.4326\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6327 - accuracy: 0.4140 - val_loss: 1.7078 - val_accuracy: 0.3811\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6225 - accuracy: 0.4176 - val_loss: 2.3022 - val_accuracy: 0.2095\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6184 - accuracy: 0.4216 - val_loss: 1.5297 - val_accuracy: 0.4565\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6129 - accuracy: 0.4210 - val_loss: 1.5714 - val_accuracy: 0.4421\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6065 - accuracy: 0.4225 - val_loss: 1.5833 - val_accuracy: 0.4281\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5985 - accuracy: 0.4292 - val_loss: 1.5431 - val_accuracy: 0.4475\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6023 - accuracy: 0.4276 - val_loss: 1.5380 - val_accuracy: 0.4500\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6036 - accuracy: 0.4230 - val_loss: 1.5736 - val_accuracy: 0.4332\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6088 - accuracy: 0.4237 - val_loss: 4.7934 - val_accuracy: 0.1716\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6040 - accuracy: 0.4257 - val_loss: 1.5445 - val_accuracy: 0.4461\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6002 - accuracy: 0.4272 - val_loss: 1.5447 - val_accuracy: 0.4453\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5847 - accuracy: 0.4346 - val_loss: 1.5585 - val_accuracy: 0.4504\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5762 - accuracy: 0.4370 - val_loss: 1.5227 - val_accuracy: 0.4561\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5773 - accuracy: 0.4368 - val_loss: 1.5506 - val_accuracy: 0.4462\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5777 - accuracy: 0.4370 - val_loss: 1.5291 - val_accuracy: 0.4480\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5680 - accuracy: 0.4390 - val_loss: 1.5735 - val_accuracy: 0.4344\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5690 - accuracy: 0.4392 - val_loss: 1.5489 - val_accuracy: 0.4484\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5693 - accuracy: 0.4382 - val_loss: 1.5214 - val_accuracy: 0.4568\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5596 - accuracy: 0.4411 - val_loss: 1.5704 - val_accuracy: 0.4360\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5603 - accuracy: 0.4437 - val_loss: 1.5237 - val_accuracy: 0.4547\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5549 - accuracy: 0.4456 - val_loss: 1.5736 - val_accuracy: 0.4402\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5580 - accuracy: 0.4436 - val_loss: 1.5741 - val_accuracy: 0.4322\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5505 - accuracy: 0.4451 - val_loss: 1.5581 - val_accuracy: 0.4393\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5541 - accuracy: 0.4450 - val_loss: 1.5487 - val_accuracy: 0.4411\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5529 - accuracy: 0.4452 - val_loss: 1.5271 - val_accuracy: 0.4478\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5483 - accuracy: 0.4493 - val_loss: 1.5056 - val_accuracy: 0.4659\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5409 - accuracy: 0.4502 - val_loss: 1.5358 - val_accuracy: 0.4484\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5437 - accuracy: 0.4467 - val_loss: 1.5208 - val_accuracy: 0.4564\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5418 - accuracy: 0.4509 - val_loss: 1.5306 - val_accuracy: 0.4561\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5383 - accuracy: 0.4508 - val_loss: 1.5328 - val_accuracy: 0.4472\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5353 - accuracy: 0.4515 - val_loss: 1.5204 - val_accuracy: 0.4593\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5397 - accuracy: 0.4503 - val_loss: 1.5487 - val_accuracy: 0.4452\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5329 - accuracy: 0.4537 - val_loss: 1.5372 - val_accuracy: 0.4509\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.4352 - accuracy: 0.4887\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5372 - accuracy: 0.4509\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 90)                276570    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 90)                360       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 90)                8190      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 90)                360       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 90)                8190      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 90)                360       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 90)                8190      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 90)                360       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 90)                8190      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 90)                360       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                910       \n",
      "=================================================================\n",
      "Total params: 312,040\n",
      "Trainable params: 311,140\n",
      "Non-trainable params: 900\n",
      "_________________________________________________________________\n",
      "90 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1848 - accuracy: 0.2180 - val_loss: 1.9198 - val_accuracy: 0.2909\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8913 - accuracy: 0.3107 - val_loss: 2.7471 - val_accuracy: 0.2473\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8332 - accuracy: 0.3341 - val_loss: 1.7891 - val_accuracy: 0.3653\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7746 - accuracy: 0.3582 - val_loss: 1.7674 - val_accuracy: 0.3727\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7560 - accuracy: 0.3691 - val_loss: 1.9642 - val_accuracy: 0.3296\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7312 - accuracy: 0.3766 - val_loss: 1.6678 - val_accuracy: 0.3975\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7201 - accuracy: 0.3822 - val_loss: 1.6194 - val_accuracy: 0.4126\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7016 - accuracy: 0.3885 - val_loss: 1.6319 - val_accuracy: 0.4096\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6796 - accuracy: 0.3968 - val_loss: 1.6565 - val_accuracy: 0.3957\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6748 - accuracy: 0.4012 - val_loss: 1.6009 - val_accuracy: 0.4249\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6640 - accuracy: 0.4036 - val_loss: 1.5627 - val_accuracy: 0.4475\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6483 - accuracy: 0.4116 - val_loss: 1.6413 - val_accuracy: 0.4035\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6420 - accuracy: 0.4134 - val_loss: 1.6066 - val_accuracy: 0.4213\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6338 - accuracy: 0.4130 - val_loss: 1.5954 - val_accuracy: 0.4274\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6269 - accuracy: 0.4168 - val_loss: 1.5892 - val_accuracy: 0.4243\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6171 - accuracy: 0.4226 - val_loss: 1.5773 - val_accuracy: 0.4382\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6151 - accuracy: 0.4229 - val_loss: 1.5733 - val_accuracy: 0.4348\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6099 - accuracy: 0.4222 - val_loss: 1.5509 - val_accuracy: 0.4428\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6033 - accuracy: 0.4247 - val_loss: 1.6066 - val_accuracy: 0.4168\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6002 - accuracy: 0.4274 - val_loss: 1.5610 - val_accuracy: 0.4403\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5958 - accuracy: 0.4319 - val_loss: 1.5321 - val_accuracy: 0.4508\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5872 - accuracy: 0.4321 - val_loss: 1.5637 - val_accuracy: 0.4459\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5850 - accuracy: 0.4327 - val_loss: 1.5363 - val_accuracy: 0.4557\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5795 - accuracy: 0.4368 - val_loss: 1.5317 - val_accuracy: 0.4527\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5743 - accuracy: 0.4400 - val_loss: 1.5490 - val_accuracy: 0.4449\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5731 - accuracy: 0.4397 - val_loss: 1.5943 - val_accuracy: 0.4288\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5694 - accuracy: 0.4407 - val_loss: 1.5803 - val_accuracy: 0.4406\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5653 - accuracy: 0.4412 - val_loss: 1.5300 - val_accuracy: 0.4510\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5604 - accuracy: 0.4450 - val_loss: 1.5426 - val_accuracy: 0.4415\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5577 - accuracy: 0.4460 - val_loss: 1.5286 - val_accuracy: 0.4565\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5589 - accuracy: 0.4426 - val_loss: 1.5400 - val_accuracy: 0.4519\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5526 - accuracy: 0.4466 - val_loss: 1.5650 - val_accuracy: 0.4332\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5550 - accuracy: 0.4478 - val_loss: 1.6081 - val_accuracy: 0.4203\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5509 - accuracy: 0.4462 - val_loss: 1.5202 - val_accuracy: 0.4541\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5429 - accuracy: 0.4499 - val_loss: 1.5562 - val_accuracy: 0.4430\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5478 - accuracy: 0.4467 - val_loss: 1.5194 - val_accuracy: 0.4587\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5425 - accuracy: 0.4485 - val_loss: 1.5485 - val_accuracy: 0.4396\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5390 - accuracy: 0.4538 - val_loss: 1.5366 - val_accuracy: 0.4498\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5356 - accuracy: 0.4524 - val_loss: 1.5465 - val_accuracy: 0.4459\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5390 - accuracy: 0.4502 - val_loss: 1.5414 - val_accuracy: 0.4430\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5326 - accuracy: 0.4542 - val_loss: 1.5231 - val_accuracy: 0.4491\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5365 - accuracy: 0.4529 - val_loss: 1.5452 - val_accuracy: 0.4418\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5305 - accuracy: 0.4547 - val_loss: 1.4781 - val_accuracy: 0.4709\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5258 - accuracy: 0.4549 - val_loss: 1.5384 - val_accuracy: 0.4486\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5250 - accuracy: 0.4594 - val_loss: 1.5377 - val_accuracy: 0.4441\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5241 - accuracy: 0.4575 - val_loss: 1.5676 - val_accuracy: 0.4390\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5250 - accuracy: 0.4578 - val_loss: 1.5748 - val_accuracy: 0.4294\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5202 - accuracy: 0.4576 - val_loss: 1.5888 - val_accuracy: 0.4422\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5178 - accuracy: 0.4564 - val_loss: 1.5437 - val_accuracy: 0.4476\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5155 - accuracy: 0.4617 - val_loss: 1.5597 - val_accuracy: 0.4377\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.4635 - accuracy: 0.4764\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5597 - accuracy: 0.4377\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 350,710\n",
      "Trainable params: 349,710\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n",
      "100 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1633 - accuracy: 0.2233 - val_loss: 1.8608 - val_accuracy: 0.3142\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8852 - accuracy: 0.3134 - val_loss: 1.7599 - val_accuracy: 0.3651\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8112 - accuracy: 0.3425 - val_loss: 1.7004 - val_accuracy: 0.3865\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7829 - accuracy: 0.3556 - val_loss: 1.6661 - val_accuracy: 0.4005\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7593 - accuracy: 0.3655 - val_loss: 1.7535 - val_accuracy: 0.3537\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7587 - accuracy: 0.3661 - val_loss: 1.7578 - val_accuracy: 0.3459\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7378 - accuracy: 0.3741 - val_loss: 1.6507 - val_accuracy: 0.3966\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7187 - accuracy: 0.3808 - val_loss: 1.6305 - val_accuracy: 0.4139\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7046 - accuracy: 0.3878 - val_loss: 1.6095 - val_accuracy: 0.4206\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6917 - accuracy: 0.3901 - val_loss: 1.6568 - val_accuracy: 0.3959\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6749 - accuracy: 0.3993 - val_loss: 1.6004 - val_accuracy: 0.4203\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6672 - accuracy: 0.4009 - val_loss: 1.6432 - val_accuracy: 0.4119\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6674 - accuracy: 0.4014 - val_loss: 1.6051 - val_accuracy: 0.4173\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6531 - accuracy: 0.4054 - val_loss: 1.5873 - val_accuracy: 0.4293\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6488 - accuracy: 0.4081 - val_loss: 1.6743 - val_accuracy: 0.3874\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6352 - accuracy: 0.4124 - val_loss: 1.5767 - val_accuracy: 0.4330\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6283 - accuracy: 0.4127 - val_loss: 1.6565 - val_accuracy: 0.3917\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6291 - accuracy: 0.4171 - val_loss: 1.5716 - val_accuracy: 0.4359\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6198 - accuracy: 0.4178 - val_loss: 1.5919 - val_accuracy: 0.4274\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6167 - accuracy: 0.4214 - val_loss: 1.6037 - val_accuracy: 0.4232\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6150 - accuracy: 0.4206 - val_loss: 1.5573 - val_accuracy: 0.4459\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6124 - accuracy: 0.4212 - val_loss: 1.5647 - val_accuracy: 0.4340\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6007 - accuracy: 0.4273 - val_loss: 1.5406 - val_accuracy: 0.4508\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5952 - accuracy: 0.4282 - val_loss: 1.5772 - val_accuracy: 0.4349\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5919 - accuracy: 0.4300 - val_loss: 1.5517 - val_accuracy: 0.4380\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5882 - accuracy: 0.4304 - val_loss: 1.5607 - val_accuracy: 0.4371\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5872 - accuracy: 0.4314 - val_loss: 1.5463 - val_accuracy: 0.4410\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5832 - accuracy: 0.4312 - val_loss: 1.5284 - val_accuracy: 0.4480\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5796 - accuracy: 0.4362 - val_loss: 1.5881 - val_accuracy: 0.4288\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5739 - accuracy: 0.4363 - val_loss: 1.5398 - val_accuracy: 0.4501\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5747 - accuracy: 0.4387 - val_loss: 1.5502 - val_accuracy: 0.4447\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5691 - accuracy: 0.4382 - val_loss: 1.5471 - val_accuracy: 0.4448\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5666 - accuracy: 0.4410 - val_loss: 1.5595 - val_accuracy: 0.4433\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5641 - accuracy: 0.4403 - val_loss: 1.5407 - val_accuracy: 0.4447\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5593 - accuracy: 0.4433 - val_loss: 1.5963 - val_accuracy: 0.4288\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5596 - accuracy: 0.4404 - val_loss: 1.6722 - val_accuracy: 0.3841\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5554 - accuracy: 0.4444 - val_loss: 1.5374 - val_accuracy: 0.4470\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5528 - accuracy: 0.4445 - val_loss: 1.5336 - val_accuracy: 0.4540\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5475 - accuracy: 0.4471 - val_loss: 1.5016 - val_accuracy: 0.4624\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5428 - accuracy: 0.4488 - val_loss: 1.5145 - val_accuracy: 0.4534\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5406 - accuracy: 0.4475 - val_loss: 1.5172 - val_accuracy: 0.4602\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5419 - accuracy: 0.4479 - val_loss: 1.5414 - val_accuracy: 0.4421\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5353 - accuracy: 0.4493 - val_loss: 1.6051 - val_accuracy: 0.4242\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5380 - accuracy: 0.4499 - val_loss: 1.5058 - val_accuracy: 0.4562\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5343 - accuracy: 0.4512 - val_loss: 1.5492 - val_accuracy: 0.4472\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5350 - accuracy: 0.4521 - val_loss: 1.5112 - val_accuracy: 0.4581\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5252 - accuracy: 0.4536 - val_loss: 1.5215 - val_accuracy: 0.4538\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5249 - accuracy: 0.4564 - val_loss: 1.5279 - val_accuracy: 0.4496\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5195 - accuracy: 0.4580 - val_loss: 1.5240 - val_accuracy: 0.4665\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5180 - accuracy: 0.4578 - val_loss: 1.5507 - val_accuracy: 0.4491\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.4504 - accuracy: 0.4759\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5507 - accuracy: 0.4491\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 110)               338030    \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 110)               440       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 110)               12210     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 110)               440       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 110)               12210     \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 110)               440       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 110)               12210     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 110)               440       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 110)               12210     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 110)               440       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1110      \n",
      "=================================================================\n",
      "Total params: 390,180\n",
      "Trainable params: 389,080\n",
      "Non-trainable params: 1,100\n",
      "_________________________________________________________________\n",
      "110 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1472 - accuracy: 0.2320 - val_loss: 1.8311 - val_accuracy: 0.3284\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8694 - accuracy: 0.3218 - val_loss: 1.7624 - val_accuracy: 0.3641\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8086 - accuracy: 0.3426 - val_loss: 1.8130 - val_accuracy: 0.3241\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7752 - accuracy: 0.3550 - val_loss: 1.7173 - val_accuracy: 0.3761\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7490 - accuracy: 0.3694 - val_loss: 1.6565 - val_accuracy: 0.4036\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7202 - accuracy: 0.3776 - val_loss: 1.6161 - val_accuracy: 0.4197\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6958 - accuracy: 0.3923 - val_loss: 1.6534 - val_accuracy: 0.3998\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6759 - accuracy: 0.3963 - val_loss: 1.7557 - val_accuracy: 0.3751\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6668 - accuracy: 0.4004 - val_loss: 1.6269 - val_accuracy: 0.4168\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6587 - accuracy: 0.4008 - val_loss: 1.6230 - val_accuracy: 0.4139\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6498 - accuracy: 0.4063 - val_loss: 1.5910 - val_accuracy: 0.4331\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6351 - accuracy: 0.4129 - val_loss: 1.5589 - val_accuracy: 0.4374\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6251 - accuracy: 0.4157 - val_loss: 1.5512 - val_accuracy: 0.4409\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6262 - accuracy: 0.4162 - val_loss: 1.5482 - val_accuracy: 0.4441\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6196 - accuracy: 0.4207 - val_loss: 1.5602 - val_accuracy: 0.4419\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6156 - accuracy: 0.4198 - val_loss: 1.5628 - val_accuracy: 0.4317\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6067 - accuracy: 0.4208 - val_loss: 1.5318 - val_accuracy: 0.4480\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5937 - accuracy: 0.4296 - val_loss: 1.5554 - val_accuracy: 0.4431\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5949 - accuracy: 0.4274 - val_loss: 1.5513 - val_accuracy: 0.4434\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5831 - accuracy: 0.4297 - val_loss: 1.5300 - val_accuracy: 0.4436\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5774 - accuracy: 0.4317 - val_loss: 1.5314 - val_accuracy: 0.4442\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5722 - accuracy: 0.4364 - val_loss: 1.5693 - val_accuracy: 0.4233\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5761 - accuracy: 0.4351 - val_loss: 1.5320 - val_accuracy: 0.4528\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5674 - accuracy: 0.4377 - val_loss: 1.5415 - val_accuracy: 0.4443\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5639 - accuracy: 0.4397 - val_loss: 1.5262 - val_accuracy: 0.4499\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5572 - accuracy: 0.4392 - val_loss: 1.5294 - val_accuracy: 0.4490\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5530 - accuracy: 0.4409 - val_loss: 1.5236 - val_accuracy: 0.4506\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5526 - accuracy: 0.4428 - val_loss: 1.5139 - val_accuracy: 0.4505\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5461 - accuracy: 0.4438 - val_loss: 1.5376 - val_accuracy: 0.4485\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5383 - accuracy: 0.4483 - val_loss: 1.5357 - val_accuracy: 0.4458\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5424 - accuracy: 0.4459 - val_loss: 1.5542 - val_accuracy: 0.4353\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5379 - accuracy: 0.4515 - val_loss: 1.5046 - val_accuracy: 0.4629\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5348 - accuracy: 0.4466 - val_loss: 1.5453 - val_accuracy: 0.4524\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5298 - accuracy: 0.4509 - val_loss: 1.5370 - val_accuracy: 0.4368\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5311 - accuracy: 0.4499 - val_loss: 1.6326 - val_accuracy: 0.4069\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5251 - accuracy: 0.4521 - val_loss: 1.5004 - val_accuracy: 0.4552\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5226 - accuracy: 0.4512 - val_loss: 1.5306 - val_accuracy: 0.4454\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5216 - accuracy: 0.4535 - val_loss: 1.5238 - val_accuracy: 0.4516\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5148 - accuracy: 0.4558 - val_loss: 1.4978 - val_accuracy: 0.4637\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5161 - accuracy: 0.4564 - val_loss: 1.5043 - val_accuracy: 0.4509\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5154 - accuracy: 0.4582 - val_loss: 1.5398 - val_accuracy: 0.4464\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5116 - accuracy: 0.4567 - val_loss: 1.5668 - val_accuracy: 0.4371\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5138 - accuracy: 0.4579 - val_loss: 1.5053 - val_accuracy: 0.4588\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5126 - accuracy: 0.4567 - val_loss: 1.4913 - val_accuracy: 0.4613\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5057 - accuracy: 0.4621 - val_loss: 1.5002 - val_accuracy: 0.4603\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5041 - accuracy: 0.4617 - val_loss: 1.5366 - val_accuracy: 0.4448\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5040 - accuracy: 0.4603 - val_loss: 1.5181 - val_accuracy: 0.4569\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5040 - accuracy: 0.4627 - val_loss: 1.4838 - val_accuracy: 0.4692\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4976 - accuracy: 0.4617 - val_loss: 1.5029 - val_accuracy: 0.4621\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4954 - accuracy: 0.4610 - val_loss: 1.4987 - val_accuracy: 0.4612\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3831 - accuracy: 0.5087\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4987 - accuracy: 0.4612\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 120)               368760    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1210      \n",
      "=================================================================\n",
      "Total params: 430,450\n",
      "Trainable params: 429,250\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "120 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1389 - accuracy: 0.2385 - val_loss: 1.8845 - val_accuracy: 0.2902\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8706 - accuracy: 0.3209 - val_loss: 1.7938 - val_accuracy: 0.3536\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.8076 - accuracy: 0.3471 - val_loss: 1.7046 - val_accuracy: 0.3883\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7789 - accuracy: 0.3581 - val_loss: 1.7224 - val_accuracy: 0.3771\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7490 - accuracy: 0.3685 - val_loss: 1.8427 - val_accuracy: 0.3373\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7104 - accuracy: 0.3852 - val_loss: 1.6551 - val_accuracy: 0.4014\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7038 - accuracy: 0.3852 - val_loss: 1.6052 - val_accuracy: 0.4217\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6868 - accuracy: 0.3929 - val_loss: 1.6025 - val_accuracy: 0.4260\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6648 - accuracy: 0.4021 - val_loss: 1.5678 - val_accuracy: 0.4395\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6489 - accuracy: 0.4076 - val_loss: 1.5804 - val_accuracy: 0.4378\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6393 - accuracy: 0.4110 - val_loss: 1.6026 - val_accuracy: 0.4278\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6269 - accuracy: 0.4158 - val_loss: 1.6929 - val_accuracy: 0.3887\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6185 - accuracy: 0.4178 - val_loss: 1.5501 - val_accuracy: 0.4462\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6117 - accuracy: 0.4195 - val_loss: 1.5474 - val_accuracy: 0.4455\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5970 - accuracy: 0.4260 - val_loss: 1.5387 - val_accuracy: 0.4457\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5926 - accuracy: 0.4316 - val_loss: 1.5500 - val_accuracy: 0.4414\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5859 - accuracy: 0.4329 - val_loss: 1.5424 - val_accuracy: 0.4550\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5775 - accuracy: 0.4335 - val_loss: 1.6410 - val_accuracy: 0.4177\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5698 - accuracy: 0.4376 - val_loss: 1.5550 - val_accuracy: 0.4423\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5643 - accuracy: 0.4421 - val_loss: 1.5545 - val_accuracy: 0.4487\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5568 - accuracy: 0.4435 - val_loss: 1.5794 - val_accuracy: 0.4331\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5579 - accuracy: 0.4440 - val_loss: 1.5210 - val_accuracy: 0.4580\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5525 - accuracy: 0.4432 - val_loss: 1.5080 - val_accuracy: 0.4611\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5466 - accuracy: 0.4494 - val_loss: 1.5375 - val_accuracy: 0.4502\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5404 - accuracy: 0.4518 - val_loss: 1.5464 - val_accuracy: 0.4497\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5396 - accuracy: 0.4505 - val_loss: 1.5091 - val_accuracy: 0.4644\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5332 - accuracy: 0.4548 - val_loss: 1.5280 - val_accuracy: 0.4456\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5274 - accuracy: 0.4547 - val_loss: 1.5963 - val_accuracy: 0.4302\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5236 - accuracy: 0.4567 - val_loss: 1.4985 - val_accuracy: 0.4626\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5185 - accuracy: 0.4578 - val_loss: 1.5300 - val_accuracy: 0.4648\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5189 - accuracy: 0.4582 - val_loss: 1.4974 - val_accuracy: 0.4706\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5160 - accuracy: 0.4590 - val_loss: 1.5555 - val_accuracy: 0.4488\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5136 - accuracy: 0.4616 - val_loss: 1.5509 - val_accuracy: 0.4515\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5061 - accuracy: 0.4658 - val_loss: 1.5057 - val_accuracy: 0.4615\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5080 - accuracy: 0.4610 - val_loss: 1.4999 - val_accuracy: 0.4519\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5000 - accuracy: 0.4675 - val_loss: 1.5192 - val_accuracy: 0.4612\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5039 - accuracy: 0.4636 - val_loss: 1.5517 - val_accuracy: 0.4411\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4977 - accuracy: 0.4675 - val_loss: 1.5160 - val_accuracy: 0.4716\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5010 - accuracy: 0.4639 - val_loss: 1.5412 - val_accuracy: 0.4439\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4872 - accuracy: 0.4707 - val_loss: 1.5111 - val_accuracy: 0.4601\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4895 - accuracy: 0.4715 - val_loss: 1.4870 - val_accuracy: 0.4703\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4918 - accuracy: 0.4699 - val_loss: 1.5253 - val_accuracy: 0.4462\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4849 - accuracy: 0.4726 - val_loss: 1.5312 - val_accuracy: 0.4500\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4888 - accuracy: 0.4699 - val_loss: 1.4613 - val_accuracy: 0.4759\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4821 - accuracy: 0.4729 - val_loss: 1.4797 - val_accuracy: 0.4752\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4773 - accuracy: 0.4751 - val_loss: 1.4849 - val_accuracy: 0.4771\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4816 - accuracy: 0.4727 - val_loss: 1.4682 - val_accuracy: 0.4716\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4759 - accuracy: 0.4730 - val_loss: 1.4769 - val_accuracy: 0.4727\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4718 - accuracy: 0.4754 - val_loss: 1.4917 - val_accuracy: 0.4621\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4742 - accuracy: 0.4743 - val_loss: 1.5595 - val_accuracy: 0.4336\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.4545 - accuracy: 0.4715\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5595 - accuracy: 0.4336\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 130)               399490    \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 130)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 130)               520       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 130)               17030     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 130)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 130)               520       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 130)               17030     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 130)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 130)               520       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 130)               17030     \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 130)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 130)               520       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 130)               17030     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 130)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 130)               520       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1310      \n",
      "=================================================================\n",
      "Total params: 471,520\n",
      "Trainable params: 470,220\n",
      "Non-trainable params: 1,300\n",
      "_________________________________________________________________\n",
      "130 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1446 - accuracy: 0.2393 - val_loss: 1.9388 - val_accuracy: 0.2877\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8505 - accuracy: 0.3282 - val_loss: 1.7959 - val_accuracy: 0.3393\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8142 - accuracy: 0.3411 - val_loss: 1.7421 - val_accuracy: 0.3738\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7729 - accuracy: 0.3600 - val_loss: 1.7624 - val_accuracy: 0.3687\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7262 - accuracy: 0.3777 - val_loss: 1.6323 - val_accuracy: 0.4096\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6945 - accuracy: 0.3868 - val_loss: 1.6594 - val_accuracy: 0.3891\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6701 - accuracy: 0.3993 - val_loss: 1.6483 - val_accuracy: 0.4093\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6544 - accuracy: 0.4040 - val_loss: 1.5992 - val_accuracy: 0.4233\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6435 - accuracy: 0.4077 - val_loss: 1.6262 - val_accuracy: 0.4016\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6330 - accuracy: 0.4096 - val_loss: 1.7082 - val_accuracy: 0.3898\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6232 - accuracy: 0.4156 - val_loss: 1.6126 - val_accuracy: 0.4168\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6125 - accuracy: 0.4195 - val_loss: 1.5383 - val_accuracy: 0.4523\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5955 - accuracy: 0.4283 - val_loss: 1.5332 - val_accuracy: 0.4483\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5901 - accuracy: 0.4300 - val_loss: 1.5726 - val_accuracy: 0.4358\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5776 - accuracy: 0.4328 - val_loss: 1.5329 - val_accuracy: 0.4470\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5785 - accuracy: 0.4318 - val_loss: 1.5392 - val_accuracy: 0.4461\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5646 - accuracy: 0.4377 - val_loss: 1.6044 - val_accuracy: 0.4262\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5571 - accuracy: 0.4409 - val_loss: 1.5263 - val_accuracy: 0.4519\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5484 - accuracy: 0.4449 - val_loss: 1.5418 - val_accuracy: 0.4465\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5486 - accuracy: 0.4442 - val_loss: 1.4857 - val_accuracy: 0.4658\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5409 - accuracy: 0.4464 - val_loss: 1.5190 - val_accuracy: 0.4505\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5330 - accuracy: 0.4497 - val_loss: 1.5330 - val_accuracy: 0.4488\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5273 - accuracy: 0.4533 - val_loss: 1.6030 - val_accuracy: 0.4272\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5244 - accuracy: 0.4556 - val_loss: 1.4699 - val_accuracy: 0.4777\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5174 - accuracy: 0.4576 - val_loss: 1.5067 - val_accuracy: 0.4632\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5172 - accuracy: 0.4558 - val_loss: 1.4911 - val_accuracy: 0.4625\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5125 - accuracy: 0.4561 - val_loss: 1.4893 - val_accuracy: 0.4637\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5122 - accuracy: 0.4579 - val_loss: 1.5702 - val_accuracy: 0.4322\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5044 - accuracy: 0.4620 - val_loss: 1.5016 - val_accuracy: 0.4632\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5026 - accuracy: 0.4615 - val_loss: 1.4695 - val_accuracy: 0.4723\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4989 - accuracy: 0.4613 - val_loss: 1.5206 - val_accuracy: 0.4558\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4931 - accuracy: 0.4651 - val_loss: 1.4957 - val_accuracy: 0.4622\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4923 - accuracy: 0.4681 - val_loss: 1.5107 - val_accuracy: 0.4531\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4891 - accuracy: 0.4655 - val_loss: 1.5136 - val_accuracy: 0.4515\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4889 - accuracy: 0.4672 - val_loss: 1.4848 - val_accuracy: 0.4617\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4844 - accuracy: 0.4688 - val_loss: 1.5085 - val_accuracy: 0.4613\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4806 - accuracy: 0.4708 - val_loss: 1.5146 - val_accuracy: 0.4533\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4801 - accuracy: 0.4707 - val_loss: 1.4890 - val_accuracy: 0.4642\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4781 - accuracy: 0.4725 - val_loss: 1.5159 - val_accuracy: 0.4536\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4735 - accuracy: 0.4717 - val_loss: 1.4859 - val_accuracy: 0.4651\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4711 - accuracy: 0.4763 - val_loss: 1.4684 - val_accuracy: 0.4794\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4682 - accuracy: 0.4738 - val_loss: 1.4976 - val_accuracy: 0.4579\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4694 - accuracy: 0.4739 - val_loss: 1.4811 - val_accuracy: 0.4704\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4631 - accuracy: 0.4772 - val_loss: 1.4804 - val_accuracy: 0.4688\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4585 - accuracy: 0.4781 - val_loss: 1.5220 - val_accuracy: 0.4543\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4593 - accuracy: 0.4774 - val_loss: 1.5275 - val_accuracy: 0.4486\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4532 - accuracy: 0.4796 - val_loss: 1.4764 - val_accuracy: 0.4625\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4521 - accuracy: 0.4811 - val_loss: 1.5054 - val_accuracy: 0.4580\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4547 - accuracy: 0.4801 - val_loss: 1.5179 - val_accuracy: 0.4586\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4544 - accuracy: 0.4804 - val_loss: 1.4818 - val_accuracy: 0.4762\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3547 - accuracy: 0.5153\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4818 - accuracy: 0.4762\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 140)               430220    \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 140)               560       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 140)               19740     \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 140)               560       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 140)               19740     \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 140)               560       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 140)               19740     \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 140)               560       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 140)               19740     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 140)               560       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1410      \n",
      "=================================================================\n",
      "Total params: 513,390\n",
      "Trainable params: 511,990\n",
      "Non-trainable params: 1,400\n",
      "_________________________________________________________________\n",
      "140 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1261 - accuracy: 0.2458 - val_loss: 1.9415 - val_accuracy: 0.3052\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8564 - accuracy: 0.3253 - val_loss: 1.7449 - val_accuracy: 0.3637\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8024 - accuracy: 0.3456 - val_loss: 1.6897 - val_accuracy: 0.3816\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7526 - accuracy: 0.3681 - val_loss: 1.6527 - val_accuracy: 0.4020\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.7156 - accuracy: 0.3829 - val_loss: 1.6514 - val_accuracy: 0.4090\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6979 - accuracy: 0.3883 - val_loss: 1.6252 - val_accuracy: 0.4151\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6702 - accuracy: 0.3993 - val_loss: 1.5923 - val_accuracy: 0.4233\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6582 - accuracy: 0.4044 - val_loss: 1.5488 - val_accuracy: 0.4454\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6430 - accuracy: 0.4101 - val_loss: 1.5360 - val_accuracy: 0.4502\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6328 - accuracy: 0.4139 - val_loss: 1.5517 - val_accuracy: 0.4392\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6282 - accuracy: 0.4171 - val_loss: 1.5508 - val_accuracy: 0.4440\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6186 - accuracy: 0.4217 - val_loss: 1.5120 - val_accuracy: 0.4588\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6047 - accuracy: 0.4244 - val_loss: 1.5359 - val_accuracy: 0.4491\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6008 - accuracy: 0.4277 - val_loss: 1.5340 - val_accuracy: 0.4406\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5881 - accuracy: 0.4326 - val_loss: 1.5420 - val_accuracy: 0.4448\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5756 - accuracy: 0.4359 - val_loss: 1.5561 - val_accuracy: 0.4473\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5717 - accuracy: 0.4375 - val_loss: 1.5359 - val_accuracy: 0.4517\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5649 - accuracy: 0.4410 - val_loss: 1.5130 - val_accuracy: 0.4613\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5590 - accuracy: 0.4433 - val_loss: 1.5034 - val_accuracy: 0.4667\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5502 - accuracy: 0.4449 - val_loss: 1.4959 - val_accuracy: 0.4665\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5455 - accuracy: 0.4457 - val_loss: 1.5318 - val_accuracy: 0.4510\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5393 - accuracy: 0.4500 - val_loss: 1.5798 - val_accuracy: 0.4405\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5287 - accuracy: 0.4542 - val_loss: 1.5045 - val_accuracy: 0.4673\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5274 - accuracy: 0.4546 - val_loss: 1.4907 - val_accuracy: 0.4639\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5229 - accuracy: 0.4587 - val_loss: 1.5214 - val_accuracy: 0.4545\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5212 - accuracy: 0.4573 - val_loss: 1.5240 - val_accuracy: 0.4594\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5163 - accuracy: 0.4568 - val_loss: 1.4795 - val_accuracy: 0.4694\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5141 - accuracy: 0.4605 - val_loss: 1.5237 - val_accuracy: 0.4584\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5070 - accuracy: 0.4635 - val_loss: 1.5207 - val_accuracy: 0.4563\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5072 - accuracy: 0.4623 - val_loss: 1.4893 - val_accuracy: 0.4673\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4996 - accuracy: 0.4665 - val_loss: 1.5327 - val_accuracy: 0.4539\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4982 - accuracy: 0.4668 - val_loss: 1.4789 - val_accuracy: 0.4696\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4923 - accuracy: 0.4664 - val_loss: 1.5155 - val_accuracy: 0.4569\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4905 - accuracy: 0.4660 - val_loss: 1.4879 - val_accuracy: 0.4648\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4873 - accuracy: 0.4705 - val_loss: 1.5489 - val_accuracy: 0.4519\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4833 - accuracy: 0.4703 - val_loss: 1.4609 - val_accuracy: 0.4824\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4732 - accuracy: 0.4729 - val_loss: 1.4787 - val_accuracy: 0.4686\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4787 - accuracy: 0.4729 - val_loss: 1.4644 - val_accuracy: 0.4765\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4741 - accuracy: 0.4739 - val_loss: 1.4850 - val_accuracy: 0.4802\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4724 - accuracy: 0.4753 - val_loss: 1.5059 - val_accuracy: 0.4630\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4694 - accuracy: 0.4727 - val_loss: 1.4487 - val_accuracy: 0.4829\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4688 - accuracy: 0.4774 - val_loss: 1.5130 - val_accuracy: 0.4527\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4686 - accuracy: 0.4740 - val_loss: 1.4773 - val_accuracy: 0.4748\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4594 - accuracy: 0.4780 - val_loss: 1.4778 - val_accuracy: 0.4724\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4593 - accuracy: 0.4809 - val_loss: 1.6140 - val_accuracy: 0.4144\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4594 - accuracy: 0.4800 - val_loss: 1.4714 - val_accuracy: 0.4710\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4533 - accuracy: 0.4822 - val_loss: 1.4654 - val_accuracy: 0.4808\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4542 - accuracy: 0.4812 - val_loss: 1.4826 - val_accuracy: 0.4661\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4491 - accuracy: 0.4848 - val_loss: 1.4655 - val_accuracy: 0.4756\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4506 - accuracy: 0.4800 - val_loss: 1.4517 - val_accuracy: 0.4838\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3035 - accuracy: 0.5396\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4517 - accuracy: 0.4838\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 150)               460950    \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1510      \n",
      "=================================================================\n",
      "Total params: 556,060\n",
      "Trainable params: 554,560\n",
      "Non-trainable params: 1,500\n",
      "_________________________________________________________________\n",
      "150 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1402 - accuracy: 0.2423 - val_loss: 1.8487 - val_accuracy: 0.3233\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8550 - accuracy: 0.3282 - val_loss: 2.2298 - val_accuracy: 0.2497\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7983 - accuracy: 0.3490 - val_loss: 1.9533 - val_accuracy: 0.3054\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7341 - accuracy: 0.3762 - val_loss: 1.7248 - val_accuracy: 0.3755\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6992 - accuracy: 0.3888 - val_loss: 1.6242 - val_accuracy: 0.4116\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6943 - accuracy: 0.3928 - val_loss: 1.6025 - val_accuracy: 0.4294\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6796 - accuracy: 0.3991 - val_loss: 1.6243 - val_accuracy: 0.4152\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6575 - accuracy: 0.4103 - val_loss: 1.5900 - val_accuracy: 0.4257\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6325 - accuracy: 0.4150 - val_loss: 1.5320 - val_accuracy: 0.4509\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6220 - accuracy: 0.4202 - val_loss: 1.5172 - val_accuracy: 0.4595\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6147 - accuracy: 0.4208 - val_loss: 1.5632 - val_accuracy: 0.4268\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6010 - accuracy: 0.4271 - val_loss: 1.6117 - val_accuracy: 0.4198\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5887 - accuracy: 0.4345 - val_loss: 1.5205 - val_accuracy: 0.4534\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5801 - accuracy: 0.4363 - val_loss: 1.5360 - val_accuracy: 0.4449\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5623 - accuracy: 0.4439 - val_loss: 1.5259 - val_accuracy: 0.4525\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5532 - accuracy: 0.4471 - val_loss: 1.5064 - val_accuracy: 0.4625\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5518 - accuracy: 0.4455 - val_loss: 1.4815 - val_accuracy: 0.4727\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5396 - accuracy: 0.4533 - val_loss: 1.5432 - val_accuracy: 0.4456\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5355 - accuracy: 0.4521 - val_loss: 1.5159 - val_accuracy: 0.4562\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5297 - accuracy: 0.4548 - val_loss: 1.5035 - val_accuracy: 0.4623\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5198 - accuracy: 0.4555 - val_loss: 1.4765 - val_accuracy: 0.4714\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5133 - accuracy: 0.4602 - val_loss: 1.4796 - val_accuracy: 0.4761\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5042 - accuracy: 0.4639 - val_loss: 1.4873 - val_accuracy: 0.4732\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5013 - accuracy: 0.4662 - val_loss: 1.5697 - val_accuracy: 0.4482\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4955 - accuracy: 0.4660 - val_loss: 1.5193 - val_accuracy: 0.4450\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4901 - accuracy: 0.4694 - val_loss: 1.4852 - val_accuracy: 0.4699\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4842 - accuracy: 0.4689 - val_loss: 1.4737 - val_accuracy: 0.4756\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4848 - accuracy: 0.4677 - val_loss: 1.5032 - val_accuracy: 0.4546\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4774 - accuracy: 0.4742 - val_loss: 1.4613 - val_accuracy: 0.4734\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4779 - accuracy: 0.4724 - val_loss: 1.5218 - val_accuracy: 0.4572\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4678 - accuracy: 0.4760 - val_loss: 1.4226 - val_accuracy: 0.4924\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4625 - accuracy: 0.4811 - val_loss: 1.4237 - val_accuracy: 0.4928\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4612 - accuracy: 0.4775 - val_loss: 1.4587 - val_accuracy: 0.4771\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4603 - accuracy: 0.4784 - val_loss: 1.4619 - val_accuracy: 0.4751\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4531 - accuracy: 0.4826 - val_loss: 1.5541 - val_accuracy: 0.4412\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4544 - accuracy: 0.4808 - val_loss: 1.4459 - val_accuracy: 0.4812\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4487 - accuracy: 0.4840 - val_loss: 1.4891 - val_accuracy: 0.4694\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4526 - accuracy: 0.4822 - val_loss: 1.4570 - val_accuracy: 0.4810\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4456 - accuracy: 0.4860 - val_loss: 1.4823 - val_accuracy: 0.4711\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4401 - accuracy: 0.4858 - val_loss: 1.4869 - val_accuracy: 0.4655\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4375 - accuracy: 0.4866 - val_loss: 1.4819 - val_accuracy: 0.4663\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4336 - accuracy: 0.4903 - val_loss: 1.4698 - val_accuracy: 0.4722\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4507 - accuracy: 0.4835 - val_loss: 1.5033 - val_accuracy: 0.4641\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4407 - accuracy: 0.4866 - val_loss: 1.4792 - val_accuracy: 0.4674\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4384 - accuracy: 0.4866 - val_loss: 1.4761 - val_accuracy: 0.4692\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4327 - accuracy: 0.4872 - val_loss: 1.4443 - val_accuracy: 0.4853\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4320 - accuracy: 0.4901 - val_loss: 1.5613 - val_accuracy: 0.4424\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4295 - accuracy: 0.4879 - val_loss: 1.4971 - val_accuracy: 0.4722\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4227 - accuracy: 0.4926 - val_loss: 1.5039 - val_accuracy: 0.4641\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4255 - accuracy: 0.4914 - val_loss: 1.4426 - val_accuracy: 0.4791\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3018 - accuracy: 0.5340\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4426 - accuracy: 0.4791\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 160)               491680    \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1610      \n",
      "=================================================================\n",
      "Total params: 599,530\n",
      "Trainable params: 597,930\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n",
      "160 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1226 - accuracy: 0.2471 - val_loss: 2.0079 - val_accuracy: 0.2510\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8465 - accuracy: 0.3283 - val_loss: 1.7510 - val_accuracy: 0.3669\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7762 - accuracy: 0.3618 - val_loss: 1.7602 - val_accuracy: 0.3601\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7294 - accuracy: 0.3774 - val_loss: 1.6697 - val_accuracy: 0.4028\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7122 - accuracy: 0.3833 - val_loss: 1.6614 - val_accuracy: 0.4004\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6880 - accuracy: 0.3964 - val_loss: 1.6095 - val_accuracy: 0.4218\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6702 - accuracy: 0.4030 - val_loss: 1.5854 - val_accuracy: 0.4229\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6493 - accuracy: 0.4099 - val_loss: 1.6104 - val_accuracy: 0.4219\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6276 - accuracy: 0.4203 - val_loss: 1.5518 - val_accuracy: 0.4385\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6111 - accuracy: 0.4236 - val_loss: 1.5335 - val_accuracy: 0.4518\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.6003 - accuracy: 0.4292 - val_loss: 1.5358 - val_accuracy: 0.4475\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5915 - accuracy: 0.4303 - val_loss: 1.5761 - val_accuracy: 0.4359\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5804 - accuracy: 0.4328 - val_loss: 1.5110 - val_accuracy: 0.4588\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5658 - accuracy: 0.4409 - val_loss: 1.5350 - val_accuracy: 0.4534\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5636 - accuracy: 0.4417 - val_loss: 1.5087 - val_accuracy: 0.4581\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5478 - accuracy: 0.4445 - val_loss: 1.5085 - val_accuracy: 0.4624\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.5440 - accuracy: 0.4516 - val_loss: 1.5388 - val_accuracy: 0.4480\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5372 - accuracy: 0.4482 - val_loss: 1.4899 - val_accuracy: 0.4667\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5276 - accuracy: 0.4540 - val_loss: 1.5040 - val_accuracy: 0.4622\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5272 - accuracy: 0.4547 - val_loss: 1.4745 - val_accuracy: 0.4700\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5148 - accuracy: 0.4573 - val_loss: 1.4858 - val_accuracy: 0.4742\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5138 - accuracy: 0.4599 - val_loss: 1.4835 - val_accuracy: 0.4688\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5093 - accuracy: 0.4594 - val_loss: 1.5074 - val_accuracy: 0.4649\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5051 - accuracy: 0.4619 - val_loss: 1.5144 - val_accuracy: 0.4594\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5019 - accuracy: 0.4624 - val_loss: 1.4616 - val_accuracy: 0.4759\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4914 - accuracy: 0.4662 - val_loss: 1.4736 - val_accuracy: 0.4691\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4857 - accuracy: 0.4677 - val_loss: 1.5074 - val_accuracy: 0.4598\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4865 - accuracy: 0.4676 - val_loss: 1.4834 - val_accuracy: 0.4697\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4784 - accuracy: 0.4707 - val_loss: 1.4520 - val_accuracy: 0.4827\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4719 - accuracy: 0.4738 - val_loss: 1.4614 - val_accuracy: 0.4752\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4702 - accuracy: 0.4745 - val_loss: 1.5392 - val_accuracy: 0.4485\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4695 - accuracy: 0.4725 - val_loss: 1.4846 - val_accuracy: 0.4687\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4679 - accuracy: 0.4755 - val_loss: 1.4692 - val_accuracy: 0.4764\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4588 - accuracy: 0.4789 - val_loss: 1.4530 - val_accuracy: 0.4812\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4589 - accuracy: 0.4765 - val_loss: 1.4663 - val_accuracy: 0.4729\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4584 - accuracy: 0.4813 - val_loss: 1.5027 - val_accuracy: 0.4720\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4562 - accuracy: 0.4799 - val_loss: 1.5636 - val_accuracy: 0.4447\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4553 - accuracy: 0.4775 - val_loss: 1.4755 - val_accuracy: 0.4748\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4472 - accuracy: 0.4832 - val_loss: 1.4806 - val_accuracy: 0.4701\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4461 - accuracy: 0.4802 - val_loss: 1.4684 - val_accuracy: 0.4765\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4452 - accuracy: 0.4837 - val_loss: 1.4750 - val_accuracy: 0.4711\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4379 - accuracy: 0.4841 - val_loss: 1.4820 - val_accuracy: 0.4757\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4397 - accuracy: 0.4837 - val_loss: 1.4511 - val_accuracy: 0.4818\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4370 - accuracy: 0.4854 - val_loss: 1.4537 - val_accuracy: 0.4904\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1.4327 - accuracy: 0.4864 - val_loss: 1.4711 - val_accuracy: 0.4794\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4284 - accuracy: 0.4872 - val_loss: 1.4649 - val_accuracy: 0.4792\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4315 - accuracy: 0.4873 - val_loss: 1.4311 - val_accuracy: 0.4883\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4273 - accuracy: 0.4880 - val_loss: 1.5367 - val_accuracy: 0.4455\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4222 - accuracy: 0.4934 - val_loss: 1.5161 - val_accuracy: 0.4626\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4241 - accuracy: 0.4905 - val_loss: 1.4466 - val_accuracy: 0.4843\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.2997 - accuracy: 0.5348\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4466 - accuracy: 0.4843\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_80 (Dense)             (None, 170)               522410    \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1710      \n",
      "=================================================================\n",
      "Total params: 643,800\n",
      "Trainable params: 642,100\n",
      "Non-trainable params: 1,700\n",
      "_________________________________________________________________\n",
      "170 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1000 - accuracy: 0.2563 - val_loss: 2.2301 - val_accuracy: 0.2169\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8321 - accuracy: 0.3381 - val_loss: 1.9649 - val_accuracy: 0.3103\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7668 - accuracy: 0.3622 - val_loss: 1.7401 - val_accuracy: 0.3738\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7191 - accuracy: 0.3834 - val_loss: 1.6125 - val_accuracy: 0.4091\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6970 - accuracy: 0.3895 - val_loss: 1.5988 - val_accuracy: 0.4303\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6838 - accuracy: 0.3948 - val_loss: 1.6273 - val_accuracy: 0.4167\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6592 - accuracy: 0.4068 - val_loss: 1.5681 - val_accuracy: 0.4402\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6403 - accuracy: 0.4123 - val_loss: 1.5936 - val_accuracy: 0.4231\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6219 - accuracy: 0.4181 - val_loss: 1.5699 - val_accuracy: 0.4324\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6111 - accuracy: 0.4232 - val_loss: 1.5625 - val_accuracy: 0.4460\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6086 - accuracy: 0.4224 - val_loss: 1.5860 - val_accuracy: 0.4248\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6006 - accuracy: 0.4278 - val_loss: 1.5151 - val_accuracy: 0.4638\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5836 - accuracy: 0.4344 - val_loss: 1.5961 - val_accuracy: 0.4244\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5800 - accuracy: 0.4367 - val_loss: 1.5699 - val_accuracy: 0.4273\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5735 - accuracy: 0.4341 - val_loss: 1.5378 - val_accuracy: 0.4463\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5600 - accuracy: 0.4407 - val_loss: 1.5460 - val_accuracy: 0.4447\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5607 - accuracy: 0.4401 - val_loss: 1.5099 - val_accuracy: 0.4685\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5519 - accuracy: 0.4475 - val_loss: 1.5269 - val_accuracy: 0.4599\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5441 - accuracy: 0.4498 - val_loss: 1.5258 - val_accuracy: 0.4571\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5397 - accuracy: 0.4503 - val_loss: 1.5379 - val_accuracy: 0.4538\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5322 - accuracy: 0.4548 - val_loss: 1.5136 - val_accuracy: 0.4531\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5184 - accuracy: 0.4608 - val_loss: 1.5241 - val_accuracy: 0.4534\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5137 - accuracy: 0.4574 - val_loss: 1.4674 - val_accuracy: 0.4745\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5108 - accuracy: 0.4592 - val_loss: 1.5591 - val_accuracy: 0.4480\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5054 - accuracy: 0.4622 - val_loss: 1.4681 - val_accuracy: 0.4770\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4970 - accuracy: 0.4618 - val_loss: 1.4874 - val_accuracy: 0.4724\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4955 - accuracy: 0.4635 - val_loss: 1.5323 - val_accuracy: 0.4498\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4903 - accuracy: 0.4676 - val_loss: 1.4806 - val_accuracy: 0.4664\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4822 - accuracy: 0.4702 - val_loss: 1.4835 - val_accuracy: 0.4734\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4841 - accuracy: 0.4688 - val_loss: 1.4845 - val_accuracy: 0.4719\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4794 - accuracy: 0.4718 - val_loss: 1.4593 - val_accuracy: 0.4792\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4738 - accuracy: 0.4746 - val_loss: 1.5056 - val_accuracy: 0.4626\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4698 - accuracy: 0.4729 - val_loss: 1.5691 - val_accuracy: 0.4433\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4664 - accuracy: 0.4772 - val_loss: 1.4852 - val_accuracy: 0.4707\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4665 - accuracy: 0.4769 - val_loss: 1.4921 - val_accuracy: 0.4624\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4599 - accuracy: 0.4784 - val_loss: 1.4833 - val_accuracy: 0.4729\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4589 - accuracy: 0.4766 - val_loss: 1.4749 - val_accuracy: 0.4702\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4527 - accuracy: 0.4794 - val_loss: 1.4721 - val_accuracy: 0.4757\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4456 - accuracy: 0.4796 - val_loss: 1.4526 - val_accuracy: 0.4775\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4453 - accuracy: 0.4839 - val_loss: 1.4737 - val_accuracy: 0.4715\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4448 - accuracy: 0.4857 - val_loss: 1.4534 - val_accuracy: 0.4769\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4408 - accuracy: 0.4860 - val_loss: 1.5567 - val_accuracy: 0.4470\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4370 - accuracy: 0.4851 - val_loss: 1.5102 - val_accuracy: 0.4530\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4377 - accuracy: 0.4866 - val_loss: 1.4474 - val_accuracy: 0.4793\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4402 - accuracy: 0.4856 - val_loss: 1.5190 - val_accuracy: 0.4657\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4306 - accuracy: 0.4897 - val_loss: 1.4882 - val_accuracy: 0.4683\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4257 - accuracy: 0.4894 - val_loss: 1.4947 - val_accuracy: 0.4606\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4233 - accuracy: 0.4891 - val_loss: 1.4756 - val_accuracy: 0.4761\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4235 - accuracy: 0.4885 - val_loss: 1.4696 - val_accuracy: 0.4699\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4230 - accuracy: 0.4889 - val_loss: 1.4156 - val_accuracy: 0.5001\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.2550 - accuracy: 0.5557\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4156 - accuracy: 0.5001\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 180)               553140    \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 180)               720       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 180)               32580     \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 180)               720       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 180)               32580     \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 180)               720       \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 180)               32580     \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 180)               720       \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 180)               32580     \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 180)               720       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1810      \n",
      "=================================================================\n",
      "Total params: 688,870\n",
      "Trainable params: 687,070\n",
      "Non-trainable params: 1,800\n",
      "_________________________________________________________________\n",
      "180 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1066 - accuracy: 0.2565 - val_loss: 1.8918 - val_accuracy: 0.3289\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8343 - accuracy: 0.3358 - val_loss: 1.7283 - val_accuracy: 0.3633\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7675 - accuracy: 0.3640 - val_loss: 1.7275 - val_accuracy: 0.3621\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7239 - accuracy: 0.3807 - val_loss: 1.6900 - val_accuracy: 0.3949\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7026 - accuracy: 0.3859 - val_loss: 1.6366 - val_accuracy: 0.4183\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6929 - accuracy: 0.3919 - val_loss: 1.7132 - val_accuracy: 0.3790\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6629 - accuracy: 0.4052 - val_loss: 1.5470 - val_accuracy: 0.4435\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6398 - accuracy: 0.4090 - val_loss: 1.5782 - val_accuracy: 0.4259\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6196 - accuracy: 0.4187 - val_loss: 1.6222 - val_accuracy: 0.4023\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6100 - accuracy: 0.4217 - val_loss: 1.5849 - val_accuracy: 0.4230\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5976 - accuracy: 0.4260 - val_loss: 1.5703 - val_accuracy: 0.4276\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5861 - accuracy: 0.4310 - val_loss: 1.5504 - val_accuracy: 0.4442\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5760 - accuracy: 0.4350 - val_loss: 1.5353 - val_accuracy: 0.4489\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5660 - accuracy: 0.4386 - val_loss: 1.5243 - val_accuracy: 0.4582\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5536 - accuracy: 0.4431 - val_loss: 1.5876 - val_accuracy: 0.4290\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5452 - accuracy: 0.4425 - val_loss: 1.5273 - val_accuracy: 0.4456\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5439 - accuracy: 0.4471 - val_loss: 1.5221 - val_accuracy: 0.4534\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5324 - accuracy: 0.4503 - val_loss: 1.5081 - val_accuracy: 0.4588\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5313 - accuracy: 0.4512 - val_loss: 1.5225 - val_accuracy: 0.4530\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5216 - accuracy: 0.4537 - val_loss: 1.5206 - val_accuracy: 0.4524\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5184 - accuracy: 0.4552 - val_loss: 1.5221 - val_accuracy: 0.4476\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5100 - accuracy: 0.4571 - val_loss: 1.5043 - val_accuracy: 0.4626\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5044 - accuracy: 0.4643 - val_loss: 1.5116 - val_accuracy: 0.4566\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4992 - accuracy: 0.4633 - val_loss: 1.5056 - val_accuracy: 0.4595\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4945 - accuracy: 0.4640 - val_loss: 1.4632 - val_accuracy: 0.4773\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4881 - accuracy: 0.4685 - val_loss: 1.5095 - val_accuracy: 0.4630\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4872 - accuracy: 0.4680 - val_loss: 1.5016 - val_accuracy: 0.4677\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4793 - accuracy: 0.4730 - val_loss: 1.5447 - val_accuracy: 0.4445\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4778 - accuracy: 0.4713 - val_loss: 1.4863 - val_accuracy: 0.4679\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4676 - accuracy: 0.4743 - val_loss: 1.4729 - val_accuracy: 0.4706\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4587 - accuracy: 0.4763 - val_loss: 1.4685 - val_accuracy: 0.4732\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4681 - accuracy: 0.4740 - val_loss: 1.5192 - val_accuracy: 0.4575\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4607 - accuracy: 0.4771 - val_loss: 1.4304 - val_accuracy: 0.4940\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4567 - accuracy: 0.4796 - val_loss: 1.4862 - val_accuracy: 0.4703\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4576 - accuracy: 0.4772 - val_loss: 1.4834 - val_accuracy: 0.4687\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4471 - accuracy: 0.4817 - val_loss: 1.5285 - val_accuracy: 0.4548\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4472 - accuracy: 0.4832 - val_loss: 1.4717 - val_accuracy: 0.4764\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4431 - accuracy: 0.4846 - val_loss: 1.4915 - val_accuracy: 0.4690\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4388 - accuracy: 0.4862 - val_loss: 1.4882 - val_accuracy: 0.4756\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4403 - accuracy: 0.4857 - val_loss: 1.4694 - val_accuracy: 0.4738\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4339 - accuracy: 0.4863 - val_loss: 1.4821 - val_accuracy: 0.4742\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4257 - accuracy: 0.4910 - val_loss: 1.5152 - val_accuracy: 0.4567\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4298 - accuracy: 0.4885 - val_loss: 1.4888 - val_accuracy: 0.4690\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4252 - accuracy: 0.4911 - val_loss: 1.4503 - val_accuracy: 0.4843\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4247 - accuracy: 0.4912 - val_loss: 1.4592 - val_accuracy: 0.4775\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4183 - accuracy: 0.4908 - val_loss: 1.4586 - val_accuracy: 0.4779\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4170 - accuracy: 0.4921 - val_loss: 1.4905 - val_accuracy: 0.4679\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4189 - accuracy: 0.4945 - val_loss: 1.4488 - val_accuracy: 0.4811\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4134 - accuracy: 0.4955 - val_loss: 1.4431 - val_accuracy: 0.4825\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4124 - accuracy: 0.4953 - val_loss: 1.4909 - val_accuracy: 0.4658\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3504 - accuracy: 0.5213\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4909 - accuracy: 0.4658\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 190)               583870    \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 190)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 190)               760       \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 190)               36290     \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 190)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 190)               760       \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 190)               36290     \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 190)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 190)               760       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 190)               36290     \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 190)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 190)               760       \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 190)               36290     \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 190)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 190)               760       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1910      \n",
      "=================================================================\n",
      "Total params: 734,740\n",
      "Trainable params: 732,840\n",
      "Non-trainable params: 1,900\n",
      "_________________________________________________________________\n",
      "190 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1177 - accuracy: 0.2521 - val_loss: 2.0619 - val_accuracy: 0.2407\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.8425 - accuracy: 0.3331 - val_loss: 1.7940 - val_accuracy: 0.3306\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7775 - accuracy: 0.3575 - val_loss: 1.7546 - val_accuracy: 0.3552\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7385 - accuracy: 0.3740 - val_loss: 1.6674 - val_accuracy: 0.4020\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7216 - accuracy: 0.3798 - val_loss: 1.6840 - val_accuracy: 0.3898\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6854 - accuracy: 0.3955 - val_loss: 1.5872 - val_accuracy: 0.4277\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6673 - accuracy: 0.4012 - val_loss: 1.6063 - val_accuracy: 0.4245\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6531 - accuracy: 0.4056 - val_loss: 1.5612 - val_accuracy: 0.4366\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6405 - accuracy: 0.4068 - val_loss: 1.6130 - val_accuracy: 0.4183\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6356 - accuracy: 0.4126 - val_loss: 1.5398 - val_accuracy: 0.4482\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6174 - accuracy: 0.4186 - val_loss: 1.5802 - val_accuracy: 0.4336\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6121 - accuracy: 0.4203 - val_loss: 1.5381 - val_accuracy: 0.4404\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6010 - accuracy: 0.4257 - val_loss: 1.5402 - val_accuracy: 0.4467\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5925 - accuracy: 0.4279 - val_loss: 1.5118 - val_accuracy: 0.4581\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5783 - accuracy: 0.4322 - val_loss: 1.7825 - val_accuracy: 0.3729\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5777 - accuracy: 0.4353 - val_loss: 1.5839 - val_accuracy: 0.4233\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5680 - accuracy: 0.4392 - val_loss: 1.5176 - val_accuracy: 0.4592\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5612 - accuracy: 0.4422 - val_loss: 1.5366 - val_accuracy: 0.4512\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5573 - accuracy: 0.4429 - val_loss: 1.5201 - val_accuracy: 0.4514\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5526 - accuracy: 0.4437 - val_loss: 1.5549 - val_accuracy: 0.4478\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5473 - accuracy: 0.4473 - val_loss: 1.5100 - val_accuracy: 0.4582\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5396 - accuracy: 0.4495 - val_loss: 1.5515 - val_accuracy: 0.4495\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5382 - accuracy: 0.4514 - val_loss: 1.5980 - val_accuracy: 0.4220\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5293 - accuracy: 0.4533 - val_loss: 1.5199 - val_accuracy: 0.4627\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5281 - accuracy: 0.4529 - val_loss: 1.5754 - val_accuracy: 0.4285\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5219 - accuracy: 0.4570 - val_loss: 1.5524 - val_accuracy: 0.4480\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5123 - accuracy: 0.4566 - val_loss: 1.5313 - val_accuracy: 0.4591\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5138 - accuracy: 0.4598 - val_loss: 1.5085 - val_accuracy: 0.4650\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5119 - accuracy: 0.4619 - val_loss: 1.5865 - val_accuracy: 0.4289\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5073 - accuracy: 0.4624 - val_loss: 1.4974 - val_accuracy: 0.4669\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5078 - accuracy: 0.4616 - val_loss: 1.5180 - val_accuracy: 0.4539\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5029 - accuracy: 0.4644 - val_loss: 1.6259 - val_accuracy: 0.4145\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5021 - accuracy: 0.4616 - val_loss: 1.5223 - val_accuracy: 0.4576\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4916 - accuracy: 0.4687 - val_loss: 1.5543 - val_accuracy: 0.4453\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4903 - accuracy: 0.4697 - val_loss: 1.5455 - val_accuracy: 0.4474\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4879 - accuracy: 0.4688 - val_loss: 1.5208 - val_accuracy: 0.4526\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4899 - accuracy: 0.4696 - val_loss: 1.4815 - val_accuracy: 0.4689\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4834 - accuracy: 0.4687 - val_loss: 1.5159 - val_accuracy: 0.4649\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4819 - accuracy: 0.4694 - val_loss: 1.5837 - val_accuracy: 0.4443\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4811 - accuracy: 0.4701 - val_loss: 1.5125 - val_accuracy: 0.4582\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4783 - accuracy: 0.4730 - val_loss: 1.5334 - val_accuracy: 0.4508\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4715 - accuracy: 0.4740 - val_loss: 1.5028 - val_accuracy: 0.4630\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4714 - accuracy: 0.4750 - val_loss: 1.5270 - val_accuracy: 0.4542\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4679 - accuracy: 0.4731 - val_loss: 1.5314 - val_accuracy: 0.4576\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4683 - accuracy: 0.4746 - val_loss: 1.4989 - val_accuracy: 0.4630\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4611 - accuracy: 0.4796 - val_loss: 1.5076 - val_accuracy: 0.4648\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4616 - accuracy: 0.4781 - val_loss: 1.5424 - val_accuracy: 0.4558\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4584 - accuracy: 0.4777 - val_loss: 1.4876 - val_accuracy: 0.4781\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4582 - accuracy: 0.4807 - val_loss: 1.5163 - val_accuracy: 0.4631\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4559 - accuracy: 0.4815 - val_loss: 1.5099 - val_accuracy: 0.4587\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3709 - accuracy: 0.5116\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5099 - accuracy: 0.4587\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 200)               614600    \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 781,410\n",
      "Trainable params: 779,410\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n",
      "200 neurons per layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.1098 - accuracy: 0.2536 - val_loss: 2.0741 - val_accuracy: 0.2430\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.8342 - accuracy: 0.3353 - val_loss: 1.7868 - val_accuracy: 0.3467\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7696 - accuracy: 0.3585 - val_loss: 1.6599 - val_accuracy: 0.3967\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.7194 - accuracy: 0.3779 - val_loss: 2.0500 - val_accuracy: 0.3014\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6836 - accuracy: 0.3946 - val_loss: 1.6150 - val_accuracy: 0.4148\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6548 - accuracy: 0.4052 - val_loss: 1.5581 - val_accuracy: 0.4409\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6330 - accuracy: 0.4125 - val_loss: 1.6533 - val_accuracy: 0.4004\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.6073 - accuracy: 0.4229 - val_loss: 1.5405 - val_accuracy: 0.4496\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5913 - accuracy: 0.4299 - val_loss: 1.5279 - val_accuracy: 0.4550\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5801 - accuracy: 0.4351 - val_loss: 1.6360 - val_accuracy: 0.4226\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5682 - accuracy: 0.4352 - val_loss: 1.5050 - val_accuracy: 0.4565\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5577 - accuracy: 0.4434 - val_loss: 1.5289 - val_accuracy: 0.4526\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5407 - accuracy: 0.4498 - val_loss: 1.4769 - val_accuracy: 0.4726\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5315 - accuracy: 0.4523 - val_loss: 1.4738 - val_accuracy: 0.4674\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5200 - accuracy: 0.4558 - val_loss: 1.4524 - val_accuracy: 0.4810\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5142 - accuracy: 0.4570 - val_loss: 1.4935 - val_accuracy: 0.4633\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.5039 - accuracy: 0.4647 - val_loss: 1.4560 - val_accuracy: 0.4820\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4984 - accuracy: 0.4629 - val_loss: 1.5036 - val_accuracy: 0.4702\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4886 - accuracy: 0.4671 - val_loss: 1.4431 - val_accuracy: 0.4816\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4767 - accuracy: 0.4716 - val_loss: 1.4634 - val_accuracy: 0.4760\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4736 - accuracy: 0.4734 - val_loss: 1.4801 - val_accuracy: 0.4680\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4654 - accuracy: 0.4786 - val_loss: 1.4639 - val_accuracy: 0.4735\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4592 - accuracy: 0.4787 - val_loss: 1.4158 - val_accuracy: 0.4941\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4507 - accuracy: 0.4835 - val_loss: 1.5017 - val_accuracy: 0.4687\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4513 - accuracy: 0.4836 - val_loss: 1.4556 - val_accuracy: 0.4820\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4464 - accuracy: 0.4845 - val_loss: 1.4571 - val_accuracy: 0.4694\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4394 - accuracy: 0.4891 - val_loss: 1.4323 - val_accuracy: 0.4878\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4372 - accuracy: 0.4887 - val_loss: 1.5289 - val_accuracy: 0.4582\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4289 - accuracy: 0.4882 - val_loss: 1.4191 - val_accuracy: 0.4894\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4250 - accuracy: 0.4919 - val_loss: 1.4391 - val_accuracy: 0.4848\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4283 - accuracy: 0.4871 - val_loss: 1.5291 - val_accuracy: 0.4560\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4274 - accuracy: 0.4881 - val_loss: 1.4436 - val_accuracy: 0.4841\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4193 - accuracy: 0.4926 - val_loss: 1.4508 - val_accuracy: 0.4827\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4161 - accuracy: 0.4948 - val_loss: 1.4743 - val_accuracy: 0.4775\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4117 - accuracy: 0.4973 - val_loss: 1.4536 - val_accuracy: 0.4765\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.4023 - accuracy: 0.4994 - val_loss: 1.4352 - val_accuracy: 0.4867\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3989 - accuracy: 0.5016 - val_loss: 1.4434 - val_accuracy: 0.4859\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3926 - accuracy: 0.5061 - val_loss: 1.5422 - val_accuracy: 0.4587\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3856 - accuracy: 0.5068 - val_loss: 1.4429 - val_accuracy: 0.4885\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3850 - accuracy: 0.5072 - val_loss: 1.3991 - val_accuracy: 0.5031\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3821 - accuracy: 0.5066 - val_loss: 1.4539 - val_accuracy: 0.4751\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3703 - accuracy: 0.5091 - val_loss: 1.4247 - val_accuracy: 0.4887\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3764 - accuracy: 0.5103 - val_loss: 1.4085 - val_accuracy: 0.4942\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3681 - accuracy: 0.5134 - val_loss: 1.4455 - val_accuracy: 0.4848\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3619 - accuracy: 0.5141 - val_loss: 1.4338 - val_accuracy: 0.4918\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3608 - accuracy: 0.5124 - val_loss: 1.4301 - val_accuracy: 0.4827\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3548 - accuracy: 0.5163 - val_loss: 1.4128 - val_accuracy: 0.4945\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3596 - accuracy: 0.5147 - val_loss: 1.4243 - val_accuracy: 0.4928\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3553 - accuracy: 0.5171 - val_loss: 1.4537 - val_accuracy: 0.4772\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.3489 - accuracy: 0.5183 - val_loss: 1.4423 - val_accuracy: 0.4850\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.2589 - accuracy: 0.5514\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4423 - accuracy: 0.4850\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y_train_error = []\n",
    "y_test_error = []\n",
    "for i in range(10,210,10):\n",
    "    x.append(i)\n",
    "    model = create_model((x_train.shape[1],), no_classes, 5, i)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print('%d neurons per layer' % i)\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=128, verbose=1, validation_data=(x_test, y_test))\n",
    "    #train error\n",
    "    _, train_accuracy = model.evaluate(x_train, y_train)\n",
    "    train_error = (1 - train_accuracy)*100\n",
    "    y_train_error.append(train_error)\n",
    "    #test_error\n",
    "    _, test_accuracy = model.evaluate(x_test, y_test)\n",
    "    test_error = (1 - test_accuracy)*100\n",
    "    y_test_error.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f544ddb2e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"number of neurons per layer\")\n",
    "plt.ylabel('test set error %')\n",
    "plt.plot(x, y_train_error, 'b', label='train error')\n",
    "plt.plot(x, y_test_error, 'r', label='test error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('number_of_neurons_per_layer___test_set_error_with_regularizer.txt', 'w')\n",
    "\n",
    "f.write('number of neurons per layer, train error, test error\\n')\n",
    "for i in range(len(x)):\n",
    "    f.write('{}, {}, {}'.format(x[i], y_train_error[i], y_test_error[i]))\n",
    "    f.write('\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
